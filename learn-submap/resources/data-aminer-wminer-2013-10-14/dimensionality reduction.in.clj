#topic_maps.core.TopicMap{:topic-graph #graphs.core.Digraph{:nodes #{{:id 763505, :title "Signal processing", :type :wiki-api.core/category} {:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 9653, :title "Expected value", :type :wiki-api.core/article} {:id 4850525, :title "Gambling terminology", :type :wiki-api.core/category} {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 1034006, :title "Particle physics", :type :wiki-api.core/category} {:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} {:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} {:id 1009204, :title "Information science", :type :wiki-api.core/category} {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 487312, :title "Information geometry", :type :wiki-api.core/article} {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} {:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} {:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} {:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 2883137, :title "Parametric model", :type :wiki-api.core/article} {:id 691921, :title "Topology", :type :wiki-api.core/category} {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 4594816, :title "P-complete problems", :type :wiki-api.core/category} {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} {:id 2022258, :title "Utility", :type :wiki-api.core/category} {:id 4842680, :title "Data security", :type :wiki-api.core/category} {:id 4859836, :title "Single equation methods (econometrics)", :type :wiki-api.core/category} {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} {:id 554671, :title "Density estimation", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 11737376, :title "Statistical natural language processing", :type :wiki-api.core/category} {:id 693992, :title "Measure theory", :type :wiki-api.core/category} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 692453, :title "Matrix theory", :type :wiki-api.core/category} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 962541, :title "Fourier analysis", :type :wiki-api.core/category} {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} {:id 695981, :title "Geometric topology", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 12684760, :title "Ethical principles", :type :wiki-api.core/category} {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 987553, :title "Interpolation", :type :wiki-api.core/category} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} {:id 20417300, :title "Types of functions", :type :wiki-api.core/category} {:id 693878, :title "Differential geometry", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} {:id 10699378, :title "Process management", :type :wiki-api.core/category} {:id 707453, :title "Digital signal processing", :type :wiki-api.core/category} {:id 5116610, :title "Actuarial science", :type :wiki-api.core/category} {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} {:id 26263822, :title "Packaging machinery", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 695968, :title "Category theory", :type :wiki-api.core/category} {:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} {:id 998678, :title "Surveillance", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} {:id 8156101, :title "Statistical methods", :type :wiki-api.core/category} {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} {:id 15165316, :title "Visualization (graphic)", :type :wiki-api.core/category} {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 909365, :title "Functional languages", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 704495, :title "Differential topology", :type :wiki-api.core/category} {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category} {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 923167, :title "Length", :type :wiki-api.core/category} {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} {:id 962413, :title "Image processing", :type :wiki-api.core/category} {:id 2299740, :title "Business terms", :type :wiki-api.core/category} {:id 27955209, :title "Model selection", :type :wiki-api.core/category} {:id 30752198, :title "Discrete transforms", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 2019322, :title "Splines", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category} {:id 39378, :title "Distance", :type :wiki-api.core/article} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 797088, :title "Computer vision", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 9387237, :title "Parametric statistics", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 712517, :title "Unitary operators", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} {:id 25292883, :title "Linear programming", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} {:id 10043, :title "Estimator", :type :wiki-api.core/article} {:id 946910, :title "Decision theory", :type :wiki-api.core/category} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 406624, :title "Time series", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category} {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} {:id 5774898, :title "Free statistical software", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} {:id 700292, :title "Scientific method", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 6537021, :title "Statistical deviation and dispersion", :type :wiki-api.core/category} {:id 13039922, :title "Information technology governance", :type :wiki-api.core/category} {:id 690777, :title "Linear algebra", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} {:id 3030322, :title "Manifolds", :type :wiki-api.core/category} {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category} {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category} {:id 21917434, :title "Information Age", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} {:id 697516, :title "Metric geometry", :type :wiki-api.core/category} {:id 703162, :title "Statistical software", :type :wiki-api.core/category} {:id 751362, :title "Face recognition", :type :wiki-api.core/category} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 2699398, :title "Dynamic programming", :type :wiki-api.core/category} {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category} {:id 1055691, :title "Learning", :type :wiki-api.core/category} {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 821959, :title "Matrices", :type :wiki-api.core/category} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} {:id 4869267, :title "Economics of uncertainty", :type :wiki-api.core/category} {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category} {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article} {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category} {:id 1213181, :title "Hilbert space", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, :in-map {{:id 763505, :title "Signal processing", :type :wiki-api.core/category} #{}, {:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} #{}, {:id 9653, :title "Expected value", :type :wiki-api.core/article} #{{:id 4850525, :title "Gambling terminology", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 4850525, :title "Gambling terminology", :type :wiki-api.core/category} #{}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 1034006, :title "Particle physics", :type :wiki-api.core/category} #{}, {:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 29421988, :title "Least squares", :type :wiki-api.core/category} #{{:id 4859836, :title "Single equation methods (econometrics)", :type :wiki-api.core/category} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category}}, {:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} #{}, {:id 1009204, :title "Information science", :type :wiki-api.core/category} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category}}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{{:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category}}, {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} #{{:id 4842680, :title "Data security", :type :wiki-api.core/category} {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category}}, {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} #{}, {:id 487312, :title "Information geometry", :type :wiki-api.core/article} #{{:id 693878, :title "Differential geometry", :type :wiki-api.core/category} {:id 695968, :title "Category theory", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} #{}, {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category}}, {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} #{}, {:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} #{{:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{{:id 1009204, :title "Information science", :type :wiki-api.core/category} {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} #{{:id 11737376, :title "Statistical natural language processing", :type :wiki-api.core/category} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} #{{:id 4594816, :title "P-complete problems", :type :wiki-api.core/category} {:id 25292883, :title "Linear programming", :type :wiki-api.core/category} {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category}}, {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} #{}, {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 2699398, :title "Dynamic programming", :type :wiki-api.core/category}}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 2883137, :title "Parametric model", :type :wiki-api.core/article} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category}}, {:id 691921, :title "Topology", :type :wiki-api.core/category} #{}, {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} #{{:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 4594816, :title "P-complete problems", :type :wiki-api.core/category} #{}, {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} #{}, {:id 2022258, :title "Utility", :type :wiki-api.core/category} #{{:id 12684760, :title "Ethical principles", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 4842680, :title "Data security", :type :wiki-api.core/category} #{{:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 4859836, :title "Single equation methods (econometrics)", :type :wiki-api.core/category} #{{:id 946892, :title "Econometrics", :type :wiki-api.core/category}}, {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 27955209, :title "Model selection", :type :wiki-api.core/category}}, {:id 554671, :title "Density estimation", :type :wiki-api.core/article} #{{:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category}}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category}}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 11737376, :title "Statistical natural language processing", :type :wiki-api.core/category} #{{:id 960021, :title "Natural language processing", :type :wiki-api.core/category}}, {:id 693992, :title "Measure theory", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} #{}, {:id 692453, :title "Matrix theory", :type :wiki-api.core/category} #{{:id 690777, :title "Linear algebra", :type :wiki-api.core/category}}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{{:id 10699378, :title "Process management", :type :wiki-api.core/category} {:id 2299740, :title "Business terms", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category}}, {:id 709243, :title "Communication", :type :wiki-api.core/category} #{}, {:id 962541, :title "Fourier analysis", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} #{}, {:id 1331441, :title "Document classification", :type :wiki-api.core/article} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category}}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category}}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} #{}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} #{{:id 6534587, :title "Regression analysis", :type :wiki-api.core/category}}, {:id 695981, :title "Geometric topology", :type :wiki-api.core/category} #{{:id 691921, :title "Topology", :type :wiki-api.core/category}}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 12684760, :title "Ethical principles", :type :wiki-api.core/category} #{}, {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} #{{:id 6534587, :title "Regression analysis", :type :wiki-api.core/category}}, {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} #{}, {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} {:id 6537021, :title "Statistical deviation and dispersion", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} #{{:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category}}, {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} #{{:id 5774898, :title "Free statistical software", :type :wiki-api.core/category}}, {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} #{{:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category}}, {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} #{}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{{:id 693985, :title "Probability theory", :type :wiki-api.core/category}}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{{:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 987553, :title "Interpolation", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} #{{:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} #{{:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category}}, {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} #{}, {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} #{{:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 8156101, :title "Statistical methods", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category}}, {:id 946892, :title "Econometrics", :type :wiki-api.core/category} #{{:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category}}, {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category}}, {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} #{}, {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} #{{:id 17306305, :title "Statistical classification", :type :wiki-api.core/category}}, {:id 20417300, :title "Types of functions", :type :wiki-api.core/category} #{}, {:id 693878, :title "Differential geometry", :type :wiki-api.core/category} #{{:id 704495, :title "Differential topology", :type :wiki-api.core/category}}, {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{{:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category}}, {:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} #{{:id 772545, :title "Probability distributions", :type :wiki-api.core/category}}, {:id 10699378, :title "Process management", :type :wiki-api.core/category} #{}, {:id 707453, :title "Digital signal processing", :type :wiki-api.core/category} #{{:id 763505, :title "Signal processing", :type :wiki-api.core/category}}, {:id 5116610, :title "Actuarial science", :type :wiki-api.core/category} #{}, {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 697516, :title "Metric geometry", :type :wiki-api.core/category}}, {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} #{}, {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} #{}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} #{{:id 1754736, :title "Cybernetics", :type :wiki-api.core/category}}, {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} #{}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{{:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} #{}, {:id 26263822, :title "Packaging machinery", :type :wiki-api.core/category} #{}, {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} #{}, {:id 695968, :title "Category theory", :type :wiki-api.core/category} #{{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category}}, {:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} #{{:id 692453, :title "Matrix theory", :type :wiki-api.core/category} {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category}}, {:id 998678, :title "Surveillance", :type :wiki-api.core/category} #{}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category}}, {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} #{}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} #{}, {:id 8156101, :title "Statistical methods", :type :wiki-api.core/category} #{}, {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} #{{:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category}}, {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} #{{:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 9387237, :title "Parametric statistics", :type :wiki-api.core/category}}, {:id 15165316, :title "Visualization (graphic)", :type :wiki-api.core/category} #{{:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category}}, {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category}}, {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} #{}, {:id 909365, :title "Functional languages", :type :wiki-api.core/category} #{}, {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} #{}, {:id 704495, :title "Differential topology", :type :wiki-api.core/category} #{{:id 691921, :title "Topology", :type :wiki-api.core/category} {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} #{}, {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 1008581, :title "Operations research", :type :wiki-api.core/category} #{{:id 5116610, :title "Actuarial science", :type :wiki-api.core/category}}, {:id 734262, :title "Measurement", :type :wiki-api.core/category} #{}, {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category}}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category}}, {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} #{{:id 772545, :title "Probability distributions", :type :wiki-api.core/category}}, {:id 923167, :title "Length", :type :wiki-api.core/category} #{}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{{:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} #{{:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category}}, {:id 962413, :title "Image processing", :type :wiki-api.core/category} #{{:id 707453, :title "Digital signal processing", :type :wiki-api.core/category}}, {:id 2299740, :title "Business terms", :type :wiki-api.core/category} #{}, {:id 27955209, :title "Model selection", :type :wiki-api.core/category} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category}}, {:id 30752198, :title "Discrete transforms", :type :wiki-api.core/category} #{}, {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} #{{:id 6537978, :title "Summary statistics", :type :wiki-api.core/category}}, {:id 706543, :title "Machine learning", :type :wiki-api.core/category} #{{:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} {:id 1055691, :title "Learning", :type :wiki-api.core/category}}, {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} #{{:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 15165316, :title "Visualization (graphic)", :type :wiki-api.core/category} {:id 13039922, :title "Information technology governance", :type :wiki-api.core/category}}, {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} #{{:id 734262, :title "Measurement", :type :wiki-api.core/category}}, {:id 2019322, :title "Splines", :type :wiki-api.core/category} #{{:id 987553, :title "Interpolation", :type :wiki-api.core/category}}, {:id 3175294, :title "Dimension", :type :wiki-api.core/category} #{{:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 3030322, :title "Manifolds", :type :wiki-api.core/category}}, {:id 39378, :title "Distance", :type :wiki-api.core/article} #{{:id 923167, :title "Length", :type :wiki-api.core/category} {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category}}, {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} #{}, {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} #{{:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category}}, {:id 1419629, :title "Searching", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 797088, :title "Computer vision", :type :wiki-api.core/category} #{{:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 26263822, :title "Packaging machinery", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} #{}, {:id 9387237, :title "Parametric statistics", :type :wiki-api.core/category} #{}, {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} #{}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 712517, :title "Unitary operators", :type :wiki-api.core/category} #{}, {:id 693985, :title "Probability theory", :type :wiki-api.core/category} #{{:id 693992, :title "Measure theory", :type :wiki-api.core/category}}, {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} #{{:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category}}, {:id 25292883, :title "Linear programming", :type :wiki-api.core/category} #{{:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category}}, {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} #{}, {:id 10043, :title "Estimator", :type :wiki-api.core/article} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 946910, :title "Decision theory", :type :wiki-api.core/category} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category} {:id 4869267, :title "Economics of uncertainty", :type :wiki-api.core/category}}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category}}, {:id 406624, :title "Time series", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category}}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 21917434, :title "Information Age", :type :wiki-api.core/category}}, {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{{:id 763505, :title "Signal processing", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article} #{{:id 6534587, :title "Regression analysis", :type :wiki-api.core/category}}, {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} #{}, {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} #{{:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category}}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{{:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 923167, :title "Length", :type :wiki-api.core/category}}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{{:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} {:id 751362, :title "Face recognition", :type :wiki-api.core/category}}, {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category} #{}, {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} #{{:id 2019322, :title "Splines", :type :wiki-api.core/category}}, {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} #{}, {:id 5774898, :title "Free statistical software", :type :wiki-api.core/category} #{{:id 703162, :title "Statistical software", :type :wiki-api.core/category}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{{:id 1009204, :title "Information science", :type :wiki-api.core/category} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category}}, {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} #{{:id 1213181, :title "Hilbert space", :type :wiki-api.core/category}}, {:id 700292, :title "Scientific method", :type :wiki-api.core/category} #{}, {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{{:id 29421852, :title "M-estimators", :type :wiki-api.core/category}}, {:id 6537021, :title "Statistical deviation and dispersion", :type :wiki-api.core/category} #{}, {:id 13039922, :title "Information technology governance", :type :wiki-api.core/category} #{}, {:id 690777, :title "Linear algebra", :type :wiki-api.core/category} #{}, {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} #{}, {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} #{{:id 8156101, :title "Statistical methods", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} #{{:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} #{{:id 962541, :title "Fourier analysis", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 30752198, :title "Discrete transforms", :type :wiki-api.core/category} {:id 712517, :title "Unitary operators", :type :wiki-api.core/category}}, {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} #{}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{{:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category}}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category}}, {:id 3030322, :title "Manifolds", :type :wiki-api.core/category} #{{:id 695981, :title "Geometric topology", :type :wiki-api.core/category} {:id 693878, :title "Differential geometry", :type :wiki-api.core/category}}, {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category} #{}, {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 690777, :title "Linear algebra", :type :wiki-api.core/category}}, {:id 21917434, :title "Information Age", :type :wiki-api.core/category} #{}, {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} #{{:id 1034006, :title "Particle physics", :type :wiki-api.core/category} {:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} #{{:id 998678, :title "Surveillance", :type :wiki-api.core/category}}, {:id 697516, :title "Metric geometry", :type :wiki-api.core/category} #{}, {:id 703162, :title "Statistical software", :type :wiki-api.core/category} #{}, {:id 751362, :title "Face recognition", :type :wiki-api.core/category} #{}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 2699398, :title "Dynamic programming", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category}}, {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category} #{{:id 4859836, :title "Single equation methods (econometrics)", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 1055691, :title "Learning", :type :wiki-api.core/category} #{}, {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} #{{:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{{:id 693992, :title "Measure theory", :type :wiki-api.core/category} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 20417300, :title "Types of functions", :type :wiki-api.core/category}}, {:id 821959, :title "Matrices", :type :wiki-api.core/category} #{{:id 692453, :title "Matrix theory", :type :wiki-api.core/category}}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{{:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} {:id 909365, :title "Functional languages", :type :wiki-api.core/category} {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category}}, {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article} #{{:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 4869267, :title "Economics of uncertainty", :type :wiki-api.core/category} #{{:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category}}, {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category} #{}, {:id 951835, :title "Computer data", :type :wiki-api.core/category} #{}, {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category} #{}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{{:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 27955209, :title "Model selection", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category}}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category}}, {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category} #{{:id 1009204, :title "Information science", :type :wiki-api.core/category} {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category}}, {:id 1213181, :title "Hilbert space", :type :wiki-api.core/category} #{}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category} {:id 700292, :title "Scientific method", :type :wiki-api.core/category}}}, :out-map {{:id 763505, :title "Signal processing", :type :wiki-api.core/category} #{{:id 707453, :title "Digital signal processing", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 695968, :title "Category theory", :type :wiki-api.core/category}}, {:id 9653, :title "Expected value", :type :wiki-api.core/article} #{}, {:id 4850525, :title "Gambling terminology", :type :wiki-api.core/category} #{{:id 9653, :title "Expected value", :type :wiki-api.core/article}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{}, {:id 1034006, :title "Particle physics", :type :wiki-api.core/category} #{{:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} #{}, {:id 29421988, :title "Least squares", :type :wiki-api.core/category} #{{:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article}}, {:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 1009204, :title "Information science", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category}}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{}, {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} #{}, {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 487312, :title "Information geometry", :type :wiki-api.core/article} #{}, {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} #{{:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} #{{:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} {:id 2699398, :title "Dynamic programming", :type :wiki-api.core/category}}, {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} #{{:id 1009204, :title "Information science", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} #{}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{{:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} #{}, {:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} #{}, {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 946910, :title "Decision theory", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category}}, {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} #{}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{}, {:id 2883137, :title "Parametric model", :type :wiki-api.core/article} #{}, {:id 691921, :title "Topology", :type :wiki-api.core/category} #{{:id 695981, :title "Geometric topology", :type :wiki-api.core/category} {:id 704495, :title "Differential topology", :type :wiki-api.core/category}}, {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} #{{:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article}}, {:id 4594816, :title "P-complete problems", :type :wiki-api.core/category} #{{:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article}}, {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} #{{:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article}}, {:id 2022258, :title "Utility", :type :wiki-api.core/category} #{}, {:id 4842680, :title "Data security", :type :wiki-api.core/category} #{{:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article}}, {:id 4859836, :title "Single equation methods (econometrics)", :type :wiki-api.core/category} #{{:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category}}, {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} #{}, {:id 554671, :title "Density estimation", :type :wiki-api.core/article} #{}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{}, {:id 11737376, :title "Statistical natural language processing", :type :wiki-api.core/category} #{{:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article}}, {:id 693992, :title "Measure theory", :type :wiki-api.core/category} #{{:id 693985, :title "Probability theory", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{}, {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} #{{:id 554671, :title "Density estimation", :type :wiki-api.core/article}}, {:id 692453, :title "Matrix theory", :type :wiki-api.core/category} #{{:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} {:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{}, {:id 709243, :title "Communication", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 962541, :title "Fourier analysis", :type :wiki-api.core/category} #{{:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article}}, {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article}}, {:id 1331441, :title "Document classification", :type :wiki-api.core/article} #{}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{}, {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 3461736, :title "Data visualization", :type :wiki-api.core/article}}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{{:id 25292883, :title "Linear programming", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} #{}, {:id 695981, :title "Geometric topology", :type :wiki-api.core/category} #{{:id 3030322, :title "Manifolds", :type :wiki-api.core/category}}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{{:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article}}, {:id 12684760, :title "Ethical principles", :type :wiki-api.core/category} #{{:id 2022258, :title "Utility", :type :wiki-api.core/category}}, {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} #{{:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article}}, {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article}}, {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} #{}, {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} #{}, {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{{:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{}, {:id 987553, :title "Interpolation", :type :wiki-api.core/category} #{{:id 2019322, :title "Splines", :type :wiki-api.core/category}}, {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} #{}, {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article}}, {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} #{{:id 27955209, :title "Model selection", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} {:id 10043, :title "Estimator", :type :wiki-api.core/article}}, {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} #{}, {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} #{{:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} #{{:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article}}, {:id 946892, :title "Econometrics", :type :wiki-api.core/category} #{{:id 4859836, :title "Single equation methods (econometrics)", :type :wiki-api.core/category} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} #{{:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} #{{:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 801135, :title "Conditional independence", :type :wiki-api.core/article}}, {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} #{}, {:id 20417300, :title "Types of functions", :type :wiki-api.core/category} #{{:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 693878, :title "Differential geometry", :type :wiki-api.core/category} #{{:id 487312, :title "Information geometry", :type :wiki-api.core/article} {:id 3030322, :title "Manifolds", :type :wiki-api.core/category}}, {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} #{{:id 987553, :title "Interpolation", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{}, {:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} #{{:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article}}, {:id 10699378, :title "Process management", :type :wiki-api.core/category} #{{:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category}}, {:id 707453, :title "Digital signal processing", :type :wiki-api.core/category} #{{:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 5116610, :title "Actuarial science", :type :wiki-api.core/category} #{{:id 1008581, :title "Operations research", :type :wiki-api.core/category}}, {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} #{{:id 53932, :title "Euclidean distance", :type :wiki-api.core/article}}, {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} #{{:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article}}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{}, {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 797088, :title "Computer vision", :type :wiki-api.core/category} {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category}}, {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} #{{:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} #{{:id 4869267, :title "Economics of uncertainty", :type :wiki-api.core/category} {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category}}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{}, {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} #{{:id 27590, :title "Standard deviation", :type :wiki-api.core/article} {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category}}, {:id 26263822, :title "Packaging machinery", :type :wiki-api.core/category} #{{:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} #{{:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category}}, {:id 695968, :title "Category theory", :type :wiki-api.core/category} #{{:id 487312, :title "Information geometry", :type :wiki-api.core/article}}, {:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} #{{:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article}}, {:id 998678, :title "Surveillance", :type :wiki-api.core/category} #{{:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category}}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article}}, {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{{:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 406624, :title "Time series", :type :wiki-api.core/article} {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article}}, {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 8156101, :title "Statistical methods", :type :wiki-api.core/category} #{{:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category}}, {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} #{}, {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} #{}, {:id 15165316, :title "Visualization (graphic)", :type :wiki-api.core/category} #{{:id 3461736, :title "Data visualization", :type :wiki-api.core/article}}, {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} #{}, {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 909365, :title "Functional languages", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} #{{:id 2883137, :title "Parametric model", :type :wiki-api.core/article} {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} {:id 27955209, :title "Model selection", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 704495, :title "Differential topology", :type :wiki-api.core/category} #{{:id 693878, :title "Differential geometry", :type :wiki-api.core/category}}, {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} #{}, {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category}}, {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 1008581, :title "Operations research", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 734262, :title "Measurement", :type :wiki-api.core/category} #{{:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} #{}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{{:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article}}, {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} #{{:id 9653, :title "Expected value", :type :wiki-api.core/article} {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article}}, {:id 923167, :title "Length", :type :wiki-api.core/category} #{{:id 39378, :title "Distance", :type :wiki-api.core/article} {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article}}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{}, {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} #{}, {:id 962413, :title "Image processing", :type :wiki-api.core/category} #{{:id 987553, :title "Interpolation", :type :wiki-api.core/category} {:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 2299740, :title "Business terms", :type :wiki-api.core/category} #{{:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category}}, {:id 27955209, :title "Model selection", :type :wiki-api.core/category} #{{:id 1179950, :title "Feature selection", :type :wiki-api.core/article} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 30752198, :title "Discrete transforms", :type :wiki-api.core/category} #{{:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article}}, {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} #{{:id 14343887, :title "Precision and recall", :type :wiki-api.core/article}}, {:id 706543, :title "Machine learning", :type :wiki-api.core/category} #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} #{}, {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} #{{:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 2019322, :title "Splines", :type :wiki-api.core/category} #{{:id 550633, :title "Spline interpolation", :type :wiki-api.core/article}}, {:id 3175294, :title "Dimension", :type :wiki-api.core/category} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 39378, :title "Distance", :type :wiki-api.core/article} #{}, {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} #{{:id 14343887, :title "Precision and recall", :type :wiki-api.core/article}}, {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} #{}, {:id 1419629, :title "Searching", :type :wiki-api.core/category} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{}, {:id 797088, :title "Computer vision", :type :wiki-api.core/category} #{{:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category}}, {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 9387237, :title "Parametric statistics", :type :wiki-api.core/category} #{{:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article}}, {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} #{{:id 2699398, :title "Dynamic programming", :type :wiki-api.core/category} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{}, {:id 712517, :title "Unitary operators", :type :wiki-api.core/category} #{{:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article}}, {:id 693985, :title "Probability theory", :type :wiki-api.core/category} #{{:id 487312, :title "Information geometry", :type :wiki-api.core/article} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category} {:id 801135, :title "Conditional independence", :type :wiki-api.core/article}}, {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article}}, {:id 25292883, :title "Linear programming", :type :wiki-api.core/category} #{{:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article}}, {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} #{{:id 11737376, :title "Statistical natural language processing", :type :wiki-api.core/category} {:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 10043, :title "Estimator", :type :wiki-api.core/article} #{}, {:id 946910, :title "Decision theory", :type :wiki-api.core/category} #{{:id 2022258, :title "Utility", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category}}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{}, {:id 406624, :title "Time series", :type :wiki-api.core/article} #{}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{{:id 487312, :title "Information geometry", :type :wiki-api.core/article} {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{{:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 10043, :title "Estimator", :type :wiki-api.core/article} {:id 29421852, :title "M-estimators", :type :wiki-api.core/category}}, {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} #{{:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article} #{}, {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} #{{:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article}}, {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} #{}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{}, {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category} #{{:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article}}, {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} #{}, {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} #{{:id 39378, :title "Distance", :type :wiki-api.core/article}}, {:id 5774898, :title "Free statistical software", :type :wiki-api.core/category} #{{:id 6615782, :title "Free plotting software", :type :wiki-api.core/category}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{{:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category} {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article}}, {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} #{}, {:id 700292, :title "Scientific method", :type :wiki-api.core/category} #{{:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{}, {:id 6537021, :title "Statistical deviation and dispersion", :type :wiki-api.core/category} #{{:id 27590, :title "Standard deviation", :type :wiki-api.core/article}}, {:id 13039922, :title "Information technology governance", :type :wiki-api.core/category} #{{:id 3461736, :title "Data visualization", :type :wiki-api.core/article}}, {:id 690777, :title "Linear algebra", :type :wiki-api.core/category} #{{:id 692453, :title "Matrix theory", :type :wiki-api.core/category} {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category}}, {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} #{{:id 2883137, :title "Parametric model", :type :wiki-api.core/article} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 27955209, :title "Model selection", :type :wiki-api.core/category} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} #{{:id 554671, :title "Density estimation", :type :wiki-api.core/article}}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{}, {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} #{}, {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{{:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article}}, {:id 3030322, :title "Manifolds", :type :wiki-api.core/category} #{{:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category} #{{:id 693992, :title "Measure theory", :type :wiki-api.core/category} {:id 962541, :title "Fourier analysis", :type :wiki-api.core/category} {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 704495, :title "Differential topology", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category}}, {:id 1770656, :title "Numerical linear algebra", :type :wiki-api.core/category} #{{:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 22476294, :title "Matrix decompositions", :type :wiki-api.core/category} {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article}}, {:id 21917434, :title "Information Age", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category}}, {:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} #{{:id 602401, :title "Facial recognition system", :type :wiki-api.core/article}}, {:id 697516, :title "Metric geometry", :type :wiki-api.core/category} #{{:id 9833053, :title "String similarity measures", :type :wiki-api.core/category}}, {:id 703162, :title "Statistical software", :type :wiki-api.core/category} #{{:id 5774898, :title "Free statistical software", :type :wiki-api.core/category}}, {:id 751362, :title "Face recognition", :type :wiki-api.core/category} #{{:id 602401, :title "Facial recognition system", :type :wiki-api.core/article}}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{}, {:id 2699398, :title "Dynamic programming", :type :wiki-api.core/category} #{{:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article}}, {:id 3751711, :title "Time series analysis", :type :wiki-api.core/category} #{{:id 406624, :title "Time series", :type :wiki-api.core/article}}, {:id 1055691, :title "Learning", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} #{{:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article}}, {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} #{}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{}, {:id 821959, :title "Matrices", :type :wiki-api.core/category} #{{:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article}}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{}, {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article} #{}, {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} #{{:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 15165316, :title "Visualization (graphic)", :type :wiki-api.core/category}}, {:id 4869267, :title "Economics of uncertainty", :type :wiki-api.core/category} #{{:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category} #{{:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article}}, {:id 951835, :title "Computer data", :type :wiki-api.core/category} #{{:id 4842680, :title "Data security", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{}, {:id 796635, :title "Knowledge representation", :type :wiki-api.core/category} #{{:id 1331441, :title "Document classification", :type :wiki-api.core/article}}, {:id 1213181, :title "Hilbert space", :type :wiki-api.core/category} #{{:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{}}}, :topic-docs #graphs.core.Digraph{:nodes #{1033568 {:id 9653, :title "Expected value", :type :wiki-api.core/article} 599008 {:id 501509, :title "Data point", :type :wiki-api.core/article} 1033505 578977 {:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} {:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} {:id 487312, :title "Information geometry", :type :wiki-api.core/article} 3730755 {:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} 1098307 {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} 1281923 {:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} 544836 3384484 {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 2883137, :title "Parametric model", :type :wiki-api.core/article} {:id 2022258, :title "Utility", :type :wiki-api.core/category} {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} {:id 554671, :title "Density estimation", :type :wiki-api.core/article} 2866181 128005 3719333 3398821 {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} 1032901 {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} 3151621 {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} 610438 {:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} 1280039 {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} 3309831 2946663 {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} 334954 {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} 984939 1281963 2789323 3233739 {:id 43487, :title "Probability density function", :type :wiki-api.core/article} 3743180 {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} 3249421 {:id 8495, :title "Data set", :type :wiki-api.core/article} 3655149 2861581 {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} 335984 212112 {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} 985040 {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} 1118226 3126322 {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} 3482226 2867858 16178 {:id 39378, :title "Distance", :type :wiki-api.core/article} 2899123 {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} 1022643 27571 2974868 {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} 129428 1249493 {:id 10043, :title "Estimator", :type :wiki-api.core/article} 908149 {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} 1032181 {:id 406624, :title "Time series", :type :wiki-api.core/article} 1032279 336023 {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article} 1033879 {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} 3440343 {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} 3517303 {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} 3215609 3730681 {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} 2864505 3270105 {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} 1138266 {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} 595962 {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} {:id 3030322, :title "Manifolds", :type :wiki-api.core/category} 1281915 3715003 3395900 {:id 1817228, :title "Training set", :type :wiki-api.core/article} 3481372 {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} 3245949 {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article} 3618142 130526 {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article} 542207 {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, :in-map {1033568 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article}}, {:id 9653, :title "Expected value", :type :wiki-api.core/article} #{}, 599008 #{{:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{}, 1033505 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, 578977 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} #{}, {:id 29421988, :title "Least squares", :type :wiki-api.core/category} #{}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{}, {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} #{}, {:id 487312, :title "Information geometry", :type :wiki-api.core/article} #{}, 3730755 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} #{}, 1098307 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category}}, {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} #{}, 1281923 #{{:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} #{}, {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} #{}, 544836 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article}}, 3384484 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{}, {:id 2883137, :title "Parametric model", :type :wiki-api.core/article} #{}, {:id 2022258, :title "Utility", :type :wiki-api.core/category} #{}, {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} #{}, {:id 554671, :title "Density estimation", :type :wiki-api.core/article} #{}, 2866181 #{{:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article}}, 128005 #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article}}, 3719333 #{{:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category}}, 3398821 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{}, 1032901 #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 2085584, :title "Feature vector", :type :wiki-api.core/article}}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{}, 3151621 #{{:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article}}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{}, 610438 #{{:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article}}, {:id 1331441, :title "Document classification", :type :wiki-api.core/article} #{}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{}, 1280039 #{{:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} {:id 554671, :title "Density estimation", :type :wiki-api.core/article} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 10043, :title "Estimator", :type :wiki-api.core/article}}, {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} #{}, 3309831 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, 2946663 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} #{}, {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} #{}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{}, {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} #{}, {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} #{}, 334954 #{{:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} #{}, {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} #{}, 984939 #{{:id 9653, :title "Expected value", :type :wiki-api.core/article} {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 487312, :title "Information geometry", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, 1281963 #{{:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article}}, 2789323 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 3461736, :title "Data visualization", :type :wiki-api.core/article}}, 3233739 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{}, 3743180 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{}, 3249421 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{}, 3655149 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, 2861581 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{}, {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} #{}, {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} #{}, {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} #{}, {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} #{}, 335984 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, 212112 #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} #{}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{}, 985040 #{{:id 2883137, :title "Parametric model", :type :wiki-api.core/article} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article}}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{}, {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} #{}, 1118226 #{{:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 39378, :title "Distance", :type :wiki-api.core/article} {:id 406624, :title "Time series", :type :wiki-api.core/article} {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article}}, 3126322 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} #{}, 3482226 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, 2867858 #{{:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article}}, 16178 #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 1331441, :title "Document classification", :type :wiki-api.core/article} {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category}}, {:id 39378, :title "Distance", :type :wiki-api.core/article} #{}, 2899123 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} #{}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{}, 1022643 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article}}, 27571 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, 2974868 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{}, 129428 #{{:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} {:id 2022258, :title "Utility", :type :wiki-api.core/category} {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article}}, 1249493 #{{:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 10043, :title "Estimator", :type :wiki-api.core/article} #{}, 908149 #{{:id 29421988, :title "Least squares", :type :wiki-api.core/category} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{}, 1032181 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article}}, {:id 406624, :title "Time series", :type :wiki-api.core/article} #{}, 1032279 #{{:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, 336023 #{{:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article}}, {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article} #{}, 1033879 #{{:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} #{}, 3440343 #{{:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article}}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{}, 3517303 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{}, {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} #{}, 3215609 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, 3730681 #{{:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{}, 2864505 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article}}, 3270105 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} #{}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{}, 1138266 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article}}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{}, {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} #{}, 595962 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article}}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{}, {:id 3030322, :title "Manifolds", :type :wiki-api.core/category} #{}, 1281915 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} {:id 3030322, :title "Manifolds", :type :wiki-api.core/category}}, 3715003 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, 3395900 #{{:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article}}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{}, 3481372 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} #{}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{}, 3245949 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article} #{}, 3618142 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article}}, 130526 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{}, 542207 #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{}}, :out-map {1033568 #{}, {:id 9653, :title "Expected value", :type :wiki-api.core/article} #{984939}, 599008 #{}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{1033568 1033505 2861581 335984 1138266 1281915}, 1033505 #{}, 578977 #{}, {:id 22562715, :title "Clustering high-dimensional data", :type :wiki-api.core/article} #{1280039}, {:id 29421988, :title "Least squares", :type :wiki-api.core/category} #{1249493 908149}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{128005 984939}, {:id 8190902, :title "Anomaly detection", :type :wiki-api.core/article} #{1280039}, {:id 487312, :title "Information geometry", :type :wiki-api.core/article} #{984939}, 3730755 #{}, {:id 6890644, :title "Singular value decomposition", :type :wiki-api.core/category} #{599008 1118226}, 1098307 #{}, {:id 4605351, :title "Latent Dirichlet allocation", :type :wiki-api.core/article} #{1033568 129428 1032279}, 1281923 #{}, {:id 4993539, :title "Semidefinite programming", :type :wiki-api.core/article} #{610438}, {:id 787776, :title "Curse of dimensionality", :type :wiki-api.core/article} #{1281923 3151621 1138266}, 544836 #{}, 3384484 #{}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{2867858}, {:id 2883137, :title "Parametric model", :type :wiki-api.core/article} #{985040}, {:id 2022258, :title "Utility", :type :wiki-api.core/category} #{129428}, {:id 1179950, :title "Feature selection", :type :wiki-api.core/article} #{1280039 129428}, {:id 554671, :title "Density estimation", :type :wiki-api.core/article} #{1280039}, 2866181 #{}, 128005 #{}, 3719333 #{}, 3398821 #{}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{1033505 1281923 544836 128005 610438 984939 2861581 2867858 1022643 27571 908149 1032181 2864505 595962 3618142}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{1032901 16178 595962}, 1032901 #{}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{1022643 908149 1032181}, 3151621 #{}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{335984}, 610438 #{}, {:id 1331441, :title "Document classification", :type :wiki-api.core/article} #{984939 16178}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{1033505 1281923 544836 212112 1118226 595962}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{984939}, 1280039 #{}, {:id 1045012, :title "Nonlinear regression", :type :wiki-api.core/article} #{984939}, 3309831 #{}, 2946663 #{}, {:id 27590, :title "Standard deviation", :type :wiki-api.core/article} #{595962}, {:id 5978424, :title "Kernel principal component analysis", :type :wiki-api.core/article} #{334954}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{1033568 599008}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{985040 129428}, {:id 76340, :title "Principal component analysis", :type :wiki-api.core/article} #{1281963 27571 129428 908149 336023}, {:id 2085584, :title "Feature vector", :type :wiki-api.core/article} #{1032901}, 334954 #{}, {:id 6534587, :title "Regression analysis", :type :wiki-api.core/category} #{16178}, {:id 1470657, :title "Linear discriminant analysis", :type :wiki-api.core/article} #{1033568 2866181 1032279 1033879 3730681}, 984939 #{}, 1281963 #{}, 2789323 #{}, 3233739 #{}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{1280039}, 3743180 #{}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{985040 336023}, 3249421 #{}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{1033568 1281923 544836 2861581}, 3655149 #{}, 2861581 #{}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{578977 3730755 1098307 3384484 3398821 3309831 2946663 2789323 3233739 3743180 3249421 3655149 3126322 3482226 2899123 2974868 3517303 3215609 3270105 3715003 3481372 3245949 130526 542207}, {:id 504458, :title "Conditional probability distribution", :type :wiki-api.core/article} #{985040}, {:id 1651906, :title "Ordinary least squares", :type :wiki-api.core/article} #{336023}, {:id 6937928, :title "Aggregate data", :type :wiki-api.core/article} #{599008}, {:id 868737, :title "Genetic algorithms", :type :wiki-api.core/category} #{1098307}, 335984 #{}, 212112 #{}, {:id 34327576, :title "Low-rank approximation", :type :wiki-api.core/article} #{908149}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{27571 1249493}, 985040 #{}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{908149}, {:id 140841, :title "Sufficient statistic", :type :wiki-api.core/article} #{984939}, 1118226 #{}, 3126322 #{}, {:id 3461736, :title "Data visualization", :type :wiki-api.core/article} #{2789323 2864505}, 3482226 #{}, 2867858 #{}, 16178 #{}, {:id 39378, :title "Distance", :type :wiki-api.core/article} #{1118226}, 2899123 #{}, {:id 3985352, :title "Ensemble learning", :type :wiki-api.core/category} #{3719333}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{984939}, 1022643 #{}, 27571 #{}, 2974868 #{}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{984939}, 129428 #{}, 1249493 #{}, {:id 10043, :title "Estimator", :type :wiki-api.core/article} #{1280039}, 908149 #{}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{595962}, 1032181 #{}, {:id 406624, :title "Time series", :type :wiki-api.core/article} #{1118226}, 1032279 #{}, 336023 #{}, {:id 16960143, :title "Principal component regression", :type :wiki-api.core/article} #{336023}, 1033879 #{}, {:id 801135, :title "Conditional independence", :type :wiki-api.core/article} #{985040}, 3440343 #{}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{1118226}, 3517303 #{}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{1033568 3395900 542207}, {:id 550633, :title "Spline interpolation", :type :wiki-api.core/article} #{1281915}, 3215609 #{}, 3730681 #{}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{984939}, 2864505 #{}, 3270105 #{}, {:id 651196, :title "Reproducing kernel Hilbert space", :type :wiki-api.core/article} #{985040}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{1033879}, 1138266 #{}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{985040}, {:id 8811, :title "Discrete Fourier transform", :type :wiki-api.core/article} #{1118226}, 595962 #{}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{334954}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{1033879}, {:id 3030322, :title "Manifolds", :type :wiki-api.core/category} #{1281915}, 1281915 #{}, 3715003 #{}, 3395900 #{}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{1032279}, 3481372 #{}, {:id 309261, :title "Nonlinear dimensionality reduction", :type :wiki-api.core/article} #{1281963 335984 1022643 1032181 3440343 2864505 3395900}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{1032279}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{599008 908149}, 3245949 #{}, {:id 14343887, :title "Precision and recall", :type :wiki-api.core/article} #{544836 2864505}, 3618142 #{}, 130526 #{}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{1249493}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{335984}, 542207 #{}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{27571}}}, :doc-map {1033568 #search_api.search_api.Paper{:id 1033568, :key "journals/pami/YanXZZYL07", :title "Graph Embedding and Extensions: A General Framework for Dimensionality Reduction.", :abstract "Over the past few decades, a large family of algorithms—supervised or unsupervised; stemming from statistics or geometry theory—has been designed to provide different solutions to the problem of dimensionality reduction. Despite the different motivations of these algorithms, we present in this paper a general formulation known as graph embedding to unify them within a common framework. In graph embedding, each algorithm can be considered as the direct graph embedding or its linear/kernel/tensor extension of a specific intrinsic graph that describes certain desired statistical or geometric properties of a data set, with constraints from scale normalization or a penalty graph that characterizes a statistical or geometric property that should be avoided. Furthermore, the graph embedding framework can be used as a general platform for developing new dimensionality reduction algorithms. By utilizing this framework as a tool, we propose a new supervised dimensionality reduction algorithm called Marginal Fisher Analysis in which the intrinsic graph characterizes the intraclass compactness and connects each data point with its neighboring points of the same class, while the penalty graph connects the marginal points and characterizes the interclass separability. We show that MFA effectively overcomes the limitations of the traditional Linear Discriminant Analysis algorithm due to data distribution assumptions and available projection directions. Real face recognition experiments show the superiority of our proposed MFA in comparison to LDA, also for corresponding kernel and tensor extensions.", :author (#search_api.search_api.Author{:id 1100627, :first-name nil, :last-name nil, :full-name "Shuicheng Yan"} #search_api.search_api.Author{:id 1177656, :first-name nil, :last-name nil, :full-name "Dong Xu"} #search_api.search_api.Author{:id 1476112, :first-name nil, :last-name nil, :full-name "Benyu Zhang"} #search_api.search_api.Author{:id 1132766, :first-name nil, :last-name nil, :full-name "HongJiang Zhang"} #search_api.search_api.Author{:id 429898, :first-name nil, :last-name nil, :full-name "Qiang Yang"} #search_api.search_api.Author{:id 450408, :first-name nil, :last-name nil, :full-name "Stephen Lin"}), :year 2007, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 952, :string "Graph Embedding and Extensions: A General Framework for Dimensionality Reduction.. Over the past few decades, a large family of algorithms—supervised or unsupervised; stemming from statistics or geometry theory—has been designed to provide different solutions to the problem of dimensionality reduction. Despite the different motivations of these algorithms, we present in this paper a general formulation known as graph embedding to unify them within a common framework. In graph embedding, each algorithm can be considered as the direct graph embedding or its linear/kernel/tensor extension of a specific intrinsic graph that describes certain desired statistical or geometric properties of a data set, with constraints from scale normalization or a penalty graph that characterizes a statistical or geometric property that should be avoided. Furthermore, the graph embedding framework can be used as a general platform for developing new dimensionality reduction algorithms. By utilizing this framework as a tool, we propose a new supervised dimensionality reduction algorithm called Marginal Fisher Analysis in which the intrinsic graph characterizes the intraclass compactness and connects each data point with its neighboring points of the same class, while the penalty graph connects the marginal points and characterizes the interclass separability. We show that MFA effectively overcomes the limitations of the traditional Linear Discriminant Analysis algorithm due to data distribution assumptions and available projection directions. Real face recognition experiments show the superiority of our proposed MFA in comparison to LDA, also for corresponding kernel and tensor extensions.", :doc-id "Graph Embedding and Extensions: A General Framework for Dimensionality Reduction. 2007  ,  ,  ,  ,  ,  "}, 599008 #search_api.search_api.Paper{:id 599008, :key "conf/sigmod/KanthAS98", :title "Dimensionality Reduction for Similarity Searching in Dynamic Databases.", :abstract "Databases are increasingly being used to store multi-media objects such as maps, images, audio and video. Storage and retrieval of these objects is accomplished using multi-dimensional index structures such as R*-trees and SS-trees. As dimensionality increases, query performance in these index structures degrades. This phenomenon, generally referred to as the dimensionality curse, can be circumvented by reducing the dimensionality of the data. Such a reduction is however accompanied by a loss of precision of query results. Current techniques such as QBIC use SVD transform-based dimensionality reduction to ensure high query precision. The drawback of this approach is that SVD is expensive to compute, and therefore not readily applicable to dynamic databases. In this paper, we propose novel techniques for performing SVD-based dimensionality reduction in dynamic databases. When the data distribution changes considerably so as to degrade query precision, we recompute the SVD transform and incorporate it in the existing index structure. For recomputing the SVD-transform, we propose a novel technique that uses aggregate data from the existing index rather than the entire data. This technique reduces the SVD-computation time without compromising query precision. We then explore efficient ways to incorporate the recomputed SVD-transform in the existing index structure without degrading subsequent query response times. These techniques reduce the computation time by a factor of 20 in experiments on color and texture image vectors. The error due to approximate computation of SVD is less than 10%.", :author (#search_api.search_api.Author{:id 1414910, :first-name nil, :last-name nil, :full-name "Kothuri Venkata Ravi Kanth"} #search_api.search_api.Author{:id 1153301, :first-name nil, :last-name nil, :full-name "Divyakant Agrawal"} #search_api.search_api.Author{:id 107025, :first-name nil, :last-name nil, :full-name "Ambuj K. Singh"}), :year 1998, :venue "SIGMOD Conference", :ncit 270, :string "Dimensionality Reduction for Similarity Searching in Dynamic Databases.. Databases are increasingly being used to store multi-media objects such as maps, images, audio and video. Storage and retrieval of these objects is accomplished using multi-dimensional index structures such as R*-trees and SS-trees. As dimensionality increases, query performance in these index structures degrades. This phenomenon, generally referred to as the dimensionality curse, can be circumvented by reducing the dimensionality of the data. Such a reduction is however accompanied by a loss of precision of query results. Current techniques such as QBIC use SVD transform-based dimensionality reduction to ensure high query precision. The drawback of this approach is that SVD is expensive to compute, and therefore not readily applicable to dynamic databases. In this paper, we propose novel techniques for performing SVD-based dimensionality reduction in dynamic databases. When the data distribution changes considerably so as to degrade query precision, we recompute the SVD transform and incorporate it in the existing index structure. For recomputing the SVD-transform, we propose a novel technique that uses aggregate data from the existing index rather than the entire data. This technique reduces the SVD-computation time without compromising query precision. We then explore efficient ways to incorporate the recomputed SVD-transform in the existing index structure without degrading subsequent query response times. These techniques reduce the computation time by a factor of 20 in experiments on color and texture image vectors. The error due to approximate computation of SVD is less than 10%.", :doc-id "Dimensionality Reduction for Similarity Searching in Dynamic Databases. 1998  ,  ,  "}, 1033505 #search_api.search_api.Paper{:id 1033505, :key "journals/pami/Yang04", :title "Distance-Preserving Projection of High-Dimensional Data for Nonlinear Dimensionality Reduction.", :abstract "A distance-preserving method is presented to map high-dimensional data sequentially to low-dimensional space. It preserves exact distances of each data point to its nearest neighbor and to some other near neighbors. Intrinsic dimensionality of data is estimated by examining the preservation of interpoint distances. The method has no user-selectable parameter. It can successfully project data when the data points are spread among multiple clusters. Results of experiments show its usefulness in projecting high-dimensional data.", :author (#search_api.search_api.Author{:id 1193187, :first-name nil, :last-name nil, :full-name "Li Yang"}), :year 2004, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 0, :string "Distance-Preserving Projection of High-Dimensional Data for Nonlinear Dimensionality Reduction.. A distance-preserving method is presented to map high-dimensional data sequentially to low-dimensional space. It preserves exact distances of each data point to its nearest neighbor and to some other near neighbors. Intrinsic dimensionality of data is estimated by examining the preservation of interpoint distances. The method has no user-selectable parameter. It can successfully project data when the data points are spread among multiple clusters. Results of experiments show its usefulness in projecting high-dimensional data.", :doc-id "Distance-Preserving Projection of High-Dimensional Data for Nonlinear Dimensionality Reduction. 2004  "}, 578977 #search_api.search_api.Paper{:id 578977, :key "conf/sdm/BinghamGHHMT06", :title "Segmentation and dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 526318, :first-name nil, :last-name nil, :full-name "Ella Bingham"} #search_api.search_api.Author{:id 1064189, :first-name nil, :last-name nil, :full-name "Aristides Gionis"} #search_api.search_api.Author{:id 132975, :first-name nil, :last-name nil, :full-name "Niina Haiminen"} #search_api.search_api.Author{:id 930430, :first-name nil, :last-name nil, :full-name "Heli Hiisilä"} #search_api.search_api.Author{:id 637822, :first-name nil, :last-name nil, :full-name "Heikki Mannila"} #search_api.search_api.Author{:id 1263281, :first-name nil, :last-name nil, :full-name "Evimaria Terzi"}), :year 2006, :venue "SDM", :ncit 23, :string "Segmentation and dimensionality reduction.. ", :doc-id "Segmentation and dimensionality reduction. 2006  ,  ,  ,  ,  ,  "}, 3730755 #search_api.search_api.Paper{:id 3730755, :key "journals/ijon/MokbelLGH13", :title "Visualizing the quality of dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 315948, :first-name nil, :last-name nil, :full-name "Bassam Mokbel"} #search_api.search_api.Author{:id 14163269, :first-name nil, :last-name nil, :full-name "Wouter Lueks"} #search_api.search_api.Author{:id 1552931, :first-name nil, :last-name nil, :full-name "Andrej Gisbrecht"} #search_api.search_api.Author{:id 477525, :first-name nil, :last-name nil, :full-name "Barbara Hammer"}), :year 2013, :venue "Neurocomputing", :ncit 0, :string "Visualizing the quality of dimensionality reduction.. ", :doc-id "Visualizing the quality of dimensionality reduction. 2013  ,  ,  ,  "}, 1098307 #search_api.search_api.Paper{:id 1098307, :key "journals/tec/RaymerPGKJ00", :title "Dimensionality reduction using genetic algorithms.", :abstract nil, :author (#search_api.search_api.Author{:id 594999, :first-name nil, :last-name nil, :full-name "Michael L. Raymer"} #search_api.search_api.Author{:id 333915, :first-name nil, :last-name nil, :full-name "William F. Punch III"} #search_api.search_api.Author{:id 231511, :first-name nil, :last-name nil, :full-name "Erik D. Goodman"} #search_api.search_api.Author{:id 54175, :first-name nil, :last-name nil, :full-name "Leslie A. Kuhn"} #search_api.search_api.Author{:id 324708, :first-name nil, :last-name nil, :full-name "Anil K. Jain"}), :year 2000, :venue "IEEE Trans. Evolutionary Computation", :ncit 517, :string "Dimensionality reduction using genetic algorithms.. ", :doc-id "Dimensionality reduction using genetic algorithms. 2000  ,  ,  ,  ,  "}, 1281923 #search_api.search_api.Paper{:id 1281923, :key "journals/tkde/LianC09", :title "General Cost Models for Evaluating Dimensionality Reduction in High-Dimensional Spaces.", :abstract "Similarity search usually encounters a serious problem in the high-dimensional space, known as the “curse of dimensionality.” In order to speed up the retrieval efficiency, most previous approaches reduce the dimensionality of the entire data set to a fixed lower value before building indexes (referred to as global dimensionality reduction (GDR)). More recent works focus on locally reducing the dimensionality of data to different values (called the local dimensionality reduction (LDR)). In addition, random projection is proposed as an approximate dimensionality reduction (ADR) technique to answer the approximate similarity search instead of the exact one. However, so far little work has formally evaluated the effectiveness and efficiency of GDR, LDR, and ADR for the range query. Motivated by this, in this paper, we propose general cost models for evaluating the query performance over the reduced data sets by GDR, LDR, and ADR, in light of which we introduce a novel (A)LDR method, Partitioning based on RANdomized Search (PRANS). It can achieve high retrieval efficiency with the guarantee of optimality given by the formal models. Finally, a {\\rm B}^{+}-tree index is constructed over the reduced partitions for fast similarity search. Extensive experiments validate the correctness of our cost models on both real and synthetic data sets and demonstrate the efficiency and effectiveness of the proposed PRANS method.", :author (#search_api.search_api.Author{:id 1282932, :first-name nil, :last-name nil, :full-name "Xiang Lian"} #search_api.search_api.Author{:id 181103, :first-name nil, :last-name nil, :full-name "Lei Chen"}), :year 2009, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 5, :string "General Cost Models for Evaluating Dimensionality Reduction in High-Dimensional Spaces.. Similarity search usually encounters a serious problem in the high-dimensional space, known as the “curse of dimensionality.” In order to speed up the retrieval efficiency, most previous approaches reduce the dimensionality of the entire data set to a fixed lower value before building indexes (referred to as global dimensionality reduction (GDR)). More recent works focus on locally reducing the dimensionality of data to different values (called the local dimensionality reduction (LDR)). In addition, random projection is proposed as an approximate dimensionality reduction (ADR) technique to answer the approximate similarity search instead of the exact one. However, so far little work has formally evaluated the effectiveness and efficiency of GDR, LDR, and ADR for the range query. Motivated by this, in this paper, we propose general cost models for evaluating the query performance over the reduced data sets by GDR, LDR, and ADR, in light of which we introduce a novel (A)LDR method, Partitioning based on RANdomized Search (PRANS). It can achieve high retrieval efficiency with the guarantee of optimality given by the formal models. Finally, a {\\rm B}^{+}-tree index is constructed over the reduced partitions for fast similarity search. Extensive experiments validate the correctness of our cost models on both real and synthetic data sets and demonstrate the efficiency and effectiveness of the proposed PRANS method.", :doc-id "General Cost Models for Evaluating Dimensionality Reduction in High-Dimensional Spaces. 2009  ,  "}, 544836 #search_api.search_api.Paper{:id 544836, :key "conf/pods/Aggarwal01", :title "On the Effects of Dimensionality Reduction on High Dimensional Similarity Search.", :abstract "The dimensionality curse has profound effects on the effectiveness of high-dimensional similarity indexing from the performance perspective. One of the well known techniques for improving the indexing performance is the method of dimensionality reduction. In this technique, the data is transformed to a lower dimensional space by finding a new axis-system in which most of the data variance is preserved in a few dimensions. This reduction may also have a positive effect on the quality of similarity for certain data domains such as text. For other domains, it may lead to loss of information and degradation of search quality. Recent research indicates that the improvement for the text domain is caused by the re-enforcement of the semantic concepts in the data. In this paper, we provide an intuitive model of the effects of dimensionality reduction on arbitrary high dimensional problems. We provide an effective diagnosis of the causality behind the qualitative effects of dimensionality reduction on a given data set. The analysis suggests that these effects are very data dependent. Our analysis also indicates that currently accepted techniques of picking the reduction which results in the least loss of information are useful for maximizing precision and recall, but are not necessarily optimum from a qualitative perspective. We demonstrate that by making simple changes to the implementation details of dimensionality reduction techniques, we can considerably improve the quality of similarity search.", :author (#search_api.search_api.Author{:id 36958, :first-name nil, :last-name nil, :full-name "Charu C. Aggarwal"}), :year 2001, :venue "PODS", :ncit 113, :string "On the Effects of Dimensionality Reduction on High Dimensional Similarity Search.. The dimensionality curse has profound effects on the effectiveness of high-dimensional similarity indexing from the performance perspective. One of the well known techniques for improving the indexing performance is the method of dimensionality reduction. In this technique, the data is transformed to a lower dimensional space by finding a new axis-system in which most of the data variance is preserved in a few dimensions. This reduction may also have a positive effect on the quality of similarity for certain data domains such as text. For other domains, it may lead to loss of information and degradation of search quality. Recent research indicates that the improvement for the text domain is caused by the re-enforcement of the semantic concepts in the data. In this paper, we provide an intuitive model of the effects of dimensionality reduction on arbitrary high dimensional problems. We provide an effective diagnosis of the causality behind the qualitative effects of dimensionality reduction on a given data set. The analysis suggests that these effects are very data dependent. Our analysis also indicates that currently accepted techniques of picking the reduction which results in the least loss of information are useful for maximizing precision and recall, but are not necessarily optimum from a qualitative perspective. We demonstrate that by making simple changes to the implementation details of dimensionality reduction techniques, we can considerably improve the quality of similarity search.", :doc-id "On the Effects of Dimensionality Reduction on High Dimensional Similarity Search. 2001  "}, 3384484 #search_api.search_api.Paper{:id 3384484, :key "journals/corr/abs-1203-6130", :title "Spectral dimensionality reduction for HMMs", :abstract nil, :author (#search_api.search_api.Author{:id 115544, :first-name nil, :last-name nil, :full-name "Dean P. Foster"} #search_api.search_api.Author{:id 14271203, :first-name nil, :last-name nil, :full-name "Jordan Rodu"} #search_api.search_api.Author{:id 352656, :first-name nil, :last-name nil, :full-name "Lyle H. Ungar"}), :year 2012, :venue "CoRR", :ncit 2, :string "Spectral dimensionality reduction for HMMs. ", :doc-id "Spectral dimensionality reduction for HMMs 2012  ,  ,  "}, 2866181 #search_api.search_api.Paper{:id 2866181, :key "journals/ml/SugiyamaINS10", :title "Semi-supervised local Fisher discriminant analysis for dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 799320, :first-name nil, :last-name nil, :full-name "Masashi Sugiyama"} #search_api.search_api.Author{:id 425766, :first-name nil, :last-name nil, :full-name "Tsuyoshi Idé"} #search_api.search_api.Author{:id 380250, :first-name nil, :last-name nil, :full-name "Shinichi Nakajima"} #search_api.search_api.Author{:id 748990, :first-name nil, :last-name nil, :full-name "Jun Sese"}), :year 2010, :venue "Machine Learning", :ncit 73, :string "Semi-supervised local Fisher discriminant analysis for dimensionality reduction.. ", :doc-id "Semi-supervised local Fisher discriminant analysis for dimensionality reduction. 2010  ,  ,  ,  "}, 128005 #search_api.search_api.Paper{:id 128005, :key "conf/cvpr/HadsellCL06", :title "Dimensionality Reduction by Learning an Invariant Mapping.", :abstract "Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that 'similar\" points in input space are mapped to nearby points on the manifold. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent nonlinear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distancemeasure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.", :author (#search_api.search_api.Author{:id 1436729, :first-name nil, :last-name nil, :full-name "Raia Hadsell"} #search_api.search_api.Author{:id 727852, :first-name nil, :last-name nil, :full-name "Sumit Chopra"} #search_api.search_api.Author{:id 450479, :first-name nil, :last-name nil, :full-name "Yann LeCun"}), :year 2006, :venue "CVPR (2)", :ncit 99, :string "Dimensionality Reduction by Learning an Invariant Mapping.. Dimensionality reduction involves mapping a set of high dimensional input points onto a low dimensional manifold so that 'similar\" points in input space are mapped to nearby points on the manifold. We present a method - called Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) - for learning a globally coherent nonlinear function that maps the data evenly to the output manifold. The learning relies solely on neighborhood relationships and does not require any distancemeasure in the input space. The method can learn mappings that are invariant to certain transformations of the inputs, as is demonstrated with a number of experiments. Comparisons are made to other techniques, in particular LLE.", :doc-id "Dimensionality Reduction by Learning an Invariant Mapping. 2006  ,  ,  "}, 3719333 #search_api.search_api.Paper{:id 3719333, :key "journals/corr/abs-1305-4345", :title "Ensembles of Classifiers based on Dimensionality Reduction", :abstract nil, :author (#search_api.search_api.Author{:id 876495, :first-name nil, :last-name nil, :full-name "Alon Schclar"} #search_api.search_api.Author{:id 529112, :first-name nil, :last-name nil, :full-name "Lior Rokach"} #search_api.search_api.Author{:id 14364311, :first-name nil, :last-name nil, :full-name "Amir Amit"}), :year 2013, :venue "CoRR", :ncit 0, :string "Ensembles of Classifiers based on Dimensionality Reduction. ", :doc-id "Ensembles of Classifiers based on Dimensionality Reduction 2013  ,  ,  "}, 3398821 #search_api.search_api.Paper{:id 3398821, :key "journals/prl/GaoSC12", :title "Dimensionality reduction via compressive sensing.", :abstract nil, :author (#search_api.search_api.Author{:id 505334, :first-name nil, :last-name nil, :full-name "Junbin Gao"} #search_api.search_api.Author{:id 441230, :first-name nil, :last-name nil, :full-name "Qinfeng Shi"} #search_api.search_api.Author{:id 844292, :first-name nil, :last-name nil, :full-name "Tibério S. Caetano"}), :year 2012, :venue "Pattern Recognition Letters", :ncit 4, :string "Dimensionality reduction via compressive sensing.. ", :doc-id "Dimensionality reduction via compressive sensing. 2012  ,  ,  "}, 1032901 #search_api.search_api.Paper{:id 1032901, :key "journals/pami/Saund89", :title "Dimensionality-Reduction Using Connectionist Networks.", :abstract "A method is presented for using connectionist networks of simple computing elements to discover a particular type of constraint in multidimensional data. Suppose that some data source provides samples consisting of n-dimensional feature-vectors, but that this data all happens to lie on an m-dimensional surface embedded in the n-dimensional feature space. Then occurrences of data can be more concisely described by specifying an m-dimensional location of the embedded surface than by reciting all n components of the feature vector. The recording of data in such a way is known as dimensionality-reduction. A method is presented for performing dimensionality-reduction in a wide class of situations for which an assumption of linearity need not be made about the underlying constraint surface. The method takes advantage of self-organizing properties of connectionist networks of simple computing elements. The authors present a scheme for representing the values of continuous (scalar) variables in subsets of units.", :author (#search_api.search_api.Author{:id 793626, :first-name nil, :last-name nil, :full-name "Eric Saund"}), :year 1989, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 112, :string "Dimensionality-Reduction Using Connectionist Networks.. A method is presented for using connectionist networks of simple computing elements to discover a particular type of constraint in multidimensional data. Suppose that some data source provides samples consisting of n-dimensional feature-vectors, but that this data all happens to lie on an m-dimensional surface embedded in the n-dimensional feature space. Then occurrences of data can be more concisely described by specifying an m-dimensional location of the embedded surface than by reciting all n components of the feature vector. The recording of data in such a way is known as dimensionality-reduction. A method is presented for performing dimensionality-reduction in a wide class of situations for which an assumption of linearity need not be made about the underlying constraint surface. The method takes advantage of self-organizing properties of connectionist networks of simple computing elements. The authors present a scheme for representing the values of continuous (scalar) variables in subsets of units.", :doc-id "Dimensionality-Reduction Using Connectionist Networks. 1989  "}, 3151621 #search_api.search_api.Paper{:id 3151621, :key "journals/corr/abs-1109-5241", :title "Curse of dimensionality reduction", :abstract nil, :author (#search_api.search_api.Author{:id 39336, :first-name nil, :last-name nil, :full-name "Stephane Gaubert"} #search_api.search_api.Author{:id 14162431, :first-name nil, :last-name nil, :full-name "William McEneaney"} #search_api.search_api.Author{:id 1483275, :first-name nil, :last-name nil, :full-name "Zheng Qu"}), :year 2011, :venue "CoRR", :ncit 0, :string "Curse of dimensionality reduction. ", :doc-id "Curse of dimensionality reduction 2011  ,  ,  "}, 610438 #search_api.search_api.Paper{:id 610438, :key "conf/soda/EngebretsenIO02", :title "Derandomized dimensionality reduction with applications.", :abstract "The Johnson-Lindenstrauss lemma provides a way to map a number of points in high-dimensional space into a low-dimensional space, with only a small distortion of the distances between the points. The proofs of the lemma are non-constructive: they show that a random mapping induces small distortions with high probability, but they do not construct the actual mapping. In this paper, we provide a procedure that constructs such a mapping deterministically in time almost linear in the number of distances to preserve times the dimension of the original space. We then use that result (together with Nisan's pseudorandom generator) to obtain an efficient derandomization of several approximation algorithms based on semidefinite programming.", :author (#search_api.search_api.Author{:id 1440051, :first-name nil, :last-name nil, :full-name "Lars Engebretsen"} #search_api.search_api.Author{:id 1526441, :first-name nil, :last-name nil, :full-name "Piotr Indyk"} #search_api.search_api.Author{:id 119468, :first-name nil, :last-name nil, :full-name "Ryan O'Donnell"}), :year 2002, :venue "SODA", :ncit 42, :string "Derandomized dimensionality reduction with applications.. The Johnson-Lindenstrauss lemma provides a way to map a number of points in high-dimensional space into a low-dimensional space, with only a small distortion of the distances between the points. The proofs of the lemma are non-constructive: they show that a random mapping induces small distortions with high probability, but they do not construct the actual mapping. In this paper, we provide a procedure that constructs such a mapping deterministically in time almost linear in the number of distances to preserve times the dimension of the original space. We then use that result (together with Nisan's pseudorandom generator) to obtain an efficient derandomization of several approximation algorithms based on semidefinite programming.", :doc-id "Derandomized dimensionality reduction with applications. 2002  ,  ,  "}, 1280039 #search_api.search_api.Paper{:id 1280039, :key "journals/nn/SugiyamaKC10", :title "Dimensionality reduction for density ratio estimation in high-dimensional spaces.", :abstract "The ratio of two probability density functions is becoming a quantity of interest these days in the machine learning and data mining communities since it can be used for various data processing tasks such as non-stationarity adaptation, outlier detection, and feature selection. Recently, several methods have been developed for directly estimating the density ratio without going through density estimation and were shown to work well in various practical problems. However, these methods still perform rather poorly when the dimensionality of the data domain is high. In this paper, we propose to incorporate a dimensionality reduction scheme into a density-ratio estimation procedure and experimentally show that the estimation accuracy in high-dimensional cases can be improved.", :author (#search_api.search_api.Author{:id 799320, :first-name nil, :last-name nil, :full-name "Masashi Sugiyama"} #search_api.search_api.Author{:id 761442, :first-name nil, :last-name nil, :full-name "Motoaki Kawanabe"} #search_api.search_api.Author{:id 1380415, :first-name nil, :last-name nil, :full-name "Pui Ling Chui"}), :year 2010, :venue "Neural Networks", :ncit 26, :string "Dimensionality reduction for density ratio estimation in high-dimensional spaces.. The ratio of two probability density functions is becoming a quantity of interest these days in the machine learning and data mining communities since it can be used for various data processing tasks such as non-stationarity adaptation, outlier detection, and feature selection. Recently, several methods have been developed for directly estimating the density ratio without going through density estimation and were shown to work well in various practical problems. However, these methods still perform rather poorly when the dimensionality of the data domain is high. In this paper, we propose to incorporate a dimensionality reduction scheme into a density-ratio estimation procedure and experimentally show that the estimation accuracy in high-dimensional cases can be improved.", :doc-id "Dimensionality reduction for density ratio estimation in high-dimensional spaces. 2010  ,  ,  "}, 3309831 #search_api.search_api.Paper{:id 3309831, :key "journals/eswa/Tsai12a", :title "Dimensionality reduction for computer facial animation.", :abstract nil, :author (#search_api.search_api.Author{:id 889423, :first-name nil, :last-name nil, :full-name "Flora S. Tsai"}), :year 2012, :venue "Expert Syst. Appl.", :ncit 0, :string "Dimensionality reduction for computer facial animation.. ", :doc-id "Dimensionality reduction for computer facial animation. 2012  "}, 2946663 #search_api.search_api.Paper{:id 2946663, :key "conf/icip/HeylenS10", :title "Nonlinear barycentric dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 1177473, :first-name nil, :last-name nil, :full-name "Rob Heylen"} #search_api.search_api.Author{:id 109211, :first-name nil, :last-name nil, :full-name "Paul Scheunders"}), :year 2010, :venue "ICIP", :ncit 2, :string "Nonlinear barycentric dimensionality reduction.. ", :doc-id "Nonlinear barycentric dimensionality reduction. 2010  ,  "}, 334954 #search_api.search_api.Paper{:id 334954, :key "conf/icml/HamLMS04", :title "A kernel view of the dimensionality reduction of manifolds.", :abstract "We interpret several well-known algorithms for dimensionality reduction of manifolds as kernel methods. Isomap, graph Laplacian eigenmap, and locally linear embedding (LLE) all utilize local neighborhood information to construct a global embedding of the manifold. We show how all three algorithms can be described as kernel PCA on specially constructed Gram matrices, and illustrate the similarities and differences between the algorithms with representative examples.", :author (#search_api.search_api.Author{:id 791688, :first-name nil, :last-name nil, :full-name "Jihun Ham"} #search_api.search_api.Author{:id 995863, :first-name nil, :last-name nil, :full-name "Daniel D. Lee"} #search_api.search_api.Author{:id 858035, :first-name nil, :last-name nil, :full-name "Sebastian Mika"} #search_api.search_api.Author{:id 1452049, :first-name nil, :last-name nil, :full-name "Bernhard Schölkopf"}), :year 2004, :venue "ICML", :ncit 273, :string "A kernel view of the dimensionality reduction of manifolds.. We interpret several well-known algorithms for dimensionality reduction of manifolds as kernel methods. Isomap, graph Laplacian eigenmap, and locally linear embedding (LLE) all utilize local neighborhood information to construct a global embedding of the manifold. We show how all three algorithms can be described as kernel PCA on specially constructed Gram matrices, and illustrate the similarities and differences between the algorithms with representative examples.", :doc-id "A kernel view of the dimensionality reduction of manifolds. 2004  ,  ,  ,  "}, 984939 #search_api.search_api.Paper{:id 984939, :key "journals/jmlr/GlobersonT03", :title "Sufficient Dimensionality Reduction.", :abstract "Dimensionality reduction of empirical co-occurrence data is a fundamental problem in unsupervised learning. It is also a well studied problem in statistics known as the analysis of cross-classified data. One principled approach to this problem is to represent the data in low dimension with minimal loss of (mutual) information contained in the original data. In this paper we introduce an information theoretic nonlinear method for finding such a most informative dimension reduction. In contrast with previously introduced clustering based approaches, here we extract continuous feature functions directly from the co-occurrence matrix. In a sense, we automatically extract functions of the variables that serve as approximate sufficient statistics for a sample of one variable about the other one. Our method is different from dimensionality reduction methods which are based on a specific, sometimes arbitrary, metric or embedding. Another interpretation of our method is as generalized - multi-dimensional - non-linear regression, where rather than fitting one regression function through two dimensional data, we extract d-regression functions whose expectation values capture the information among the variables. It thus presents a new learning paradigm that unifies aspects from both supervised and unsupervised learning. The resulting dimension reduction can be described by two conjugate d-dimensional differential manifolds that are coupled through Maximum Entropy I-projections. The Riemannian metrics of these manifolds are determined by the observed expectation values of our extracted features. Following this geometric interpretation we present an iterative information projection algorithm for finding such features and prove its convergence. Our algorithm is similar to the method of \"association analysis\" in statistics, though the feature extraction context as well as the information theoretic and geometric interpretation are new. The algorithm is illustrated by various synthetic co-occurrence data. It is then demonstrated for text categorization and information retrieval and proves effective in selecting a small set of features, often improving performance over the original feature set.", :author (#search_api.search_api.Author{:id 1080882, :first-name nil, :last-name nil, :full-name "Amir Globerson"} #search_api.search_api.Author{:id 1164135, :first-name nil, :last-name nil, :full-name "Naftali Tishby"}), :year 2003, :venue "Journal of Machine Learning Research", :ncit 78, :string "Sufficient Dimensionality Reduction.. Dimensionality reduction of empirical co-occurrence data is a fundamental problem in unsupervised learning. It is also a well studied problem in statistics known as the analysis of cross-classified data. One principled approach to this problem is to represent the data in low dimension with minimal loss of (mutual) information contained in the original data. In this paper we introduce an information theoretic nonlinear method for finding such a most informative dimension reduction. In contrast with previously introduced clustering based approaches, here we extract continuous feature functions directly from the co-occurrence matrix. In a sense, we automatically extract functions of the variables that serve as approximate sufficient statistics for a sample of one variable about the other one. Our method is different from dimensionality reduction methods which are based on a specific, sometimes arbitrary, metric or embedding. Another interpretation of our method is as generalized - multi-dimensional - non-linear regression, where rather than fitting one regression function through two dimensional data, we extract d-regression functions whose expectation values capture the information among the variables. It thus presents a new learning paradigm that unifies aspects from both supervised and unsupervised learning. The resulting dimension reduction can be described by two conjugate d-dimensional differential manifolds that are coupled through Maximum Entropy I-projections. The Riemannian metrics of these manifolds are determined by the observed expectation values of our extracted features. Following this geometric interpretation we present an iterative information projection algorithm for finding such features and prove its convergence. Our algorithm is similar to the method of \"association analysis\" in statistics, though the feature extraction context as well as the information theoretic and geometric interpretation are new. The algorithm is illustrated by various synthetic co-occurrence data. It is then demonstrated for text categorization and information retrieval and proves effective in selecting a small set of features, often improving performance over the original feature set.", :doc-id "Sufficient Dimensionality Reduction. 2003  ,  "}, 1281963 #search_api.search_api.Paper{:id 1281963, :key "journals/tkde/ZhangTLY09", :title "Patch Alignment for Dimensionality Reduction.", :abstract "Spectral analysis-based dimensionality reduction algorithms are important and have been popularly applied in data mining and computer vision applications. To date many algorithms have been developed, e.g., principal component analysis, locally linear embedding, Laplacian eigenmaps, and local tangent space alignment. All of these algorithms have been designed intuitively and pragmatically, i.e., on the basis of the experience and knowledge of experts for their own purposes. Therefore, it will be more informative to provide a systematic framework for understanding the common properties and intrinsic difference in different algorithms. In this paper, we propose such a framework, named \"patch alignment,” which consists of two stages: part optimization and whole alignment. The framework reveals that 1) algorithms are intrinsically different in the patch optimization stage and 2) all algorithms share an almost identical whole alignment stage. As an application of this framework, we develop a new dimensionality reduction algorithm, termed Discriminative Locality Alignment (DLA), by imposing discriminative information in the part optimization stage. DLA can 1) attack the distribution nonlinearity of measurements; 2) preserve the discriminative ability; and 3) avoid the small-sample-size problem. Thorough empirical studies demonstrate the effectiveness of DLA compared with representative dimensionality reduction algorithms.", :author (#search_api.search_api.Author{:id 818402, :first-name nil, :last-name nil, :full-name "Tianhao Zhang"} #search_api.search_api.Author{:id 1164473, :first-name nil, :last-name nil, :full-name "Dacheng Tao"} #search_api.search_api.Author{:id 824407, :first-name nil, :last-name nil, :full-name "Xuelong Li"} #search_api.search_api.Author{:id 1511261, :first-name nil, :last-name nil, :full-name "Jie Yang"}), :year 2009, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 161, :string "Patch Alignment for Dimensionality Reduction.. Spectral analysis-based dimensionality reduction algorithms are important and have been popularly applied in data mining and computer vision applications. To date many algorithms have been developed, e.g., principal component analysis, locally linear embedding, Laplacian eigenmaps, and local tangent space alignment. All of these algorithms have been designed intuitively and pragmatically, i.e., on the basis of the experience and knowledge of experts for their own purposes. Therefore, it will be more informative to provide a systematic framework for understanding the common properties and intrinsic difference in different algorithms. In this paper, we propose such a framework, named \"patch alignment,” which consists of two stages: part optimization and whole alignment. The framework reveals that 1) algorithms are intrinsically different in the patch optimization stage and 2) all algorithms share an almost identical whole alignment stage. As an application of this framework, we develop a new dimensionality reduction algorithm, termed Discriminative Locality Alignment (DLA), by imposing discriminative information in the part optimization stage. DLA can 1) attack the distribution nonlinearity of measurements; 2) preserve the discriminative ability; and 3) avoid the small-sample-size problem. Thorough empirical studies demonstrate the effectiveness of DLA compared with representative dimensionality reduction algorithms.", :doc-id "Patch Alignment for Dimensionality Reduction. 2009  ,  ,  ,  "}, 2789323 #search_api.search_api.Paper{:id 2789323, :key "conf/gecco/IckeR10", :title "Dimensionality reduction using symbolic regression.", :abstract "In this paper, we propose a symbolic regression approach for data visualization that is suited for classification tasks. Our algorithm seeks a visually and semantically interpretable lower dimensional representation of the given dataset that would increase classifier accuracy as well. This simultaneous identification of easily interpretable dimensionality reduction and improved classification accuracy relieves the user of the burden of experimenting with the many combinations of classification and dimensionality reduction techniques", :author (#search_api.search_api.Author{:id 151646, :first-name nil, :last-name nil, :full-name "Ilknur Icke"} #search_api.search_api.Author{:id 862786, :first-name nil, :last-name nil, :full-name "Andrew Rosenberg"}), :year 2010, :venue "GECCO (Companion)", :ncit 1, :string "Dimensionality reduction using symbolic regression.. In this paper, we propose a symbolic regression approach for data visualization that is suited for classification tasks. Our algorithm seeks a visually and semantically interpretable lower dimensional representation of the given dataset that would increase classifier accuracy as well. This simultaneous identification of easily interpretable dimensionality reduction and improved classification accuracy relieves the user of the burden of experimenting with the many combinations of classification and dimensionality reduction techniques", :doc-id "Dimensionality reduction using symbolic regression. 2010  ,  "}, 3233739 #search_api.search_api.Paper{:id 3233739, :key "conf/ijcnn/OnclinxLWV10", :title "Dimensionality reduction by rank preservation.", :abstract nil, :author (#search_api.search_api.Author{:id 922352, :first-name nil, :last-name nil, :full-name "Victor Onclinx"} #search_api.search_api.Author{:id 1089626, :first-name nil, :last-name nil, :full-name "John Aldo Lee"} #search_api.search_api.Author{:id 594310, :first-name nil, :last-name nil, :full-name "Vincent Wertz"} #search_api.search_api.Author{:id 555506, :first-name nil, :last-name nil, :full-name "Michel Verleysen"}), :year 2010, :venue "IJCNN", :ncit 1, :string "Dimensionality reduction by rank preservation.. ", :doc-id "Dimensionality reduction by rank preservation. 2010  ,  ,  ,  "}, 3743180 #search_api.search_api.Paper{:id 3743180, :key "journals/mta/ZhangZ13", :title "Dimensionality reduction-based spoken emotion recognition.", :abstract nil, :author (#search_api.search_api.Author{:id 496894, :first-name nil, :last-name nil, :full-name "Shiqing Zhang"} #search_api.search_api.Author{:id 217543, :first-name nil, :last-name nil, :full-name "Xiaoming Zhao"}), :year 2013, :venue "Multimedia Tools Appl.", :ncit 0, :string "Dimensionality reduction-based spoken emotion recognition.. ", :doc-id "Dimensionality reduction-based spoken emotion recognition. 2013  ,  "}, 3249421 #search_api.search_api.Paper{:id 3249421, :key "journals/eswa/Tsai12", :title "A visualization metric for dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 889423, :first-name nil, :last-name nil, :full-name "Flora S. Tsai"}), :year 2012, :venue "Expert Syst. Appl.", :ncit 2, :string "A visualization metric for dimensionality reduction.. ", :doc-id "A visualization metric for dimensionality reduction. 2012  "}, 3655149 #search_api.search_api.Paper{:id 3655149, :key "journals/ivs/FernstadSJ13", :title "Quality-based guidance for exploratory dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 14293603, :first-name nil, :last-name nil, :full-name "Sara Johansson Fernstad"} #search_api.search_api.Author{:id 610955, :first-name nil, :last-name nil, :full-name "Jane Shaw"} #search_api.search_api.Author{:id 1072866, :first-name nil, :last-name nil, :full-name "Jimmy Johansson"}), :year 2013, :venue "Information Visualization", :ncit 0, :string "Quality-based guidance for exploratory dimensionality reduction.. ", :doc-id "Quality-based guidance for exploratory dimensionality reduction. 2013  ,  ,  "}, 2861581 #search_api.search_api.Paper{:id 2861581, :key "journals/ijon/ChenZBWC10", :title "Constrained Laplacian Eigenmap for dimensionality reduction.", :abstract "Dimensionality reduction is a commonly used tool in machine learning, especially when dealing with high dimensional data. We consider semi-supervised graph based dimensionality reduction in this paper, and a novel dimensionality reduction algorithm called constrained Laplacian Eigenmap (CLE) is proposed. Suppose the data set contains r classes, and for each class we have some labeled points. CLE maps each data point into r different lines, and each map i tries to separate points belonging to class i from others by using label information. CLE constrains the solution space of Laplacian Eigenmap only to contain embedding results that are consistent with the labels. Then, each point is represented as a r-dimensional vector. Labeled points belonging to the same class are merged together, labeled points belonging to different classes are separated, and similar points are close to one another. We perform semi-supervised document clustering using CLE on two standard corpora. Experimental results show that CLE is very effective.", :author (#search_api.search_api.Author{:id 707135, :first-name nil, :last-name nil, :full-name "Chun Chen"} #search_api.search_api.Author{:id 1541946, :first-name nil, :last-name nil, :full-name "Lijun Zhang"} #search_api.search_api.Author{:id 66914, :first-name nil, :last-name nil, :full-name "Jiajun Bu"} #search_api.search_api.Author{:id 1497529, :first-name nil, :last-name nil, :full-name "Can Wang"} #search_api.search_api.Author{:id 1227722, :first-name nil, :last-name nil, :full-name "Wei Chen"}), :year 2010, :venue "Neurocomputing", :ncit 10, :string "Constrained Laplacian Eigenmap for dimensionality reduction.. Dimensionality reduction is a commonly used tool in machine learning, especially when dealing with high dimensional data. We consider semi-supervised graph based dimensionality reduction in this paper, and a novel dimensionality reduction algorithm called constrained Laplacian Eigenmap (CLE) is proposed. Suppose the data set contains r classes, and for each class we have some labeled points. CLE maps each data point into r different lines, and each map i tries to separate points belonging to class i from others by using label information. CLE constrains the solution space of Laplacian Eigenmap only to contain embedding results that are consistent with the labels. Then, each point is represented as a r-dimensional vector. Labeled points belonging to the same class are merged together, labeled points belonging to different classes are separated, and similar points are close to one another. We perform semi-supervised document clustering using CLE on two standard corpora. Experimental results show that CLE is very effective.", :doc-id "Constrained Laplacian Eigenmap for dimensionality reduction. 2010  ,  ,  ,  ,  "}, 335984 #search_api.search_api.Paper{:id 335984, :key "conf/icml/YangFZB06", :title "Semi-supervised nonlinear dimensionality reduction.", :abstract "The problem of nonlinear dimensionality reduction is considered. We focus on problems where prior information is available, namely, semi-supervised dimensionality reduction. It is shown that basic nonlinear dimensionality reduction algorithms, such as Locally Linear Embedding (LLE), Isometric feature mapping (ISOMAP), and Local Tangent Space Alignment (LTSA), can be modified by taking into account prior information on exact mapping of certain data points. The sensitivity analysis of our algorithms shows that prior information will improve stability of the solution. We also give some insight on what kind of prior information best improves the solution. We demonstrate the usefulness of our algorithm by synthetic and real life examples.", :author (#search_api.search_api.Author{:id 1005957, :first-name nil, :last-name nil, :full-name "Xin Yang"} #search_api.search_api.Author{:id 209375, :first-name nil, :last-name nil, :full-name "Haoying Fu"} #search_api.search_api.Author{:id 1440445, :first-name nil, :last-name nil, :full-name "Hongyuan Zha"} #search_api.search_api.Author{:id 44676, :first-name nil, :last-name nil, :full-name "Jesse L. Barlow"}), :year 2006, :venue "ICML", :ncit 86, :string "Semi-supervised nonlinear dimensionality reduction.. The problem of nonlinear dimensionality reduction is considered. We focus on problems where prior information is available, namely, semi-supervised dimensionality reduction. It is shown that basic nonlinear dimensionality reduction algorithms, such as Locally Linear Embedding (LLE), Isometric feature mapping (ISOMAP), and Local Tangent Space Alignment (LTSA), can be modified by taking into account prior information on exact mapping of certain data points. The sensitivity analysis of our algorithms shows that prior information will improve stability of the solution. We also give some insight on what kind of prior information best improves the solution. We demonstrate the usefulness of our algorithm by synthetic and real life examples.", :doc-id "Semi-supervised nonlinear dimensionality reduction. 2006  ,  ,  ,  "}, 212112 #search_api.search_api.Paper{:id 212112, :key "conf/focs/AndoniIP06", :title "On the Optimality of the Dimensionality Reduction Method.", :abstract "We investigate the optimality of (1+\\in )-approximation algorithms obtained via the dimensionality reduction method. We show that: --Any data structure for the (1+\\in )-approximate nearest neighbor problem in Hamming space, which uses constant number of probes to answer each query, must use n^{\\Omega \\left( {1/ \\in ^2 } \\right)}space. --Any algorithm for the (1+\\in )-approximate closest substring problem must run in time exponential in 1/ \\in ^{2 - \\gamma } for any \\gamma > 0 (unless 3SAT can be solved in subexponential time) Both lower bounds are (essentially) tight.", :author (#search_api.search_api.Author{:id 121263, :first-name nil, :last-name nil, :full-name "Alexandr Andoni"} #search_api.search_api.Author{:id 1526441, :first-name nil, :last-name nil, :full-name "Piotr Indyk"} #search_api.search_api.Author{:id 1272709, :first-name nil, :last-name nil, :full-name "Mihai Patrascu"}), :year 2006, :venue "FOCS", :ncit 48, :string "On the Optimality of the Dimensionality Reduction Method.. We investigate the optimality of (1+\\in )-approximation algorithms obtained via the dimensionality reduction method. We show that: --Any data structure for the (1+\\in )-approximate nearest neighbor problem in Hamming space, which uses constant number of probes to answer each query, must use n^{\\Omega \\left( {1/ \\in ^2 } \\right)}space. --Any algorithm for the (1+\\in )-approximate closest substring problem must run in time exponential in 1/ \\in ^{2 - \\gamma } for any \\gamma > 0 (unless 3SAT can be solved in subexponential time) Both lower bounds are (essentially) tight.", :doc-id "On the Optimality of the Dimensionality Reduction Method. 2006  ,  ,  "}, 985040 #search_api.search_api.Paper{:id 985040, :key "journals/jmlr/FukumizuBJ03", :title "Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces.", :abstract "We propose a novel method of dimensionality reduction for supervised learning problems. Given a regression or classification problem in which we wish to predict a response variable Y from an explanatory variable X, we treat the problem of dimensionality reduction as that of finding a low-dimensional \"effective subspace\" for X which retains the statistical relationship between X and Y. We show that this problem can be formulated in terms of conditional independence. To turn this formulation into an optimization problem we establish a general nonparametric characterization of conditional independence using covariance operators on reproducing kernel Hilbert spaces. This characterization allows us to derive a contrast function for estimation of the effective subspace. Unlike many conventional methods for dimensionality reduction in supervised learning, the proposed method requires neither assumptions on the marginal distribution of X, nor a parametric model of the conditional distribution of Y. We present experiments that compare the performance of the method with conventional methods.", :author (#search_api.search_api.Author{:id 650180, :first-name nil, :last-name nil, :full-name "Kenji Fukumizu"} #search_api.search_api.Author{:id 356953, :first-name nil, :last-name nil, :full-name "Francis R. Bach"} #search_api.search_api.Author{:id 221919, :first-name nil, :last-name nil, :full-name "Michael I. Jordan"}), :year 2004, :venue "Journal of Machine Learning Research", :ncit 227, :string "Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces.. We propose a novel method of dimensionality reduction for supervised learning problems. Given a regression or classification problem in which we wish to predict a response variable Y from an explanatory variable X, we treat the problem of dimensionality reduction as that of finding a low-dimensional \"effective subspace\" for X which retains the statistical relationship between X and Y. We show that this problem can be formulated in terms of conditional independence. To turn this formulation into an optimization problem we establish a general nonparametric characterization of conditional independence using covariance operators on reproducing kernel Hilbert spaces. This characterization allows us to derive a contrast function for estimation of the effective subspace. Unlike many conventional methods for dimensionality reduction in supervised learning, the proposed method requires neither assumptions on the marginal distribution of X, nor a parametric model of the conditional distribution of Y. We present experiments that compare the performance of the method with conventional methods.", :doc-id "Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces. 2004  ,  ,  "}, 1118226 #search_api.search_api.Paper{:id 1118226, :key "journals/tods/ChakrabartiKMP02", :title "Locally adaptive dimensionality reduction for indexing large time series databases.", :abstract "Similarity search in large time series databases has attracted much research interest recently. It is a difficult problem because of the typically high dimensionality of the data. The most promising solutions involve performing dimensionality reduction on the data, then indexing the reduced data with a multidimensional index structure. Many dimensionality reduction techniques have been proposed, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), and the Discrete Wavelet Transform (DWT). In this article, we introduce a new dimensionality reduction technique, which we call Adaptive Piecewise Constant Approximation (APCA). While previous techniques (e.g., SVD, DFT and DWT) choose a common representation for all the items in the database that minimizes the global reconstruction error, APCA approximates each time series by a set of constant value segments of varying lengths such that their individual reconstruction errors are minimal. We show how APCA can be indexed using a multidimensional index structure. We propose two distance measures in the indexed space that exploit the high fidelity of APCA for fast searching: a lower bounding Euclidean distance approximation, and a non-lower-bounding, but very tight, Euclidean distance approximation, and show how they can support fast exact searching and even faster approximate searching on the same index structure. We theoretically and empirically compare APCA to all the other techniques and demonstrate its superiority.", :author (#search_api.search_api.Author{:id 1102334, :first-name nil, :last-name nil, :full-name "Kaushik Chakrabarti"} #search_api.search_api.Author{:id 196194, :first-name nil, :last-name nil, :full-name "Eamonn J. Keogh"} #search_api.search_api.Author{:id 77119, :first-name nil, :last-name nil, :full-name "Sharad Mehrotra"} #search_api.search_api.Author{:id 132607, :first-name nil, :last-name nil, :full-name "Michael J. Pazzani"}), :year 2002, :venue "ACM Trans. Database Syst.", :ncit 664, :string "Locally adaptive dimensionality reduction for indexing large time series databases.. Similarity search in large time series databases has attracted much research interest recently. It is a difficult problem because of the typically high dimensionality of the data. The most promising solutions involve performing dimensionality reduction on the data, then indexing the reduced data with a multidimensional index structure. Many dimensionality reduction techniques have been proposed, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), and the Discrete Wavelet Transform (DWT). In this article, we introduce a new dimensionality reduction technique, which we call Adaptive Piecewise Constant Approximation (APCA). While previous techniques (e.g., SVD, DFT and DWT) choose a common representation for all the items in the database that minimizes the global reconstruction error, APCA approximates each time series by a set of constant value segments of varying lengths such that their individual reconstruction errors are minimal. We show how APCA can be indexed using a multidimensional index structure. We propose two distance measures in the indexed space that exploit the high fidelity of APCA for fast searching: a lower bounding Euclidean distance approximation, and a non-lower-bounding, but very tight, Euclidean distance approximation, and show how they can support fast exact searching and even faster approximate searching on the same index structure. We theoretically and empirically compare APCA to all the other techniques and demonstrate its superiority.", :doc-id "Locally adaptive dimensionality reduction for indexing large time series databases. 2002  ,  ,  ,  "}, 3126322 #search_api.search_api.Paper{:id 3126322, :key "journals/widm/Yang11", :title "Distance-preserving dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 1193170, :first-name nil, :last-name nil, :full-name "Li Yang"}), :year 2011, :venue "Wiley Interdisc. Rew.: Data Mining and Knowledge Discovery", :ncit 3, :string "Distance-preserving dimensionality reduction.. ", :doc-id "Distance-preserving dimensionality reduction. 2011  "}, 3482226 #search_api.search_api.Paper{:id 3482226, :key "journals/pr/ZhuHYSXL13", :title "Self-taught dimensionality reduction on the high-dimensional small-sized data.", :abstract nil, :author (#search_api.search_api.Author{:id 1521665, :first-name nil, :last-name nil, :full-name "Xiaofeng Zhu"} #search_api.search_api.Author{:id 950608, :first-name nil, :last-name nil, :full-name "Zi Huang"} #search_api.search_api.Author{:id 756242, :first-name nil, :last-name nil, :full-name "Yang Yang"} #search_api.search_api.Author{:id 1347203, :first-name nil, :last-name nil, :full-name "Heng Tao Shen"} #search_api.search_api.Author{:id 695188, :first-name nil, :last-name nil, :full-name "Changsheng Xu"} #search_api.search_api.Author{:id 1108709, :first-name nil, :last-name nil, :full-name "Jiebo Luo"}), :year 2013, :venue "Pattern Recognition", :ncit 5, :string "Self-taught dimensionality reduction on the high-dimensional small-sized data.. ", :doc-id "Self-taught dimensionality reduction on the high-dimensional small-sized data. 2013  ,  ,  ,  ,  ,  "}, 2867858 #search_api.search_api.Paper{:id 2867858, :key "journals/prl/LeeV10", :title "Scale-independent quality criteria for dimensionality reduction.", :abstract "Dimensionality reduction aims at representing high-dimensional data in low-dimensional spaces, in order to facilitate their visual interpretation. Many techniques exist, ranging from simple linear projections to more complex nonlinear transformations. The large variety of methods emphasizes the need of quality criteria that allow for fair comparisons between them. This paper extends previous work about rank-based quality criteria and proposes to circumvent their scale dependency. Most dimensionality reduction techniques indeed rely on a scale parameter that distinguish between local and global data properties. Such a scale dependency can be similarly found in usual quality criteria: they assess the embedding quality on a certain scale. Experiments with various dimensionality reduction techniques eventually show the strengths and weaknesses of the proposed scale-independent criteria.", :author (#search_api.search_api.Author{:id 1089626, :first-name nil, :last-name nil, :full-name "John Aldo Lee"} #search_api.search_api.Author{:id 555506, :first-name nil, :last-name nil, :full-name "Michel Verleysen"}), :year 2010, :venue "Pattern Recognition Letters", :ncit 13, :string "Scale-independent quality criteria for dimensionality reduction.. Dimensionality reduction aims at representing high-dimensional data in low-dimensional spaces, in order to facilitate their visual interpretation. Many techniques exist, ranging from simple linear projections to more complex nonlinear transformations. The large variety of methods emphasizes the need of quality criteria that allow for fair comparisons between them. This paper extends previous work about rank-based quality criteria and proposes to circumvent their scale dependency. Most dimensionality reduction techniques indeed rely on a scale parameter that distinguish between local and global data properties. Such a scale dependency can be similarly found in usual quality criteria: they assess the embedding quality on a certain scale. Experiments with various dimensionality reduction techniques eventually show the strengths and weaknesses of the proposed scale-independent criteria.", :doc-id "Scale-independent quality criteria for dimensionality reduction. 2010  ,  "}, 16178 #search_api.search_api.Paper{:id 16178, :key "conf/aaai/PanKY08", :title "Transfer Learning via Dimensionality Reduction.", :abstract "Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new dimensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification.", :author (#search_api.search_api.Author{:id 391084, :first-name nil, :last-name nil, :full-name "Sinno Jialin Pan"} #search_api.search_api.Author{:id 319466, :first-name nil, :last-name nil, :full-name "James T. Kwok"} #search_api.search_api.Author{:id 429898, :first-name nil, :last-name nil, :full-name "Qiang Yang"}), :year 2008, :venue "AAAI", :ncit 115, :string "Transfer Learning via Dimensionality Reduction.. Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new dimensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification.", :doc-id "Transfer Learning via Dimensionality Reduction. 2008  ,  ,  "}, 2899123 #search_api.search_api.Paper{:id 2899123, :key "conf/cvpr/Carreira-PerpinanL10", :title "Parametric dimensionality reduction by unsupervised regression.", :abstract nil, :author (#search_api.search_api.Author{:id 1425022, :first-name nil, :last-name nil, :full-name "Miguel Á. Carreira-Perpiñán"} #search_api.search_api.Author{:id 1050233, :first-name nil, :last-name nil, :full-name "Zhengdong Lu"}), :year 2010, :venue "CVPR", :ncit 9, :string "Parametric dimensionality reduction by unsupervised regression.. ", :doc-id "Parametric dimensionality reduction by unsupervised regression. 2010  ,  "}, 1022643 #search_api.search_api.Paper{:id 1022643, :key "journals/neco/BelkinN03", :title "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.", :abstract "One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.", :author (#search_api.search_api.Author{:id 84999, :first-name nil, :last-name nil, :full-name "Mikhail Belkin"} #search_api.search_api.Author{:id 824566, :first-name nil, :last-name nil, :full-name "Partha Niyogi"}), :year 2003, :venue "Neural Computation", :ncit 3017, :string "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation.. One of the central problems in machine learning and pattern recognition is to develop appropriate representations for complex data. We consider the problem of constructing a representation for data lying on a low-dimensional manifold embedded in a high-dimensional space. Drawing on the correspondence between the graph Laplacian, the Laplace Beltrami operator on the manifold, and the connections to the heat equation, we propose a geometrically motivated algorithm for representing the high-dimensional data. The algorithm provides a computationally efficient approach to nonlinear dimensionality reduction that has locality-preserving properties and a natural connection to clustering. Some potential applications and illustrative examples are discussed.", :doc-id "Laplacian Eigenmaps for Dimensionality Reduction and Data Representation. 2003  ,  "}, 27571 #search_api.search_api.Paper{:id 27571, :key "conf/adma/PlastriaBC08", :title "Dimensionality Reduction for Classification.", :abstract "We investigate the effects of dimensionality reduction using different techniques and different dimensions on six two-class data sets with numerical attributes as pre-processing for two classification algorithms. Besides reducing the dimensionality with the use of principal components and linear discriminants, we also introduce four new techniques. After this dimensionality reduction two algorithms are applied. The first algorithm takes advantage of the reduced dimensionality itself while the second one directly exploits the dimensional ranking. We observe that neither a single superior dimensionality reduction technique nor a straightforward way to select the optimal dimension can be identified. On the other hand we show that a good choice of technique and dimension can have a major impact on the classification power, generating classifiers that can rival industry standards. We conclude that dimensionality reduction should not only be used for visualisation or as pre-processing on very high dimensional data, but also as a general pre-processing technique on numerical data to raise the classification power. The difficult choice of both the dimensionality reduction technique and the reduced dimension however, should be directly based on the effects on the classification power.", :author (#search_api.search_api.Author{:id 77009, :first-name nil, :last-name nil, :full-name "Frank Plastria"} #search_api.search_api.Author{:id 687874, :first-name nil, :last-name nil, :full-name "Steven De Bruyne"} #search_api.search_api.Author{:id 913397, :first-name nil, :last-name nil, :full-name "Emilio Carrizosa"}), :year 2008, :venue "ADMA", :ncit 5, :string "Dimensionality Reduction for Classification.. We investigate the effects of dimensionality reduction using different techniques and different dimensions on six two-class data sets with numerical attributes as pre-processing for two classification algorithms. Besides reducing the dimensionality with the use of principal components and linear discriminants, we also introduce four new techniques. After this dimensionality reduction two algorithms are applied. The first algorithm takes advantage of the reduced dimensionality itself while the second one directly exploits the dimensional ranking. We observe that neither a single superior dimensionality reduction technique nor a straightforward way to select the optimal dimension can be identified. On the other hand we show that a good choice of technique and dimension can have a major impact on the classification power, generating classifiers that can rival industry standards. We conclude that dimensionality reduction should not only be used for visualisation or as pre-processing on very high dimensional data, but also as a general pre-processing technique on numerical data to raise the classification power. The difficult choice of both the dimensionality reduction technique and the reduced dimension however, should be directly based on the effects on the classification power.", :doc-id "Dimensionality Reduction for Classification. 2008  ,  ,  "}, 2974868 #search_api.search_api.Paper{:id 2974868, :key "journals/ml/GiraldoLQ11", :title "Foraging theory for dimensionality reduction of clustered data.", :abstract nil, :author (#search_api.search_api.Author{:id 1626388, :first-name nil, :last-name nil, :full-name "Luis Felipe Giraldo"} #search_api.search_api.Author{:id 441484, :first-name nil, :last-name nil, :full-name "Fernando Lozano"} #search_api.search_api.Author{:id 142910, :first-name nil, :last-name nil, :full-name "Nicanor Quijano"}), :year 2011, :venue "Machine Learning", :ncit 5, :string "Foraging theory for dimensionality reduction of clustered data.. ", :doc-id "Foraging theory for dimensionality reduction of clustered data. 2011  ,  ,  "}, 129428 #search_api.search_api.Paper{:id 129428, :key "conf/cvpr/WolfB05", :title "Combining Variable Selection with Dimensionality Reduction.", :abstract "This paper bridges the gap between variable selection methods (e.g., Pearson coefficients, KS test) and dimensionality reduction algorithms (e.g., PCA, LDA). Variable selection algorithms encounter difficulties dealing with highly correlated data, since many features are similar in quality. Dimensionality reduction algorithms tend to combine all variables and cannot select a subset of significant variables. Our approach combines both methodologies by applying variable selection followed by dimensionality reduction. This combination makes sense only when using the same utility function in both stages, which we do. The resulting algorithm benefits from complex features as variable selection algorithms do, and at the same time enjoys the benefits of dimensionality reduction.", :author (#search_api.search_api.Author{:id 1032199, :first-name nil, :last-name nil, :full-name "Lior Wolf"} #search_api.search_api.Author{:id 587909, :first-name nil, :last-name nil, :full-name "Stanley M. Bileschi"}), :year 2005, :venue "CVPR (2)", :ncit 18, :string "Combining Variable Selection with Dimensionality Reduction.. This paper bridges the gap between variable selection methods (e.g., Pearson coefficients, KS test) and dimensionality reduction algorithms (e.g., PCA, LDA). Variable selection algorithms encounter difficulties dealing with highly correlated data, since many features are similar in quality. Dimensionality reduction algorithms tend to combine all variables and cannot select a subset of significant variables. Our approach combines both methodologies by applying variable selection followed by dimensionality reduction. This combination makes sense only when using the same utility function in both stages, which we do. The resulting algorithm benefits from complex features as variable selection algorithms do, and at the same time enjoys the benefits of dimensionality reduction.", :doc-id "Combining Variable Selection with Dimensionality Reduction. 2005  ,  "}, 1249493 #search_api.search_api.Paper{:id 1249493, :key "conf/ijcai/JiY09", :title "Linear Dimensionality Reduction for Multi-label Classification.", :abstract "Dimensionality reduction is an essential step in high-dimensional data analysis. Many dimensionality reduction algorithms have been applied successfully to multi-class and multi-label problems. They are commonly applied as a separate data preprocessing step before classification algorithms. In this paper, we study a joint learning framework in which we perform dimensionality reduction and multi-label classification simultaneously. We show that when the least squares loss is used in classification, this joint learning decouples into two separate components, i.e., dimensionality reduction followed by multi-label classification. This analysis partially justifies the current practice of a separate application of dimensionality reduction for classification problems. We extend our analysis using other loss functions, including the hinge loss and the squared hinge loss. We further extend the formulation to the more general case where the input data for different class labels may differ, overcoming the limitation of traditional dimensionality reduction algorithms. Experiments on benchmark data sets have been conducted to evaluate the proposed joint formulations.", :author (#search_api.search_api.Author{:id 1404867, :first-name nil, :last-name nil, :full-name "Shuiwang Ji"} #search_api.search_api.Author{:id 1406190, :first-name nil, :last-name nil, :full-name "Jieping Ye"}), :year 2009, :venue "IJCAI", :ncit 27, :string "Linear Dimensionality Reduction for Multi-label Classification.. Dimensionality reduction is an essential step in high-dimensional data analysis. Many dimensionality reduction algorithms have been applied successfully to multi-class and multi-label problems. They are commonly applied as a separate data preprocessing step before classification algorithms. In this paper, we study a joint learning framework in which we perform dimensionality reduction and multi-label classification simultaneously. We show that when the least squares loss is used in classification, this joint learning decouples into two separate components, i.e., dimensionality reduction followed by multi-label classification. This analysis partially justifies the current practice of a separate application of dimensionality reduction for classification problems. We extend our analysis using other loss functions, including the hinge loss and the squared hinge loss. We further extend the formulation to the more general case where the input data for different class labels may differ, overcoming the limitation of traditional dimensionality reduction algorithms. Experiments on benchmark data sets have been conducted to evaluate the proposed joint formulations.", :doc-id "Linear Dimensionality Reduction for Multi-label Classification. 2009  ,  "}, 908149 #search_api.search_api.Paper{:id 908149, :key "journals/ijcv/WangA08", :title "A Tensor Approximation Approach to Dimensionality Reduction.", :abstract "Dimensionality reduction has recently been extensively studied for computer vision applications. We present a novel multilinear algebra based approach to reduced dimensionality representation of multidimensional data, such as image ensembles, video sequences and volume data. Before reducing the dimensionality we do not convert it into a vector as is done by traditional dimensionality reduction techniques like PCA. Our approach works directly on the multidimensional form of the data (matrix in 2D and tensor in higher dimensions) to yield what we call a Datum-as-Is representation. This helps exploit spatio-temporal redundancies with less information loss than image-as-vector methods. An efficient rank-R tensor approximation algorithm is presented to approximate higher-order tensors. We show that rank-R tensor approximation using Datum-as-Is representation generalizes many existing approaches that use image-as-matrix representation, such as generalized low rank approximation of matrices (GLRAM) (Ye, Y. in Mach. Learn. 61:167---191, 2005), rank-one decomposition of matrices (RODM) (Shashua, A., Levin, A. in CVPR'01: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition, p. 42, 2001) and rank-one decomposition of tensors (RODT) (Wang, H., Ahuja, N. in ICPR '04: ICPR '04: Proceedings of the 17th international conference on pattern recognition (ICPR'04), vol. 1, pp. 44---47, 2004). Our approach yields the most compact data representation among all known image-as-matrix methods. In addition, we propose another rank-R tensor approximation algorithm based on slice projection of third-order tensors, which needs fewer iterations for convergence for the important special case of 2D image ensembles, e.g., video. We evaluated the performance of our approach vs. other approaches on a number of datasets with the following two main results. First, for a fixed compression ratio, the proposed algorithm yields the best representation of image ensembles visually as well as in the least squares sense. Second, proposed representation gives the best performance for object classification.", :author (#search_api.search_api.Author{:id 1535787, :first-name nil, :last-name nil, :full-name "Hongcheng Wang"} #search_api.search_api.Author{:id 467434, :first-name nil, :last-name nil, :full-name "Narendra Ahuja"}), :year 2008, :venue "International Journal of Computer Vision", :ncit 41, :string "A Tensor Approximation Approach to Dimensionality Reduction.. Dimensionality reduction has recently been extensively studied for computer vision applications. We present a novel multilinear algebra based approach to reduced dimensionality representation of multidimensional data, such as image ensembles, video sequences and volume data. Before reducing the dimensionality we do not convert it into a vector as is done by traditional dimensionality reduction techniques like PCA. Our approach works directly on the multidimensional form of the data (matrix in 2D and tensor in higher dimensions) to yield what we call a Datum-as-Is representation. This helps exploit spatio-temporal redundancies with less information loss than image-as-vector methods. An efficient rank-R tensor approximation algorithm is presented to approximate higher-order tensors. We show that rank-R tensor approximation using Datum-as-Is representation generalizes many existing approaches that use image-as-matrix representation, such as generalized low rank approximation of matrices (GLRAM) (Ye, Y. in Mach. Learn. 61:167---191, 2005), rank-one decomposition of matrices (RODM) (Shashua, A., Levin, A. in CVPR'01: Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition, p. 42, 2001) and rank-one decomposition of tensors (RODT) (Wang, H., Ahuja, N. in ICPR '04: ICPR '04: Proceedings of the 17th international conference on pattern recognition (ICPR'04), vol. 1, pp. 44---47, 2004). Our approach yields the most compact data representation among all known image-as-matrix methods. In addition, we propose another rank-R tensor approximation algorithm based on slice projection of third-order tensors, which needs fewer iterations for convergence for the important special case of 2D image ensembles, e.g., video. We evaluated the performance of our approach vs. other approaches on a number of datasets with the following two main results. First, for a fixed compression ratio, the proposed algorithm yields the best representation of image ensembles visually as well as in the least squares sense. Second, proposed representation gives the best performance for object classification.", :doc-id "A Tensor Approximation Approach to Dimensionality Reduction. 2008  ,  "}, 1032181 #search_api.search_api.Paper{:id 1032181, :key "journals/pami/LawJ06", :title "Incremental Nonlinear Dimensionality Reduction by Manifold Learning.", :abstract "Understanding the structure of multidimensional patterns, especially in unsupervised cases, is of fundamental importance in data mining, pattern recognition, and machine learning. Several algorithms have been proposed to analyze the structure of high-dimensional data based on the notion of manifold learning. These algorithms have been used to extract the intrinsic characteristics of different types of high-dimensional data by performing nonlinear dimensionality reduction. Most of these algorithms operate in a \"batch” mode and cannot be efficiently applied when data are collected sequentially. In this paper, we describe an incremental version of ISOMAP, one of the key manifold learning algorithms. Our experiments on synthetic data as well as real world images demonstrate that our modified algorithm can maintain an accurate low-dimensional representation of the data in an efficient manner.", :author (#search_api.search_api.Author{:id 856856, :first-name nil, :last-name nil, :full-name "Martin H. C. Law"} #search_api.search_api.Author{:id 324696, :first-name nil, :last-name nil, :full-name "Anil K. Jain"}), :year 2006, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 132, :string "Incremental Nonlinear Dimensionality Reduction by Manifold Learning.. Understanding the structure of multidimensional patterns, especially in unsupervised cases, is of fundamental importance in data mining, pattern recognition, and machine learning. Several algorithms have been proposed to analyze the structure of high-dimensional data based on the notion of manifold learning. These algorithms have been used to extract the intrinsic characteristics of different types of high-dimensional data by performing nonlinear dimensionality reduction. Most of these algorithms operate in a \"batch” mode and cannot be efficiently applied when data are collected sequentially. In this paper, we describe an incremental version of ISOMAP, one of the key manifold learning algorithms. Our experiments on synthetic data as well as real world images demonstrate that our modified algorithm can maintain an accurate low-dimensional representation of the data in an efficient manner.", :doc-id "Incremental Nonlinear Dimensionality Reduction by Manifold Learning. 2006  ,  "}, 1032279 #search_api.search_api.Paper{:id 1032279, :key "journals/pami/LotlikarK00", :title "Fractional-Step Dimensionality Reduction.", :abstract "Linear projections for dimensionality reduction, computed using linear discriminant analysis (LDA), are commonly based on optimization of certain separability criteria in the output space. The resulting optimization problem is linear, but these separability criteria are not directly related to the classification accuracy in the output space. Consequently, a trial and error procedure has to be invoked, experimenting with different separability criteria that differ in the weighting function used and selecting the one that performed best on the training set. Often, even the best weighting function among the trial choices results in poor classification of data in the subspace. In this short paper, we introduce the concept of fractional dimensionality and develop an incremental procedure, called the fractional-step LDA (F-LDA) to reduce the dimensionality in fractional steps. The F-LDA algorithm is more robust to the selection of weighting function and for any given weighting function, it finds a subspace in which the classification accuracy is higher than that obtained using LDA.", :author (#search_api.search_api.Author{:id 131666, :first-name nil, :last-name nil, :full-name "Rohit Lotlikar"} #search_api.search_api.Author{:id 1533262, :first-name nil, :last-name nil, :full-name "Ravi Kothari"}), :year 2000, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 184, :string "Fractional-Step Dimensionality Reduction.. Linear projections for dimensionality reduction, computed using linear discriminant analysis (LDA), are commonly based on optimization of certain separability criteria in the output space. The resulting optimization problem is linear, but these separability criteria are not directly related to the classification accuracy in the output space. Consequently, a trial and error procedure has to be invoked, experimenting with different separability criteria that differ in the weighting function used and selecting the one that performed best on the training set. Often, even the best weighting function among the trial choices results in poor classification of data in the subspace. In this short paper, we introduce the concept of fractional dimensionality and develop an incremental procedure, called the fractional-step LDA (F-LDA) to reduce the dimensionality in fractional steps. The F-LDA algorithm is more robust to the selection of weighting function and for any given weighting function, it finds a subspace in which the classification accuracy is higher than that obtained using LDA.", :doc-id "Fractional-Step Dimensionality Reduction. 2000  ,  "}, 336023 #search_api.search_api.Paper{:id 336023, :key "conf/icml/MosciRV07", :title "Dimensionality reduction and generalization.", :abstract "In this paper we investigate the regularization property of Kernel Principal Component Analysis (KPCA), by studying its application as a preprocessing step to supervised learning problems. We show that performing KPCA and then ordinary least squares on the projected data, a procedure known as kernel principal component regression (KPCR), is equivalent to spectral cut-off regularization, the regularization parameter being exactly the number of principal components to keep. Using probabilistic estimates for integral operators we can prove error estimates for KPCR and propose a parameter choice procedure allowing to prove consistency of the algorithm.", :author (#search_api.search_api.Author{:id 198832, :first-name nil, :last-name nil, :full-name "Sofia Mosci"} #search_api.search_api.Author{:id 58790, :first-name nil, :last-name nil, :full-name "Lorenzo Rosasco"} #search_api.search_api.Author{:id 601093, :first-name nil, :last-name nil, :full-name "Alessandro Verri"}), :year 2007, :venue "ICML", :ncit 12, :string "Dimensionality reduction and generalization.. In this paper we investigate the regularization property of Kernel Principal Component Analysis (KPCA), by studying its application as a preprocessing step to supervised learning problems. We show that performing KPCA and then ordinary least squares on the projected data, a procedure known as kernel principal component regression (KPCR), is equivalent to spectral cut-off regularization, the regularization parameter being exactly the number of principal components to keep. Using probabilistic estimates for integral operators we can prove error estimates for KPCR and propose a parameter choice procedure allowing to prove consistency of the algorithm.", :doc-id "Dimensionality reduction and generalization. 2007  ,  ,  "}, 1033879 #search_api.search_api.Paper{:id 1033879, :key "journals/pami/Sanguinetti08", :title "Dimensionality Reduction of Clustered Data Sets.", :abstract "We present a novel probabilistic latent variable model to perform linear dimensionality reduction on data sets which contain clusters. We prove that the maximum likelihood solution of the model is an unsupervised generalisation of linear discriminant analysis. This provides a completely new approach to one of the most established and widely used classification algorithms. The performance of the model is then demonstrated on a number of real and artificial data sets.", :author (#search_api.search_api.Author{:id 1164342, :first-name nil, :last-name nil, :full-name "Guido Sanguinetti"}), :year 2008, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 24, :string "Dimensionality Reduction of Clustered Data Sets.. We present a novel probabilistic latent variable model to perform linear dimensionality reduction on data sets which contain clusters. We prove that the maximum likelihood solution of the model is an unsupervised generalisation of linear discriminant analysis. This provides a completely new approach to one of the most established and widely used classification algorithms. The performance of the model is then demonstrated on a number of real and artificial data sets.", :doc-id "Dimensionality Reduction of Clustered Data Sets. 2008  "}, 3440343 #search_api.search_api.Paper{:id 3440343, :key "conf/ijcnn/GashlerM11", :title "Temporal nonlinear dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 1539811, :first-name nil, :last-name nil, :full-name "Michael Gashler"} #search_api.search_api.Author{:id 930639, :first-name nil, :last-name nil, :full-name "Tony R. Martinez"}), :year 2011, :venue "IJCNN", :ncit 2, :string "Temporal nonlinear dimensionality reduction.. ", :doc-id "Temporal nonlinear dimensionality reduction. 2011  ,  "}, 3517303 #search_api.search_api.Paper{:id 3517303, :key "conf/cvpr/TimofteG12", :title "Iterative Nearest Neighbors for classification and dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 1589075, :first-name nil, :last-name nil, :full-name "Radu Timofte"} #search_api.search_api.Author{:id 1340319, :first-name nil, :last-name nil, :full-name "Luc J. Van Gool"}), :year 2012, :venue "CVPR", :ncit 6, :string "Iterative Nearest Neighbors for classification and dimensionality reduction.. ", :doc-id "Iterative Nearest Neighbors for classification and dimensionality reduction. 2012  ,  "}, 3215609 #search_api.search_api.Paper{:id 3215609, :key "conf/cidm/BunteBH11", :title "Dimensionality reduction mappings.", :abstract nil, :author (#search_api.search_api.Author{:id 1150674, :first-name nil, :last-name nil, :full-name "Kerstin Bunte"} #search_api.search_api.Author{:id 1194904, :first-name nil, :last-name nil, :full-name "Michael Biehl"} #search_api.search_api.Author{:id 477525, :first-name nil, :last-name nil, :full-name "Barbara Hammer"}), :year 2011, :venue "CIDM", :ncit 3, :string "Dimensionality reduction mappings.. ", :doc-id "Dimensionality reduction mappings. 2011  ,  ,  "}, 3730681 #search_api.search_api.Paper{:id 3730681, :key "journals/ijon/LiangXZ13", :title "Normalized discriminant analysis for dimensionality reduction.", :abstract nil, :author (#search_api.search_api.Author{:id 304579, :first-name nil, :last-name nil, :full-name "Zhizheng Liang"} #search_api.search_api.Author{:id 276361, :first-name nil, :last-name nil, :full-name "Shixiong Xia"} #search_api.search_api.Author{:id 1486662, :first-name nil, :last-name nil, :full-name "Yong Zhou"}), :year 2013, :venue "Neurocomputing", :ncit 0, :string "Normalized discriminant analysis for dimensionality reduction.. ", :doc-id "Normalized discriminant analysis for dimensionality reduction. 2013  ,  ,  "}, 2864505 #search_api.search_api.Paper{:id 2864505, :key "journals/jmlr/VennaPNAK10", :title "Information Retrieval Perspective to Nonlinear Dimensionality Reduction for Data Visualization.", :abstract "Nonlinear dimensionality reduction methods are often used to visualize high-dimensional data, although the existing methods have been designed for other related tasks such as manifold learning. It has been difficult to assess the quality of visualizations since the task has not been well-defined. We give a rigorous definition for a specific visualization task, resulting in quantifiable goodness measures and new visualization methods. The task is information retrieval given the visualization: to find similar data based on the similarities shown on the display. The fundamental tradeoff between precision and recall of information retrieval can then be quantified in visualizations as well. The user needs to give the relative cost of missing similar points vs. retrieving dissimilar points, after which the total cost can be measured. We then introduce a new method NeRV (neighbor retrieval visualizer) which produces an optimal visualization by minimizing the cost. We further derive a variant for supervised visualization; class information is taken rigorously into account when computing the similarity relationships. We show empirically that the unsupervised version outperforms existing unsupervised dimensionality reduction methods in the visualization task, and the supervised version outperforms existing supervised methods. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player", :author (#search_api.search_api.Author{:id 315617, :first-name nil, :last-name nil, :full-name "Jarkko Venna"} #search_api.search_api.Author{:id 988116, :first-name nil, :last-name nil, :full-name "Jaakko Peltonen"} #search_api.search_api.Author{:id 1102214, :first-name nil, :last-name nil, :full-name "Kristian Nybo"} #search_api.search_api.Author{:id 678977, :first-name nil, :last-name nil, :full-name "Helena Aidos"} #search_api.search_api.Author{:id 1441437, :first-name nil, :last-name nil, :full-name "Samuel Kaski"}), :year 2010, :venue "Journal of Machine Learning Research", :ncit 58, :string "Information Retrieval Perspective to Nonlinear Dimensionality Reduction for Data Visualization.. Nonlinear dimensionality reduction methods are often used to visualize high-dimensional data, although the existing methods have been designed for other related tasks such as manifold learning. It has been difficult to assess the quality of visualizations since the task has not been well-defined. We give a rigorous definition for a specific visualization task, resulting in quantifiable goodness measures and new visualization methods. The task is information retrieval given the visualization: to find similar data based on the similarities shown on the display. The fundamental tradeoff between precision and recall of information retrieval can then be quantified in visualizations as well. The user needs to give the relative cost of missing similar points vs. retrieving dissimilar points, after which the total cost can be measured. We then introduce a new method NeRV (neighbor retrieval visualizer) which produces an optimal visualization by minimizing the cost. We further derive a variant for supervised visualization; class information is taken rigorously into account when computing the similarity relationships. We show empirically that the unsupervised version outperforms existing unsupervised dimensionality reduction methods in the visualization task, and the supervised version outperforms existing supervised methods. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player", :doc-id "Information Retrieval Perspective to Nonlinear Dimensionality Reduction for Data Visualization. 2010  ,  ,  ,  ,  "}, 3270105 #search_api.search_api.Paper{:id 3270105, :key "journals/paa/AverbuchRSZ12", :title "Dimensionality reduction for detection of moving vehicles.", :abstract nil, :author (#search_api.search_api.Author{:id 975287, :first-name nil, :last-name nil, :full-name "Amir Averbuch"} #search_api.search_api.Author{:id 1234015, :first-name nil, :last-name nil, :full-name "N. Rabin"} #search_api.search_api.Author{:id 876495, :first-name nil, :last-name nil, :full-name "Alon Schclar"} #search_api.search_api.Author{:id 133730, :first-name nil, :last-name nil, :full-name "Valery A. Zheludev"}), :year 2012, :venue "Pattern Anal. Appl.", :ncit 1, :string "Dimensionality reduction for detection of moving vehicles.. ", :doc-id "Dimensionality reduction for detection of moving vehicles. 2012  ,  ,  ,  "}, 1138266 #search_api.search_api.Paper{:id 1138266, :key "journals/vldb/ShenZZ07", :title "An adaptive and dynamic dimensionality reduction method for high-dimensional indexing.", :abstract "The notorious &#x201c;dimensionality curse&#x201d; is a well-known phenomenon for any multi-dimensional indexes attempting to scale up to high dimensions. One well-known approach to overcome degradation in performance with respect to increasing dimensions is to reduce the dimensionality of the original dataset before constructing the index. However, identifying the correlation among the dimensions and effectively reducing them are challenging tasks. In this paper, we present an adaptive Multi-level Mahalanobis-based Dimensionality Reduction (MMDR) technique for high-dimensional indexing. Our MMDR technique has four notable features compared to existing methods. First, it discovers elliptical clusters for more effective dimensionality reduction by using only the low-dimensional subspaces. Second, data points in the different axis systems are indexed using a single B+-tree. Third, our technique is highly scalable in terms of data size and dimension. Finally, it is also dynamic and adaptive to insertions. An extensive performance study was conducted using both real and synthetic datasets, and the results show that our technique not only achieves higher precision, but also enables queries to be processed efficiently.", :author (#search_api.search_api.Author{:id 1347203, :first-name nil, :last-name nil, :full-name "Heng Tao Shen"} #search_api.search_api.Author{:id 229589, :first-name nil, :last-name nil, :full-name "Xiaofang Zhou"} #search_api.search_api.Author{:id 1304062, :first-name nil, :last-name nil, :full-name "Aoying Zhou"}), :year 2007, :venue "VLDB J.", :ncit 26, :string "An adaptive and dynamic dimensionality reduction method for high-dimensional indexing.. The notorious &#x201c;dimensionality curse&#x201d; is a well-known phenomenon for any multi-dimensional indexes attempting to scale up to high dimensions. One well-known approach to overcome degradation in performance with respect to increasing dimensions is to reduce the dimensionality of the original dataset before constructing the index. However, identifying the correlation among the dimensions and effectively reducing them are challenging tasks. In this paper, we present an adaptive Multi-level Mahalanobis-based Dimensionality Reduction (MMDR) technique for high-dimensional indexing. Our MMDR technique has four notable features compared to existing methods. First, it discovers elliptical clusters for more effective dimensionality reduction by using only the low-dimensional subspaces. Second, data points in the different axis systems are indexed using a single B+-tree. Third, our technique is highly scalable in terms of data size and dimension. Finally, it is also dynamic and adaptive to insertions. An extensive performance study was conducted using both real and synthetic datasets, and the results show that our technique not only achieves higher precision, but also enables queries to be processed efficiently.", :doc-id "An adaptive and dynamic dimensionality reduction method for high-dimensional indexing. 2007  ,  ,  "}, 595962 #search_api.search_api.Paper{:id 595962, :key "conf/sigir/HuangSZSR07", :title "Dimensionality reduction for dimension-specific search.", :abstract "Dimensionality reduction plays an important role in efficient similarity search, which is often based on k-nearest neighbor (k-NN) queries over a high-dimensional feature space. In this paper, we introduce a novel type of k-NN query, namely conditional k-NN (ck-NN), which considers dimension-specific constraint in addition to the inter-point distances. However, existing dimensionality reduction methods are not applicable to this new type of queries. We propose a novel Mean-Std (standard deviation) guided Dimensionality Reduction (MSDR) to support a pruning based efficient ck-NN query processing strategy. Our preliminary experimental results on 3D protein structure data demonstrate that the MSDR method is promising.", :author (#search_api.search_api.Author{:id 950608, :first-name nil, :last-name nil, :full-name "Zi Huang"} #search_api.search_api.Author{:id 1347203, :first-name nil, :last-name nil, :full-name "Heng Tao Shen"} #search_api.search_api.Author{:id 229589, :first-name nil, :last-name nil, :full-name "Xiaofang Zhou"} #search_api.search_api.Author{:id 1001977, :first-name nil, :last-name nil, :full-name "Dawei Song"} #search_api.search_api.Author{:id 920041, :first-name nil, :last-name nil, :full-name "Stefan M. Rüger"}), :year 2007, :venue "SIGIR", :ncit 0, :string "Dimensionality reduction for dimension-specific search.. Dimensionality reduction plays an important role in efficient similarity search, which is often based on k-nearest neighbor (k-NN) queries over a high-dimensional feature space. In this paper, we introduce a novel type of k-NN query, namely conditional k-NN (ck-NN), which considers dimension-specific constraint in addition to the inter-point distances. However, existing dimensionality reduction methods are not applicable to this new type of queries. We propose a novel Mean-Std (standard deviation) guided Dimensionality Reduction (MSDR) to support a pruning based efficient ck-NN query processing strategy. Our preliminary experimental results on 3D protein structure data demonstrate that the MSDR method is promising.", :doc-id "Dimensionality reduction for dimension-specific search. 2007  ,  ,  ,  ,  "}, 1281915 #search_api.search_api.Paper{:id 1281915, :key "journals/tkde/XiangNZZ09", :title "Nonlinear Dimensionality Reduction with Local Spline Embedding.", :abstract "This paper presents a new algorithm for Nonlinear Dimensionality Reduction (NLDR). Our algorithm is developed under the conceptual framework of compatible mapping. Each such mapping is a compound of a tangent space projection and a group of splines. Tangent space projection is estimated at each data point on the manifold, through which the data point itself and its neighbors are represented in tangent space with local coordinates. Splines are then constructed to guarantee that each of the local coordinates can be mapped to its own single global coordinate with respect to the underlying manifold. Thus, the compatibility between local alignments is ensured. In such a work setting, we develop an optimization framework based on reconstruction error analysis, which can yield a global optimum. The proposed algorithm is also extended to embed out of samples via spline interpolation. Experiments on toy data sets and real-world data sets illustrate the validity of our method.", :author (#search_api.search_api.Author{:id 564264, :first-name nil, :last-name nil, :full-name "Shiming Xiang"} #search_api.search_api.Author{:id 1512909, :first-name nil, :last-name nil, :full-name "Feiping Nie"} #search_api.search_api.Author{:id 227858, :first-name nil, :last-name nil, :full-name "Changshui Zhang"} #search_api.search_api.Author{:id 1025151, :first-name nil, :last-name nil, :full-name "Chunxia Zhang"}), :year 2009, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 37, :string "Nonlinear Dimensionality Reduction with Local Spline Embedding.. This paper presents a new algorithm for Nonlinear Dimensionality Reduction (NLDR). Our algorithm is developed under the conceptual framework of compatible mapping. Each such mapping is a compound of a tangent space projection and a group of splines. Tangent space projection is estimated at each data point on the manifold, through which the data point itself and its neighbors are represented in tangent space with local coordinates. Splines are then constructed to guarantee that each of the local coordinates can be mapped to its own single global coordinate with respect to the underlying manifold. Thus, the compatibility between local alignments is ensured. In such a work setting, we develop an optimization framework based on reconstruction error analysis, which can yield a global optimum. The proposed algorithm is also extended to embed out of samples via spline interpolation. Experiments on toy data sets and real-world data sets illustrate the validity of our method.", :doc-id "Nonlinear Dimensionality Reduction with Local Spline Embedding. 2009  ,  ,  ,  "}, 3715003 #search_api.search_api.Paper{:id 3715003, :key "journals/datamine/LehrmannHPPN13", :title "Visualizing dimensionality reduction of systems biology data.", :abstract nil, :author (#search_api.search_api.Author{:id 14423387, :first-name nil, :last-name nil, :full-name "Andreas Lehrmann"} #search_api.search_api.Author{:id 631753, :first-name nil, :last-name nil, :full-name "Michael Huber"} #search_api.search_api.Author{:id 1516938, :first-name nil, :last-name nil, :full-name "Aydin Can Polatkan"} #search_api.search_api.Author{:id 1546292, :first-name nil, :last-name nil, :full-name "Albert Pritzkau"} #search_api.search_api.Author{:id 839927, :first-name nil, :last-name nil, :full-name "Kay Nieselt"}), :year 2013, :venue "Data Min. Knowl. Discov.", :ncit 0, :string "Visualizing dimensionality reduction of systems biology data.. ", :doc-id "Visualizing dimensionality reduction of systems biology data. 2013  ,  ,  ,  ,  "}, 3395900 #search_api.search_api.Paper{:id 3395900, :key "journals/ivc/HuangY12", :title "On nonlinear dimensionality reduction for face recognition.", :abstract nil, :author (#search_api.search_api.Author{:id 389008, :first-name nil, :last-name nil, :full-name "Weilin Huang"} #search_api.search_api.Author{:id 1095764, :first-name nil, :last-name nil, :full-name "Hujun Yin"}), :year 2012, :venue "Image Vision Comput.", :ncit 1, :string "On nonlinear dimensionality reduction for face recognition.. ", :doc-id "On nonlinear dimensionality reduction for face recognition. 2012  ,  "}, 3481372 #search_api.search_api.Paper{:id 3481372, :key "journals/mp/AravkinFHL12", :title "Robust inversion, dimensionality reduction, and randomized sampling.", :abstract nil, :author (#search_api.search_api.Author{:id 14162778, :first-name nil, :last-name nil, :full-name "Aleksandr Aravkin"} #search_api.search_api.Author{:id 120651, :first-name nil, :last-name nil, :full-name "Michael P. Friedlander"} #search_api.search_api.Author{:id 367639, :first-name nil, :last-name nil, :full-name "Felix J. Herrmann"} #search_api.search_api.Author{:id 1607334, :first-name nil, :last-name nil, :full-name "Tristan van Leeuwen"}), :year 2012, :venue "Math. Program.", :ncit 4, :string "Robust inversion, dimensionality reduction, and randomized sampling.. ", :doc-id "Robust inversion, dimensionality reduction, and randomized sampling. 2012  ,  ,  ,  "}, 3245949 #search_api.search_api.Paper{:id 3245949, :key "journals/ijrr/DalibardL11", :title "Linear dimensionality reduction in random motion planning.", :abstract nil, :author (#search_api.search_api.Author{:id 1561099, :first-name nil, :last-name nil, :full-name "Sébastien Dalibard"} #search_api.search_api.Author{:id 678775, :first-name nil, :last-name nil, :full-name "Jean-Paul Laumond"}), :year 2011, :venue "I. J. Robotic Res.", :ncit 4, :string "Linear dimensionality reduction in random motion planning.. ", :doc-id "Linear dimensionality reduction in random motion planning. 2011  ,  "}, 3618142 #search_api.search_api.Paper{:id 3618142, :key "journals/datamine/LeeGK13", :title "Dependence maps, a dimensionality reduction with dependence distance for high-dimensional data.", :abstract nil, :author (#search_api.search_api.Author{:id 137147, :first-name nil, :last-name nil, :full-name "Kichun Lee"} #search_api.search_api.Author{:id 613134, :first-name nil, :last-name nil, :full-name "Alexander Gray"} #search_api.search_api.Author{:id 278622, :first-name nil, :last-name nil, :full-name "Heeyoung Kim"}), :year 2013, :venue "Data Min. Knowl. Discov.", :ncit 0, :string "Dependence maps, a dimensionality reduction with dependence distance for high-dimensional data.. ", :doc-id "Dependence maps, a dimensionality reduction with dependence distance for high-dimensional data. 2013  ,  ,  "}, 130526 #search_api.search_api.Paper{:id 130526, :key "conf/cvpr/Carreira-PerpinanL08", :title "Dimensionality reduction by unsupervised regression.", :abstract nil, :author (#search_api.search_api.Author{:id 966826, :first-name nil, :last-name nil, :full-name "Miguel Á. Carreira-Perpiñán"} #search_api.search_api.Author{:id 1050233, :first-name nil, :last-name nil, :full-name "Zhengdong Lu"}), :year 2008, :venue "CVPR", :ncit 9, :string "Dimensionality reduction by unsupervised regression.. ", :doc-id "Dimensionality reduction by unsupervised regression. 2008  ,  "}, 542207 #search_api.search_api.Paper{:id 542207, :key "conf/pkdd/WangSZ08", :title "Transferred Dimensionality Reduction.", :abstract "Dimensionality reduction is one of the widely used techniques for data analysis. However, it is often hard to get a demanded low-dimensional representation with only the unlabeled data, especially for the discriminative task. In this paper, we put forward a novel problem of Transferred Dimensionality Reduction, which is to do unsupervised discriminative dimensionality reduction with the help of related prior knowledge from other classes in the same type of concept. We propose an algorithm named Transferred Discriminative Analysis to tackle this problem. It uses clustering to generate class labels for the target unlabeled data, and use dimensionality reduction for them joint with prior labeled data to do subspace selection. This two steps run adaptively to find a better discriminative subspace, and get better clustering results simultaneously. The experimental results on both constrained and unconstrained face recognition demonstrate significant improvements of our algorithm over the state-of-the-art methods.", :author (#search_api.search_api.Author{:id 1361000, :first-name nil, :last-name nil, :full-name "Zheng Wang"} #search_api.search_api.Author{:id 1243285, :first-name nil, :last-name nil, :full-name "Yangqiu Song"} #search_api.search_api.Author{:id 227858, :first-name nil, :last-name nil, :full-name "Changshui Zhang"}), :year 2008, :venue "ECML/PKDD (2)", :ncit 37, :string "Transferred Dimensionality Reduction.. Dimensionality reduction is one of the widely used techniques for data analysis. However, it is often hard to get a demanded low-dimensional representation with only the unlabeled data, especially for the discriminative task. In this paper, we put forward a novel problem of Transferred Dimensionality Reduction, which is to do unsupervised discriminative dimensionality reduction with the help of related prior knowledge from other classes in the same type of concept. We propose an algorithm named Transferred Discriminative Analysis to tackle this problem. It uses clustering to generate class labels for the target unlabeled data, and use dimensionality reduction for them joint with prior labeled data to do subspace selection. This two steps run adaptively to find a better discriminative subspace, and get better clustering results simultaneously. The experimental results on both constrained and unconstrained face recognition demonstrate significant improvements of our algorithm over the state-of-the-art methods.", :doc-id "Transferred Dimensionality Reduction. 2008  ,  ,  "}}}