#topic_maps.core.TopicMap{:topic-graph #graphs.core.Digraph{:nodes #{{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} {:id 1223322, :title "NP-complete problems", :type :wiki-api.core/category} {:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} {:id 2688181, :title "Reality", :type :wiki-api.core/category} {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 745820, :title "DNA", :type :wiki-api.core/category} {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} {:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} {:id 787876, :title "Computational linguistics", :type :wiki-api.core/category} {:id 24059390, :title "Markov models", :type :wiki-api.core/category} {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 3367631, :title "Neurophysiology", :type :wiki-api.core/category} {:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} {:id 744360, :title "Networks", :type :wiki-api.core/category} {:id 1609358, :title "Latin logical phrases", :type :wiki-api.core/category} {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} {:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 1650642, :title "Economics models", :type :wiki-api.core/category} {:id 1158544, :title "Exponentials", :type :wiki-api.core/category} {:id 1609357, :title "Latin philosophical phrases", :type :wiki-api.core/category} {:id 746340, :title "Gene expression", :type :wiki-api.core/category} {:id 4244958, :title "Electrophysiology", :type :wiki-api.core/category} {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 34989583, :title "Term logic", :type :wiki-api.core/category} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 25063012, :title "Concepts in epistemology", :type :wiki-api.core/category} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 30982373, :title "Missing data", :type :wiki-api.core/category} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 31362245, :title "Electrodiagnosis", :type :wiki-api.core/category} {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 23968676, :title "Analytic geometry", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} {:id 691898, :title "Graph theory", :type :wiki-api.core/category} {:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} {:id 699287, :title "Graph algorithms", :type :wiki-api.core/category} {:id 21310691, :title "Statistical forecasting", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 339174, :title "Exponential family", :type :wiki-api.core/article} {:id 16989227, :title "Data", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 37415391, :title "A priori", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 30636687, :title "Network analysis", :type :wiki-api.core/category} {:id 6534870, :title "Statistical laws", :type :wiki-api.core/category} {:id 35791326, :title "Subjective experience", :type :wiki-api.core/category} {:id 17768567, :title "Systems of probability distributions", :type :wiki-api.core/category} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 31614277, :title "Statistical intervals", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 716309, :title "Cartography", :type :wiki-api.core/category} {:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 2664243, :title "Rationalism", :type :wiki-api.core/category} {:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} {:id 10699378, :title "Process management", :type :wiki-api.core/category} {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} {:id 4594748, :title "Computational problems", :type :wiki-api.core/category} {:id 563854, :title "Global optimization", :type :wiki-api.core/article} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 17766079, :title "Random graphs", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 1063460, :title "Philosophical logic", :type :wiki-api.core/category} {:id 29359268, :title "Point estimation performance", :type :wiki-api.core/category} {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} {:id 998678, :title "Surveillance", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 4222755, :title "Neurotechnology", :type :wiki-api.core/category} {:id 11056269, :title "Multivariable calculus", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 35896842, :title "Brain–computer interfacing", :type :wiki-api.core/category} {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} {:id 21067529, :title "Outlines", :type :wiki-api.core/category} {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} {:id 3142995, :title "Empiricism", :type :wiki-api.core/category} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 909365, :title "Functional languages", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} {:id 1385393, :title "Long tail", :type :wiki-api.core/article} {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 3966723, :title "Kantianism", :type :wiki-api.core/category} {:id 2210772, :title "Continuous distributions", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category} {:id 25685, :title "Random variable", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article} {:id 18112594, :title "Tails of probability distributions", :type :wiki-api.core/category} {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} {:id 923167, :title "Length", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category} {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 4149155, :title "Psephology", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category} {:id 2299740, :title "Business terms", :type :wiki-api.core/category} {:id 1532663, :title "Artificial intelligence applications", :type :wiki-api.core/category} {:id 2210781, :title "Discrete distributions", :type :wiki-api.core/category} {:id 15932036, :title "Vectors", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category} {:id 1013715, :title "Bilinear forms", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 797088, :title "Computer vision", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 35092769, :title "Conceptual distinctions", :type :wiki-api.core/category} {:id 3314991, :title "Bias", :type :wiki-api.core/category} {:id 33793046, :title "Transformation (function)", :type :wiki-api.core/category} {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} {:id 8525467, :title "Pointing-device text input", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category} {:id 1557538, :title "Research methods", :type :wiki-api.core/category} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 434897, :title "Hough transform", :type :wiki-api.core/article} {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} {:id 11637786, :title "Internet marketing", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 25346631, :title "Computational problems in graph theory", :type :wiki-api.core/category} {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} {:id 5774898, :title "Free statistical software", :type :wiki-api.core/category} {:id 22712867, :title "Justification", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category} {:id 1009209, :title "Information", :type :wiki-api.core/category} {:id 693800, :title "Geography", :type :wiki-api.core/category} {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} {:id 700292, :title "Scientific method", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} {:id 364002, :title "Hill climbing", :type :wiki-api.core/article} {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} {:id 690777, :title "Linear algebra", :type :wiki-api.core/category} {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} {:id 11487293, :title "Applied probability", :type :wiki-api.core/category} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} {:id 21917434, :title "Information Age", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} {:id 697516, :title "Metric geometry", :type :wiki-api.core/category} {:id 703162, :title "Statistical software", :type :wiki-api.core/category} {:id 751362, :title "Face recognition", :type :wiki-api.core/category} {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 14426697, :title "Market research", :type :wiki-api.core/category} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category} {:id 35356667, :title "Hamiltonian paths and cycles", :type :wiki-api.core/category} {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} {:id 821959, :title "Matrices", :type :wiki-api.core/category} {:id 31120608, :title "Psychiatric assessment", :type :wiki-api.core/category} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} {:id 9272793, :title "Computational statistics", :type :wiki-api.core/category} {:id 427282, :title "Mutual information", :type :wiki-api.core/article} {:id 951835, :title "Computer data", :type :wiki-api.core/category} {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article} {:id 157093, :title "Dot product", :type :wiki-api.core/article} {:id 32611713, :title "Emerging technologies", :type :wiki-api.core/category} {:id 22100652, :title "Empirical process", :type :wiki-api.core/category} {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article} {:id 13167332, :title "Sources of knowledge", :type :wiki-api.core/category} {:id 29526090, :title "Iterative methods", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, :in-map {{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} #{}, {:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 11056269, :title "Multivariable calculus", :type :wiki-api.core/category}}, {:id 1223322, :title "NP-complete problems", :type :wiki-api.core/category} #{{:id 4594748, :title "Computational problems", :type :wiki-api.core/category}}, {:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 2688181, :title "Reality", :type :wiki-api.core/category} #{}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 745820, :title "DNA", :type :wiki-api.core/category} #{}, {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} #{}, {:id 787876, :title "Computational linguistics", :type :wiki-api.core/category} #{}, {:id 24059390, :title "Markov models", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} #{}, {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} #{{:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 21310691, :title "Statistical forecasting", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category}}, {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 29526090, :title "Iterative methods", :type :wiki-api.core/category}}, {:id 3367631, :title "Neurophysiology", :type :wiki-api.core/category} #{}, {:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} #{}, {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} #{}, {:id 744360, :title "Networks", :type :wiki-api.core/category} #{}, {:id 1609358, :title "Latin logical phrases", :type :wiki-api.core/category} #{{:id 1609357, :title "Latin philosophical phrases", :type :wiki-api.core/category}}, {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} #{{:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 22100652, :title "Empirical process", :type :wiki-api.core/category}}, {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} #{{:id 3367631, :title "Neurophysiology", :type :wiki-api.core/category} {:id 4244958, :title "Electrophysiology", :type :wiki-api.core/category} {:id 31362245, :title "Electrodiagnosis", :type :wiki-api.core/category} {:id 35896842, :title "Brain–computer interfacing", :type :wiki-api.core/category} {:id 31120608, :title "Psychiatric assessment", :type :wiki-api.core/category} {:id 32611713, :title "Emerging technologies", :type :wiki-api.core/category}}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 9272793, :title "Computational statistics", :type :wiki-api.core/category}}, {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} #{{:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category}}, {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} #{}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} #{}, {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} #{{:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{}, {:id 1650642, :title "Economics models", :type :wiki-api.core/category} #{{:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category}}, {:id 1158544, :title "Exponentials", :type :wiki-api.core/category} #{}, {:id 1609357, :title "Latin philosophical phrases", :type :wiki-api.core/category} #{}, {:id 746340, :title "Gene expression", :type :wiki-api.core/category} #{}, {:id 4244958, :title "Electrophysiology", :type :wiki-api.core/category} #{}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 34989583, :title "Term logic", :type :wiki-api.core/category} #{}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 25063012, :title "Concepts in epistemology", :type :wiki-api.core/category} #{}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 30982373, :title "Missing data", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{{:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{{:id 10699378, :title "Process management", :type :wiki-api.core/category} {:id 2299740, :title "Business terms", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category}}, {:id 709243, :title "Communication", :type :wiki-api.core/category} #{{:id 1009209, :title "Information", :type :wiki-api.core/category}}, {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} #{{:id 33793046, :title "Transformation (function)", :type :wiki-api.core/category}}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{{:id 30636687, :title "Network analysis", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 31362245, :title "Electrodiagnosis", :type :wiki-api.core/category} #{}, {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category}}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} #{{:id 734262, :title "Measurement", :type :wiki-api.core/category} {:id 3314991, :title "Bias", :type :wiki-api.core/category}}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 23968676, :title "Analytic geometry", :type :wiki-api.core/category} #{}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category}}, {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} #{{:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 691898, :title "Graph theory", :type :wiki-api.core/category} #{}, {:id 1376472, :title "Randomness", :type :wiki-api.core/category} #{}, {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} #{}, {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} #{{:id 5774898, :title "Free statistical software", :type :wiki-api.core/category}}, {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} #{{:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category}}, {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} #{{:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category}}, {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} #{{:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category}}, {:id 699287, :title "Graph algorithms", :type :wiki-api.core/category} #{{:id 25346631, :title "Computational problems in graph theory", :type :wiki-api.core/category}}, {:id 21310691, :title "Statistical forecasting", :type :wiki-api.core/category} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category}}, {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 339174, :title "Exponential family", :type :wiki-api.core/article} #{{:id 1158544, :title "Exponentials", :type :wiki-api.core/category} {:id 17768567, :title "Systems of probability distributions", :type :wiki-api.core/category} {:id 2210772, :title "Continuous distributions", :type :wiki-api.core/category} {:id 2210781, :title "Discrete distributions", :type :wiki-api.core/category}}, {:id 16989227, :title "Data", :type :wiki-api.core/category} #{}, {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} #{{:id 1419629, :title "Searching", :type :wiki-api.core/category}}, {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 37415391, :title "A priori", :type :wiki-api.core/category} #{{:id 35791326, :title "Subjective experience", :type :wiki-api.core/category} {:id 3966723, :title "Kantianism", :type :wiki-api.core/category} {:id 22712867, :title "Justification", :type :wiki-api.core/category} {:id 13167332, :title "Sources of knowledge", :type :wiki-api.core/category}}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{{:id 716309, :title "Cartography", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} {:id 693800, :title "Geography", :type :wiki-api.core/category}}, {:id 30636687, :title "Network analysis", :type :wiki-api.core/category} #{}, {:id 6534870, :title "Statistical laws", :type :wiki-api.core/category} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 35791326, :title "Subjective experience", :type :wiki-api.core/category} #{}, {:id 17768567, :title "Systems of probability distributions", :type :wiki-api.core/category} #{}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 31614277, :title "Statistical intervals", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 946892, :title "Econometrics", :type :wiki-api.core/category} #{{:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category}}, {:id 716309, :title "Cartography", :type :wiki-api.core/category} #{}, {:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category} {:id 697516, :title "Metric geometry", :type :wiki-api.core/category}}, {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category}}, {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} #{}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{{:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category}}, {:id 2664243, :title "Rationalism", :type :wiki-api.core/category} #{{:id 37415391, :title "A priori", :type :wiki-api.core/category}}, {:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} #{}, {:id 10699378, :title "Process management", :type :wiki-api.core/category} #{}, {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 697516, :title "Metric geometry", :type :wiki-api.core/category}}, {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} #{}, {:id 4594748, :title "Computational problems", :type :wiki-api.core/category} #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category}}, {:id 563854, :title "Global optimization", :type :wiki-api.core/article} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category}}, {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} #{}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 17766079, :title "Random graphs", :type :wiki-api.core/category} #{{:id 691898, :title "Graph theory", :type :wiki-api.core/category}}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{{:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 1063460, :title "Philosophical logic", :type :wiki-api.core/category} #{}, {:id 29359268, :title "Point estimation performance", :type :wiki-api.core/category} #{{:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} #{}, {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} #{{:id 24059390, :title "Markov models", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category}}, {:id 998678, :title "Surveillance", :type :wiki-api.core/category} #{}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category}}, {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} #{{:id 1532663, :title "Artificial intelligence applications", :type :wiki-api.core/category} {:id 8525467, :title "Pointing-device text input", :type :wiki-api.core/category}}, {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} #{}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 30982373, :title "Missing data", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 4222755, :title "Neurotechnology", :type :wiki-api.core/category} #{{:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category}}, {:id 11056269, :title "Multivariable calculus", :type :wiki-api.core/category} #{}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 35896842, :title "Brain–computer interfacing", :type :wiki-api.core/category} #{{:id 4222755, :title "Neurotechnology", :type :wiki-api.core/category}}, {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} #{}, {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} #{}, {:id 21067529, :title "Outlines", :type :wiki-api.core/category} #{}, {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} #{}, {:id 3142995, :title "Empiricism", :type :wiki-api.core/category} #{{:id 22712867, :title "Justification", :type :wiki-api.core/category}}, {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} #{}, {:id 909365, :title "Functional languages", :type :wiki-api.core/category} #{}, {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} #{{:id 1223322, :title "NP-complete problems", :type :wiki-api.core/category} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 699287, :title "Graph algorithms", :type :wiki-api.core/category} {:id 35356667, :title "Hamiltonian paths and cycles", :type :wiki-api.core/category}}, {:id 1385393, :title "Long tail", :type :wiki-api.core/article} #{{:id 1650642, :title "Economics models", :type :wiki-api.core/category} {:id 6534870, :title "Statistical laws", :type :wiki-api.core/category} {:id 18112594, :title "Tails of probability distributions", :type :wiki-api.core/category} {:id 11637786, :title "Internet marketing", :type :wiki-api.core/category}}, {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} #{}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{{:id 4594748, :title "Computational problems", :type :wiki-api.core/category}}, {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} #{}, {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 3966723, :title "Kantianism", :type :wiki-api.core/category} #{}, {:id 2210772, :title "Continuous distributions", :type :wiki-api.core/category} #{}, {:id 1008581, :title "Operations research", :type :wiki-api.core/category} #{{:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category}}, {:id 734262, :title "Measurement", :type :wiki-api.core/category} #{}, {:id 25685, :title "Random variable", :type :wiki-api.core/article} #{{:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category}}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} #{{:id 693985, :title "Probability theory", :type :wiki-api.core/category}}, {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article} #{{:id 29359268, :title "Point estimation performance", :type :wiki-api.core/category} {:id 3314991, :title "Bias", :type :wiki-api.core/category}}, {:id 18112594, :title "Tails of probability distributions", :type :wiki-api.core/category} #{}, {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} #{{:id 2688181, :title "Reality", :type :wiki-api.core/category} {:id 1609358, :title "Latin logical phrases", :type :wiki-api.core/category} {:id 34989583, :title "Term logic", :type :wiki-api.core/category} {:id 2664243, :title "Rationalism", :type :wiki-api.core/category} {:id 1063460, :title "Philosophical logic", :type :wiki-api.core/category} {:id 3142995, :title "Empiricism", :type :wiki-api.core/category} {:id 35092769, :title "Conceptual distinctions", :type :wiki-api.core/category}}, {:id 923167, :title "Length", :type :wiki-api.core/category} #{}, {:id 962413, :title "Image processing", :type :wiki-api.core/category} #{}, {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category}}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 4149155, :title "Psephology", :type :wiki-api.core/category} #{}, {:id 694008, :title "Statistics", :type :wiki-api.core/category} #{{:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} {:id 1557538, :title "Research methods", :type :wiki-api.core/category} {:id 1009209, :title "Information", :type :wiki-api.core/category} {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category}}, {:id 2299740, :title "Business terms", :type :wiki-api.core/category} #{}, {:id 1532663, :title "Artificial intelligence applications", :type :wiki-api.core/category} #{}, {:id 2210781, :title "Discrete distributions", :type :wiki-api.core/category} #{}, {:id 15932036, :title "Vectors", :type :wiki-api.core/category} #{{:id 690777, :title "Linear algebra", :type :wiki-api.core/category}}, {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} #{{:id 9272793, :title "Computational statistics", :type :wiki-api.core/category}}, {:id 706543, :title "Machine learning", :type :wiki-api.core/category} #{{:id 9272793, :title "Computational statistics", :type :wiki-api.core/category}}, {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} #{{:id 734262, :title "Measurement", :type :wiki-api.core/category}}, {:id 3175294, :title "Dimension", :type :wiki-api.core/category} #{{:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category}}, {:id 1013715, :title "Bilinear forms", :type :wiki-api.core/category} #{}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{{:id 744360, :title "Networks", :type :wiki-api.core/category} {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category}}, {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category}}, {:id 1419629, :title "Searching", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 797088, :title "Computer vision", :type :wiki-api.core/category} #{{:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} #{}, {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} #{}, {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} #{}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 35092769, :title "Conceptual distinctions", :type :wiki-api.core/category} #{}, {:id 3314991, :title "Bias", :type :wiki-api.core/category} #{}, {:id 33793046, :title "Transformation (function)", :type :wiki-api.core/category} #{{:id 763625, :title "Affine geometry", :type :wiki-api.core/category}}, {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} #{{:id 1158544, :title "Exponentials", :type :wiki-api.core/category}}, {:id 693985, :title "Probability theory", :type :wiki-api.core/category} #{}, {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} #{{:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category}}, {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} #{{:id 787876, :title "Computational linguistics", :type :wiki-api.core/category} {:id 1532663, :title "Artificial intelligence applications", :type :wiki-api.core/category}}, {:id 8525467, :title "Pointing-device text input", :type :wiki-api.core/category} #{}, {:id 946910, :title "Decision theory", :type :wiki-api.core/category} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category} {:id 693985, :title "Probability theory", :type :wiki-api.core/category}}, {:id 1557538, :title "Research methods", :type :wiki-api.core/category} #{{:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category}}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{{:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category} #{}, {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{{:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 21917434, :title "Information Age", :type :wiki-api.core/category}}, {:id 434897, :title "Hough transform", :type :wiki-api.core/article} #{{:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} #{{:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category}}, {:id 11637786, :title "Internet marketing", :type :wiki-api.core/category} #{}, {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} #{}, {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 21067529, :title "Outlines", :type :wiki-api.core/category} {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category}}, {:id 25346631, :title "Computational problems in graph theory", :type :wiki-api.core/category} #{{:id 691898, :title "Graph theory", :type :wiki-api.core/category} {:id 4594748, :title "Computational problems", :type :wiki-api.core/category}}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{{:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 923167, :title "Length", :type :wiki-api.core/category}}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{{:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} {:id 751362, :title "Face recognition", :type :wiki-api.core/category}}, {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category} #{}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{{:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} {:id 25208324, :title "F-divergences", :type :wiki-api.core/category}}, {:id 5774898, :title "Free statistical software", :type :wiki-api.core/category} #{{:id 703162, :title "Statistical software", :type :wiki-api.core/category}}, {:id 22712867, :title "Justification", :type :wiki-api.core/category} #{{:id 25063012, :title "Concepts in epistemology", :type :wiki-api.core/category}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category}}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{{:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category}}, {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category} #{}, {:id 1009209, :title "Information", :type :wiki-api.core/category} #{{:id 16989227, :title "Data", :type :wiki-api.core/category}}, {:id 693800, :title "Geography", :type :wiki-api.core/category} #{}, {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 700292, :title "Scientific method", :type :wiki-api.core/category} #{}, {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{{:id 29421852, :title "M-estimators", :type :wiki-api.core/category}}, {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} #{}, {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} #{{:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 364002, :title "Hill climbing", :type :wiki-api.core/article} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} #{{:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category}}, {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} #{{:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 690777, :title "Linear algebra", :type :wiki-api.core/category} #{}, {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} #{}, {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} #{{:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} #{{:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} #{}, {:id 11487293, :title "Applied probability", :type :wiki-api.core/category} #{}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{{:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category}}, {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category}}, {:id 21917434, :title "Information Age", :type :wiki-api.core/category} #{}, {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} #{{:id 998678, :title "Surveillance", :type :wiki-api.core/category}}, {:id 697516, :title "Metric geometry", :type :wiki-api.core/category} #{}, {:id 703162, :title "Statistical software", :type :wiki-api.core/category} #{{:id 9272793, :title "Computational statistics", :type :wiki-api.core/category}}, {:id 751362, :title "Face recognition", :type :wiki-api.core/category} #{{:id 1532663, :title "Artificial intelligence applications", :type :wiki-api.core/category}}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{{:id 745820, :title "DNA", :type :wiki-api.core/category} {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} {:id 746340, :title "Gene expression", :type :wiki-api.core/category} {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category}}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 14426697, :title "Market research", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 31614277, :title "Statistical intervals", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category} {:id 4149155, :title "Psephology", :type :wiki-api.core/category} {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} {:id 14426697, :title "Market research", :type :wiki-api.core/category}}, {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} #{{:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category} #{}, {:id 35356667, :title "Hamiltonian paths and cycles", :type :wiki-api.core/category} #{}, {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} #{{:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 821959, :title "Matrices", :type :wiki-api.core/category} #{{:id 690777, :title "Linear algebra", :type :wiki-api.core/category}}, {:id 31120608, :title "Psychiatric assessment", :type :wiki-api.core/category} #{}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{{:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} {:id 909365, :title "Functional languages", :type :wiki-api.core/category} {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category}}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} #{{:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 9272793, :title "Computational statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 427282, :title "Mutual information", :type :wiki-api.core/article} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 951835, :title "Computer data", :type :wiki-api.core/category} #{{:id 16989227, :title "Data", :type :wiki-api.core/category}}, {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category} #{}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{{:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category}}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category}}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article} #{{:id 787876, :title "Computational linguistics", :type :wiki-api.core/category} {:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category}}, {:id 157093, :title "Dot product", :type :wiki-api.core/article} #{{:id 23968676, :title "Analytic geometry", :type :wiki-api.core/category} {:id 15932036, :title "Vectors", :type :wiki-api.core/category} {:id 1013715, :title "Bilinear forms", :type :wiki-api.core/category} {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category}}, {:id 32611713, :title "Emerging technologies", :type :wiki-api.core/category} #{}, {:id 22100652, :title "Empirical process", :type :wiki-api.core/category} #{}, {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 11487293, :title "Applied probability", :type :wiki-api.core/category}}, {:id 13167332, :title "Sources of knowledge", :type :wiki-api.core/category} #{{:id 25063012, :title "Concepts in epistemology", :type :wiki-api.core/category}}, {:id 29526090, :title "Iterative methods", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category}}, {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category}}}, :out-map {{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article}}, {:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} #{}, {:id 1223322, :title "NP-complete problems", :type :wiki-api.core/category} #{{:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category}}, {:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} #{{:id 5175143, :title "Geostatistics", :type :wiki-api.core/category}}, {:id 2688181, :title "Reality", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{}, {:id 745820, :title "DNA", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} #{}, {:id 8910108, :title "Linux numerical analysis software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 787876, :title "Computational linguistics", :type :wiki-api.core/category} #{{:id 960021, :title "Natural language processing", :type :wiki-api.core/category} {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article}}, {:id 24059390, :title "Markov models", :type :wiki-api.core/category} #{{:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category}}, {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} #{{:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} #{}, {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} #{{:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} {:id 364002, :title "Hill climbing", :type :wiki-api.core/article}}, {:id 3367631, :title "Neurophysiology", :type :wiki-api.core/category} #{{:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category}}, {:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} #{{:id 24114689, :title "Microarrays", :type :wiki-api.core/category}}, {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} #{{:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 744360, :title "Networks", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 1609358, :title "Latin logical phrases", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} #{}, {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} #{}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category}}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{}, {:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} #{{:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} #{{:id 191752, :title "Covariance matrix", :type :wiki-api.core/article}}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{{:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 4594748, :title "Computational problems", :type :wiki-api.core/category}}, {:id 1650642, :title "Economics models", :type :wiki-api.core/category} #{{:id 1385393, :title "Long tail", :type :wiki-api.core/article}}, {:id 1158544, :title "Exponentials", :type :wiki-api.core/category} #{{:id 339174, :title "Exponential family", :type :wiki-api.core/article} {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category}}, {:id 1609357, :title "Latin philosophical phrases", :type :wiki-api.core/category} #{{:id 1609358, :title "Latin logical phrases", :type :wiki-api.core/category}}, {:id 746340, :title "Gene expression", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 4244958, :title "Electrophysiology", :type :wiki-api.core/category} #{{:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category}}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{}, {:id 34989583, :title "Term logic", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{}, {:id 25063012, :title "Concepts in epistemology", :type :wiki-api.core/category} #{{:id 22712867, :title "Justification", :type :wiki-api.core/category} {:id 13167332, :title "Sources of knowledge", :type :wiki-api.core/category}}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{}, {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} #{{:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article}}, {:id 30982373, :title "Missing data", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article}}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{}, {:id 709243, :title "Communication", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} #{}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{}, {:id 31362245, :title "Electrodiagnosis", :type :wiki-api.core/category} #{{:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category}}, {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article}}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{}, {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article}}, {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} #{}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{{:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category}}, {:id 23968676, :title "Analytic geometry", :type :wiki-api.core/category} #{{:id 157093, :title "Dot product", :type :wiki-api.core/article}}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 14426697, :title "Market research", :type :wiki-api.core/category} {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article}}, {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} #{}, {:id 691898, :title "Graph theory", :type :wiki-api.core/category} #{{:id 17766079, :title "Random graphs", :type :wiki-api.core/category} {:id 25346631, :title "Computational problems in graph theory", :type :wiki-api.core/category}}, {:id 1376472, :title "Randomness", :type :wiki-api.core/category} #{{:id 25685, :title "Random variable", :type :wiki-api.core/article} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category}}, {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 6615782, :title "Free plotting software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} #{}, {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} #{}, {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} #{}, {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} #{{:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} #{}, {:id 699287, :title "Graph algorithms", :type :wiki-api.core/category} #{{:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category}}, {:id 21310691, :title "Statistical forecasting", :type :wiki-api.core/category} #{{:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category}}, {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} #{{:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} {:id 30982373, :title "Missing data", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 339174, :title "Exponential family", :type :wiki-api.core/article} #{}, {:id 16989227, :title "Data", :type :wiki-api.core/category} #{{:id 1009209, :title "Information", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 364002, :title "Hill climbing", :type :wiki-api.core/article}}, {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} #{{:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 21310691, :title "Statistical forecasting", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, {:id 37415391, :title "A priori", :type :wiki-api.core/category} #{{:id 2664243, :title "Rationalism", :type :wiki-api.core/category}}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{}, {:id 30636687, :title "Network analysis", :type :wiki-api.core/category} #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 6534870, :title "Statistical laws", :type :wiki-api.core/category} #{{:id 1385393, :title "Long tail", :type :wiki-api.core/article}}, {:id 35791326, :title "Subjective experience", :type :wiki-api.core/category} #{{:id 37415391, :title "A priori", :type :wiki-api.core/category}}, {:id 17768567, :title "Systems of probability distributions", :type :wiki-api.core/category} #{{:id 339174, :title "Exponential family", :type :wiki-api.core/article}}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{}, {:id 31614277, :title "Statistical intervals", :type :wiki-api.core/category} #{{:id 280911, :title "Confidence interval", :type :wiki-api.core/article}}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{}, {:id 946892, :title "Econometrics", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 716309, :title "Cartography", :type :wiki-api.core/category} #{{:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} #{{:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article}}, {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 29526090, :title "Iterative methods", :type :wiki-api.core/category}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{}, {:id 2664243, :title "Rationalism", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 17923612, :title "Types of probability distributions", :type :wiki-api.core/category} #{{:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article}}, {:id 10699378, :title "Process management", :type :wiki-api.core/category} #{{:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category}}, {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} #{{:id 53932, :title "Euclidean distance", :type :wiki-api.core/article}}, {:id 33313601, :title "Literate programming", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 4594748, :title "Computational problems", :type :wiki-api.core/category} #{{:id 1223322, :title "NP-complete problems", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 25346631, :title "Computational problems in graph theory", :type :wiki-api.core/category}}, {:id 563854, :title "Global optimization", :type :wiki-api.core/article} #{}, {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article}}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{}, {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category}}, {:id 17766079, :title "Random graphs", :type :wiki-api.core/category} #{}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{}, {:id 1063460, :title "Philosophical logic", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 29359268, :title "Point estimation performance", :type :wiki-api.core/category} #{{:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article}}, {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} #{{:id 191752, :title "Covariance matrix", :type :wiki-api.core/article}}, {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} #{{:id 1650642, :title "Economics models", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} #{}, {:id 998678, :title "Surveillance", :type :wiki-api.core/category} #{{:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category}}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{{:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 563854, :title "Global optimization", :type :wiki-api.core/article}}, {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} #{}, {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{}, {:id 4222755, :title "Neurotechnology", :type :wiki-api.core/category} #{{:id 35896842, :title "Brain–computer interfacing", :type :wiki-api.core/category}}, {:id 11056269, :title "Multivariable calculus", :type :wiki-api.core/category} #{{:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article}}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article}}, {:id 35896842, :title "Brain–computer interfacing", :type :wiki-api.core/category} #{{:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category}}, {:id 1358456, :title "GNU Project software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 21067529, :title "Outlines", :type :wiki-api.core/category} #{{:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article}}, {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 3142995, :title "Empiricism", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 909365, :title "Functional languages", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} #{{:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} {:id 6534870, :title "Statistical laws", :type :wiki-api.core/category} {:id 25685, :title "Random variable", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} #{}, {:id 1385393, :title "Long tail", :type :wiki-api.core/article} #{}, {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} #{{:id 33793046, :title "Transformation (function)", :type :wiki-api.core/category}}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{}, {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} #{}, {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category}}, {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article}}, {:id 3966723, :title "Kantianism", :type :wiki-api.core/category} #{{:id 37415391, :title "A priori", :type :wiki-api.core/category}}, {:id 2210772, :title "Continuous distributions", :type :wiki-api.core/category} #{{:id 339174, :title "Exponential family", :type :wiki-api.core/article}}, {:id 1008581, :title "Operations research", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 734262, :title "Measurement", :type :wiki-api.core/category} #{{:id 1385769, :title "Systematic error", :type :wiki-api.core/article} {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 25685, :title "Random variable", :type :wiki-api.core/article} #{}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} #{{:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article}}, {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article} #{}, {:id 18112594, :title "Tails of probability distributions", :type :wiki-api.core/category} #{{:id 1385393, :title "Long tail", :type :wiki-api.core/article}}, {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} #{}, {:id 923167, :title "Length", :type :wiki-api.core/category} #{{:id 53932, :title "Euclidean distance", :type :wiki-api.core/article}}, {:id 962413, :title "Image processing", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 797088, :title "Computer vision", :type :wiki-api.core/category} {:id 505717, :title "Image segmentation", :type :wiki-api.core/article}}, {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} #{}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{}, {:id 4149155, :title "Psephology", :type :wiki-api.core/category} #{{:id 280911, :title "Confidence interval", :type :wiki-api.core/article}}, {:id 694008, :title "Statistics", :type :wiki-api.core/category} #{{:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 31614277, :title "Statistical intervals", :type :wiki-api.core/category} {:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 6537978, :title "Summary statistics", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 9272793, :title "Computational statistics", :type :wiki-api.core/category}}, {:id 2299740, :title "Business terms", :type :wiki-api.core/category} #{{:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category}}, {:id 1532663, :title "Artificial intelligence applications", :type :wiki-api.core/category} #{{:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} {:id 751362, :title "Face recognition", :type :wiki-api.core/category}}, {:id 2210781, :title "Discrete distributions", :type :wiki-api.core/category} #{{:id 339174, :title "Exponential family", :type :wiki-api.core/article}}, {:id 15932036, :title "Vectors", :type :wiki-api.core/category} #{{:id 157093, :title "Dot product", :type :wiki-api.core/article}}, {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category}}, {:id 706543, :title "Machine learning", :type :wiki-api.core/category} #{{:id 24059390, :title "Markov models", :type :wiki-api.core/category} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 12535256, :title "Kernel methods for machine learning", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} #{{:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 3175294, :title "Dimension", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 1013715, :title "Bilinear forms", :type :wiki-api.core/category} #{{:id 157093, :title "Dot product", :type :wiki-api.core/article}}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article}}, {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} #{{:id 24114689, :title "Microarrays", :type :wiki-api.core/category}}, {:id 1419629, :title "Searching", :type :wiki-api.core/category} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{}, {:id 797088, :title "Computer vision", :type :wiki-api.core/category} #{{:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 434897, :title "Hough transform", :type :wiki-api.core/article} {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category}}, {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} #{{:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} #{{:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article}}, {:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category} #{{:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 925067, :title "Data-centric programming languages", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{}, {:id 35092769, :title "Conceptual distinctions", :type :wiki-api.core/category} #{{:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article}}, {:id 3314991, :title "Bias", :type :wiki-api.core/category} #{{:id 1385769, :title "Systematic error", :type :wiki-api.core/article} {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article}}, {:id 33793046, :title "Transformation (function)", :type :wiki-api.core/category} #{{:id 38449, :title "Affine transformation", :type :wiki-api.core/article}}, {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} #{}, {:id 693985, :title "Probability theory", :type :wiki-api.core/category} #{{:id 25685, :title "Random variable", :type :wiki-api.core/article} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 946910, :title "Decision theory", :type :wiki-api.core/category}}, {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article}}, {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 8525467, :title "Pointing-device text input", :type :wiki-api.core/category} #{{:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category}}, {:id 946910, :title "Decision theory", :type :wiki-api.core/category} #{{:id 22004271, :title "Optimal decisions", :type :wiki-api.core/category}}, {:id 1557538, :title "Research methods", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{}, {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category} #{{:id 4222755, :title "Neurotechnology", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} #{{:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category}}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{{:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} {:id 427282, :title "Mutual information", :type :wiki-api.core/article}}, {:id 434897, :title "Hough transform", :type :wiki-api.core/article} #{}, {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} #{{:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{{:id 29359268, :title "Point estimation performance", :type :wiki-api.core/category} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article}}, {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, {:id 11637786, :title "Internet marketing", :type :wiki-api.core/category} #{{:id 1385393, :title "Long tail", :type :wiki-api.core/article}}, {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article}}, {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article}}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{}, {:id 25346631, :title "Computational problems in graph theory", :type :wiki-api.core/category} #{{:id 699287, :title "Graph algorithms", :type :wiki-api.core/category}}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{}, {:id 11472332, :title "Articles containing proofs", :type :wiki-api.core/category} #{{:id 157093, :title "Dot product", :type :wiki-api.core/article}}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{}, {:id 5774898, :title "Free statistical software", :type :wiki-api.core/category} #{{:id 6615782, :title "Free plotting software", :type :wiki-api.core/category}}, {:id 22712867, :title "Justification", :type :wiki-api.core/category} #{{:id 37415391, :title "A priori", :type :wiki-api.core/category} {:id 3142995, :title "Empiricism", :type :wiki-api.core/category}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{{:id 9833053, :title "String similarity measures", :type :wiki-api.core/category} {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} {:id 1419629, :title "Searching", :type :wiki-api.core/category}}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{}, {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category} #{{:id 24114689, :title "Microarrays", :type :wiki-api.core/category}}, {:id 1009209, :title "Information", :type :wiki-api.core/category} #{{:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 693800, :title "Geography", :type :wiki-api.core/category} #{{:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} #{}, {:id 700292, :title "Scientific method", :type :wiki-api.core/category} #{{:id 1557538, :title "Research methods", :type :wiki-api.core/category} {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category}}, {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{}, {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} #{{:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article}}, {:id 364002, :title "Hill climbing", :type :wiki-api.core/article} #{}, {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} #{{:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article}}, {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} #{}, {:id 690777, :title "Linear algebra", :type :wiki-api.core/category} #{{:id 15932036, :title "Vectors", :type :wiki-api.core/category} {:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} #{{:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article}}, {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} #{{:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} #{{:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article}}, {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} #{{:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category}}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{}, {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 11487293, :title "Applied probability", :type :wiki-api.core/category} #{{:id 10384312, :title "Empirical probability", :type :wiki-api.core/article}}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{}, {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} #{}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article}}, {:id 21917434, :title "Information Age", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} #{{:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} {:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} {:id 17922914, :title "Estimation of densities", :type :wiki-api.core/category} {:id 1817228, :title "Training set", :type :wiki-api.core/article}}, {:id 10812576, :title "Automatic identification and data capture", :type :wiki-api.core/category} #{{:id 602401, :title "Facial recognition system", :type :wiki-api.core/article}}, {:id 697516, :title "Metric geometry", :type :wiki-api.core/category} #{{:id 6536186, :title "Statistical distance measures", :type :wiki-api.core/category} {:id 9833053, :title "String similarity measures", :type :wiki-api.core/category}}, {:id 703162, :title "Statistical software", :type :wiki-api.core/category} #{{:id 5774898, :title "Free statistical software", :type :wiki-api.core/category}}, {:id 751362, :title "Face recognition", :type :wiki-api.core/category} #{{:id 602401, :title "Facial recognition system", :type :wiki-api.core/article}}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{}, {:id 14426697, :title "Market research", :type :wiki-api.core/category} #{{:id 280911, :title "Confidence interval", :type :wiki-api.core/article}}, {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} #{}, {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} #{}, {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 35356667, :title "Hamiltonian paths and cycles", :type :wiki-api.core/category} #{{:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category}}, {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} #{{:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article}}, {:id 821959, :title "Matrices", :type :wiki-api.core/category} #{{:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article}}, {:id 31120608, :title "Psychiatric assessment", :type :wiki-api.core/category} #{{:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category}}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{}, {:id 3224825, :title "Scientific modeling", :type :wiki-api.core/category} #{{:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category}}, {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} #{}, {:id 9272793, :title "Computational statistics", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 703162, :title "Statistical software", :type :wiki-api.core/category}}, {:id 427282, :title "Mutual information", :type :wiki-api.core/article} #{}, {:id 951835, :title "Computer data", :type :wiki-api.core/category} #{{:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 34313543, :title "Cross-platform free software", :type :wiki-api.core/category} #{{:id 8523545, :title "R (programming language)", :type :wiki-api.core/category}}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{}, {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article} #{}, {:id 157093, :title "Dot product", :type :wiki-api.core/article} #{}, {:id 32611713, :title "Emerging technologies", :type :wiki-api.core/category} #{{:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category}}, {:id 22100652, :title "Empirical process", :type :wiki-api.core/category} #{{:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article}}, {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article} #{}, {:id 13167332, :title "Sources of knowledge", :type :wiki-api.core/category} #{{:id 37415391, :title "A priori", :type :wiki-api.core/category}}, {:id 29526090, :title "Iterative methods", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category}}, {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category} #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{}}}, :topic-docs #graphs.core.Digraph{:nodes #{730336 {:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} 3663520 595744 594049 {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} 1032258 {:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} 1031235 1009731 {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} {:id 5206601, :title "Data mining", :type :wiki-api.core/category} 3394083 1032835 1031939 597891 985059 {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} 832677 1033413 {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} 3509574 {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} {:id 691898, :title "Graph theory", :type :wiki-api.core/category} 839752 1009800 {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} 3307625 {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} {:id 339174, :title "Exponential family", :type :wiki-api.core/article} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} 27498 527435 1219659 {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 563854, :title "Global optimization", :type :wiki-api.core/article} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} 1023181 {:id 17766079, :title "Random graphs", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} 839501 {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} 939118 {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} 893422 1031215 1033455 2966831 {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} {:id 1385393, :title "Long tail", :type :wiki-api.core/article} 2878447 {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} 1042704 3073360 {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} {:id 25685, :title "Random variable", :type :wiki-api.core/article} 3700560 {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article} {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} 2870097 1257393 {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} 2864403 {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} 3679540 1273172 {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} 600021 {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 434897, :title "Hough transform", :type :wiki-api.core/article} 346006 3677399 {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} 1033911 {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} 527448 1065112 2867384 3516632 {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} 1031640 {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} 790361 1032218 985178 {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 364002, :title "Hill climbing", :type :wiki-api.core/article} {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} 985307 {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} 907739 {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} 1044411 {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} {:id 1817228, :title "Training set", :type :wiki-api.core/article} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} 984956 {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} 3548061 1031101 {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} 3359998 {:id 427282, :title "Mutual information", :type :wiki-api.core/article} 1009438 {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article} 3065726 {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article} 1113151 {:id 157093, :title "Dot product", :type :wiki-api.core/article} 642207 {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, :in-map {730336 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} #{}, 3663520 #{{:id 3424576, :title "Kernel methods", :type :wiki-api.core/article}}, 595744 #{{:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} {:id 427282, :title "Mutual information", :type :wiki-api.core/article}}, 594049 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{}, {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} #{}, 1032258 #{{:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} #{}, 1031235 #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} {:id 157093, :title "Dot product", :type :wiki-api.core/article}}, 1009731 #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} #{}, {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} #{}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{}, 3394083 #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, 1032835 #{{:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article}}, 1031939 #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article}}, 597891 #{{:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article}}, 985059 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{}, 832677 #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} {:id 505717, :title "Image segmentation", :type :wiki-api.core/article}}, 1033413 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article}}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{}, {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} #{}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{}, 3509574 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{}, {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} #{}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{}, {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} #{}, {:id 691898, :title "Graph theory", :type :wiki-api.core/category} #{}, 839752 #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article}}, 1009800 #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 364002, :title "Hill climbing", :type :wiki-api.core/article}}, {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} #{}, {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} #{}, {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} #{}, 3307625 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} #{}, {:id 339174, :title "Exponential family", :type :wiki-api.core/article} #{}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{}, 27498 #{{:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 280911, :title "Confidence interval", :type :wiki-api.core/article}}, 527435 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1219659 #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{}, {:id 563854, :title "Global optimization", :type :wiki-api.core/article} #{}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{}, 1023181 #{{:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 17766079, :title "Random graphs", :type :wiki-api.core/category} #{}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{}, 839501 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 563854, :title "Global optimization", :type :wiki-api.core/article}}, {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} #{}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{}, {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} #{}, 939118 #{{:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article}}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{}, 893422 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article}}, 1031215 #{{:id 17766079, :title "Random graphs", :type :wiki-api.core/category}}, 1033455 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, 2966831 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} #{}, {:id 1385393, :title "Long tail", :type :wiki-api.core/article} #{}, 2878447 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{}, 1042704 #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 691898, :title "Graph theory", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article}}, 3073360 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} #{}, {:id 25685, :title "Random variable", :type :wiki-api.core/article} #{}, 3700560 #{{:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article}}, {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article} #{}, {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} #{}, {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} #{}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{}, 2870097 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article}}, 1257393 #{{:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article}}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{}, 2864403 #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{}, 3679540 #{{:id 1385393, :title "Long tail", :type :wiki-api.core/article}}, 1273172 #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} #{}, 600021 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{}, {:id 434897, :title "Hough transform", :type :wiki-api.core/article} #{}, 346006 #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, 3677399 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{}, 1033911 #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 25685, :title "Random variable", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article}}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{}, 527448 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, 1065112 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article}}, 2867384 #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, 3516632 #{{:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article}}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{}, 1031640 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{}, 790361 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1032218 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, 985178 #{{:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} {:id 339174, :title "Exponential family", :type :wiki-api.core/article} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} {:id 28004586, :title "Loss functions", :type :wiki-api.core/category}}, {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} #{}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{}, {:id 364002, :title "Hill climbing", :type :wiki-api.core/article} #{}, {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} #{}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{}, 985307 #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{}, 907739 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} {:id 434897, :title "Hough transform", :type :wiki-api.core/article} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article}}, {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} #{}, 1044411 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 1817228, :title "Training set", :type :wiki-api.core/article}}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{}, {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} #{}, 984956 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} #{}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{}, 3548061 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 1031101 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article}}, {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} #{}, 3359998 #{{:id 17179027, :title "Categorical data", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 427282, :title "Mutual information", :type :wiki-api.core/article} #{}, 1009438 #{{:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{}, 3065726 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{}, {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article} #{}, 1113151 #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 157093, :title "Dot product", :type :wiki-api.core/article} #{}, 642207 #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article} #{}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{}}, :out-map {730336 #{}, {:id 159974, :title "Lagrange multiplier", :type :wiki-api.core/article} #{1032835}, 3663520 #{}, 595744 #{}, 594049 #{}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{1033413 1033455 600021 1031640 1032218 1031101}, {:id 17179027, :title "Categorical data", :type :wiki-api.core/category} #{3359998}, 1032258 #{}, {:id 32549775, :title "Bayesian inference", :type :wiki-api.core/category} #{1009438}, 1031235 #{}, 1009731 #{}, {:id 2690455, :title "Empirical distribution function", :type :wiki-api.core/article} #{595744}, {:id 3072007, :title "Electroencephalography", :type :wiki-api.core/category} #{1031640}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{1113151 642207}, 3394083 #{}, 1032835 #{}, 1031939 #{}, 597891 #{}, 985059 #{}, {:id 769503, :title "Scale parameter", :type :wiki-api.core/article} #{1031101}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{1009731 1219659}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{1033911}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{1009800 1042704}, 832677 #{}, 1033413 #{}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{527448 907739 984956}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{1031235 2867384 984956}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{1031939 832677 1273172}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{2867384}, {:id 26348962, :title "Sensitivity analysis", :type :wiki-api.core/category} #{1033455}, {:id 38449, :title "Affine transformation", :type :wiki-api.core/article} #{907739}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{1032835 3509574 2966831 3073360 2870097 1273172 3548061 3065726}, 3509574 #{}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{839752 2864403}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{1032835 1031101}, {:id 1385769, :title "Systematic error", :type :wiki-api.core/article} #{1033455}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{1009438}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{730336 594049 985059 527435 839501 600021 1065112 790361 1044411 3359998}, {:id 40326, :title "Positive-definite matrix", :type :wiki-api.core/article} #{1031235}, {:id 691898, :title "Graph theory", :type :wiki-api.core/category} #{1042704}, 839752 #{}, 1009800 #{}, {:id 4491248, :title "Bregman divergence", :type :wiki-api.core/article} #{985178}, {:id 191752, :title "Covariance matrix", :type :wiki-api.core/article} #{1033455}, {:id 799760, :title "Mahalanobis distance", :type :wiki-api.core/article} #{985178}, 3307625 #{}, {:id 2090057, :title "Kernel density estimation", :type :wiki-api.core/article} #{1033413}, {:id 339174, :title "Exponential family", :type :wiki-api.core/article} #{985178}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{839752 1113151 642207}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{27498 1257393 2867384 3516632 1031101}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{1033413 3307625 893422 2878447 3677399 1033911 527448 2867384 1031640 1031101 1009438}, 27498 #{}, 527435 #{}, 1219659 #{}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{1033413}, {:id 563854, :title "Global optimization", :type :wiki-api.core/article} #{839501}, {:id 20926, :title "Supervised learning", :type :wiki-api.core/article} #{2864403}, 1023181 #{}, {:id 17766079, :title "Random graphs", :type :wiki-api.core/category} #{1031215}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{1031235 597891 1023181 2864403 1065112 1031640 1031101}, 839501 #{}, {:id 21407782, :title "Markov chain Monte Carlo", :type :wiki-api.core/category} #{839752}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{985307}, {:id 22406300, :title "Handwriting recognition", :type :wiki-api.core/category} #{1031939}, 939118 #{}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{1009731 985178}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{1032835}, 893422 #{}, 1031215 #{}, 1033455 #{}, 2966831 #{}, {:id 31111956, :title "Travelling salesman problem", :type :wiki-api.core/category} #{1032835}, {:id 1385393, :title "Long tail", :type :wiki-api.core/article} #{3679540}, 2878447 #{}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{1033455 1042704 2870097 2864403 985307}, 1042704 #{}, 3073360 #{}, {:id 14663145, :title "Document clustering", :type :wiki-api.core/article} #{595744}, {:id 25685, :title "Random variable", :type :wiki-api.core/article} #{1033911}, 3700560 #{}, {:id 8450479, :title "Bias of an estimator", :type :wiki-api.core/article} #{1031101}, {:id 6679056, :title "A priori and a posteriori", :type :wiki-api.core/article} #{1031640}, {:id 313942, :title "Local search (optimization)", :type :wiki-api.core/article} #{1032258}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{1042704 3700560}, 2870097 #{}, 1257393 #{}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{1032258 1031939}, 2864403 #{}, {:id 242190, :title "Feature extraction", :type :wiki-api.core/article} #{1031939}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{1032835 1031939 832677 1032218}, 3679540 #{}, 1273172 #{}, {:id 31024818, :title "Gaussian function", :type :wiki-api.core/category} #{984956}, 600021 #{}, {:id 1775388, :title "K-nearest neighbor algorithm", :type :wiki-api.core/article} #{2864403}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{1009731 1042704 1031640}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{1033911 985307}, {:id 434897, :title "Hough transform", :type :wiki-api.core/article} #{907739}, 346006 #{}, 3677399 #{}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{832677 907739}, 1033911 #{}, {:id 53932, :title "Euclidean distance", :type :wiki-api.core/article} #{985178}, {:id 602401, :title "Facial recognition system", :type :wiki-api.core/article} #{1031939}, 527448 #{}, 1065112 #{}, 2867384 #{}, 3516632 #{}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{939118 985178}, 1031640 #{}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{832677}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{1031235 3394083 346006 1032218 984956}, 790361 #{}, 1032218 #{}, 985178 #{}, {:id 558462, :title "Information bottleneck method", :type :wiki-api.core/article} #{595744}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{1031640}, {:id 364002, :title "Hill climbing", :type :wiki-api.core/article} #{1009800}, {:id 23548403, :title "Exploratory data analysis", :type :wiki-api.core/category} #{832677}, {:id 506077, :title "Marginal distribution", :type :wiki-api.core/article} #{1009731}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{1033413 839752}, 985307 #{}, {:id 3424576, :title "Kernel methods", :type :wiki-api.core/article} #{3663520}, 907739 #{}, {:id 1053303, :title "Statistical learning theory", :type :wiki-api.core/article} #{1031939}, 1044411 #{}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{1023181}, {:id 1817228, :title "Training set", :type :wiki-api.core/article} #{1044411}, {:id 280911, :title "Confidence interval", :type :wiki-api.core/article} #{27498}, 984956 #{}, {:id 879637, :title "Joint probability distribution", :type :wiki-api.core/article} #{595744}, {:id 8523545, :title "R (programming language)", :type :wiki-api.core/category} #{1219659}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{2864403}, 3548061 #{}, 1031101 #{}, {:id 505717, :title "Image segmentation", :type :wiki-api.core/article} #{832677}, 3359998 #{}, {:id 427282, :title "Mutual information", :type :wiki-api.core/article} #{595744}, 1009438 #{}, {:id 28004586, :title "Loss functions", :type :wiki-api.core/category} #{985178}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{1009731 1219659}, 3065726 #{}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{597891 839752}, {:id 1473135, :title "Semantic similarity", :type :wiki-api.core/article} #{893422}, 1113151 #{}, {:id 157093, :title "Dot product", :type :wiki-api.core/article} #{1031235}, 642207 #{}, {:id 10384312, :title "Empirical probability", :type :wiki-api.core/article} #{1033911}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{1033455}}}, :doc-map {730336 #search_api.search_api.Paper{:id 730336, :key "conf/icycs/Wang08", :title "A Subsystem Division Method by Clustering.", :abstract "State explosion problem is the primary obstacle to model complex system with Petri nets; modularization and hierarchy provide ways to solve this problem. When the bottom-up method is adopted, system functions in the lower layers are combined to obtain sub systems. The idea of clustering is introduced to decide which functions should be combined. The operation to combine two functions is defined; the distance between two functions is calculated by the degree of relevancy; a clustering algorithm with the idea of nearest-neighbor-first is designed to divide functions into sub systems. The function clustering method presented in this paper facilitates the Petri nets based system developing process.", :author (#search_api.search_api.Author{:id 451015, :first-name nil, :last-name nil, :full-name "Zhijian Wang"}), :year 2008, :venue "ICYCS", :ncit 0, :string "A Subsystem Division Method by Clustering.. State explosion problem is the primary obstacle to model complex system with Petri nets; modularization and hierarchy provide ways to solve this problem. When the bottom-up method is adopted, system functions in the lower layers are combined to obtain sub systems. The idea of clustering is introduced to decide which functions should be combined. The operation to combine two functions is defined; the distance between two functions is calculated by the degree of relevancy; a clustering algorithm with the idea of nearest-neighbor-first is designed to divide functions into sub systems. The function clustering method presented in this paper facilitates the Petri nets based system developing process.", :doc-id "A Subsystem Division Method by Clustering. 2008  "}, 3663520 #search_api.search_api.Paper{:id 3663520, :key "conf/icpr/FausserS12", :title "Clustering large datasets with kernel methods.", :abstract nil, :author (#search_api.search_api.Author{:id 1557097, :first-name nil, :last-name nil, :full-name "Stefan Faußer"} #search_api.search_api.Author{:id 104411, :first-name nil, :last-name nil, :full-name "Friedhelm Schwenker"}), :year 2012, :venue "ICPR", :ncit 0, :string "Clustering large datasets with kernel methods.. ", :doc-id "Clustering large datasets with kernel methods. 2012  ,  "}, 595744 #search_api.search_api.Paper{:id 595744, :key "conf/sigir/SlonimT00", :title "Document clustering using word clusters via the information bottleneck method.", :abstract "We present a novel implementation of the recently introduced information bottleneck method for unsupervised document clustering. Given a joint empirical distribution of words and documents, p(x, y), we first cluster the words, Y, so that the obtained word clusters, Ytilde;, maximally preserve the information on the documents. The resulting joint distribution. p(X, Ytilde;), contains most of the original information about the documents, I(X; Ytilde;) &ap; I(X; Y), but it is much less sparse and noisy. Using the same procedure we then cluster the documents, X, so that the information about the word-clusters is preserved. Thus, we first find word-clusters that capture most of the mutual information about to set of documents, and then find document clusters, that preserve the information about the word clusters. We tested this procedure over several document collections based on subsets taken from the standard 20Newsgroups corpus. The results were assessed by calculating the correlation between the document clusters and the correct labels for these documents. Finding from our experiments show that this double clustering procedure, which uses the information bottleneck method, yields significantly superior performance compared to other common document distributional clustering algorithms. Moreover, the double clustering procedure improves all the distributional clustering methods examined here.", :author (#search_api.search_api.Author{:id 27645, :first-name nil, :last-name nil, :full-name "Noam Slonim"} #search_api.search_api.Author{:id 1164135, :first-name nil, :last-name nil, :full-name "Naftali Tishby"}), :year 2000, :venue "SIGIR", :ncit 364, :string "Document clustering using word clusters via the information bottleneck method.. We present a novel implementation of the recently introduced information bottleneck method for unsupervised document clustering. Given a joint empirical distribution of words and documents, p(x, y), we first cluster the words, Y, so that the obtained word clusters, Ytilde;, maximally preserve the information on the documents. The resulting joint distribution. p(X, Ytilde;), contains most of the original information about the documents, I(X; Ytilde;) &ap; I(X; Y), but it is much less sparse and noisy. Using the same procedure we then cluster the documents, X, so that the information about the word-clusters is preserved. Thus, we first find word-clusters that capture most of the mutual information about to set of documents, and then find document clusters, that preserve the information about the word clusters. We tested this procedure over several document collections based on subsets taken from the standard 20Newsgroups corpus. The results were assessed by calculating the correlation between the document clusters and the correct labels for these documents. Finding from our experiments show that this double clustering procedure, which uses the information bottleneck method, yields significantly superior performance compared to other common document distributional clustering algorithms. Moreover, the double clustering procedure improves all the distributional clustering methods examined here.", :doc-id "Document clustering using word clusters via the information bottleneck method. 2000  ,  "}, 594049 #search_api.search_api.Paper{:id 594049, :key "conf/siggraph/SmitsAG94", :title "A clustering algorithm for radiosity in complex environments.", :abstract "We present an approach for accelerating hierarchical radiosity by clustering objects. Previous approaches constructed effective hierarchies by subdividing surfaces, but could not exploit a hierarchical grouping on existing surfaces. This limitation resulted in an excessive number of initial links in complex environments. Initial linking is potentially the most expensive portion of hierarchical radiosity algorithms, and constrains the complexity of the environments that can be simulated. The clustering algorithm presented here operates by estimating energy transfer between collections of objects while maintaining reliable error bounds on each transfer. Two methods of bounding the transfers are employed with different tradeoffs between accuracy and time. In contrast with the O(s2) time and space complexity of the initial linking in previous hierarchical radiosity algorithms, the new methods have complexities of O(slogs) and O(s) for both time and space. Using these methods we have obtained speedups of two orders of magnitude for environments of moderate complexity while maintaining comparable accuracy.", :author (#search_api.search_api.Author{:id 703081, :first-name nil, :last-name nil, :full-name "Brian E. Smits"} #search_api.search_api.Author{:id 365508, :first-name nil, :last-name nil, :full-name "James Arvo"} #search_api.search_api.Author{:id 1021389, :first-name nil, :last-name nil, :full-name "Donald P. Greenberg"}), :year 1994, :venue "SIGGRAPH", :ncit 238, :string "A clustering algorithm for radiosity in complex environments.. We present an approach for accelerating hierarchical radiosity by clustering objects. Previous approaches constructed effective hierarchies by subdividing surfaces, but could not exploit a hierarchical grouping on existing surfaces. This limitation resulted in an excessive number of initial links in complex environments. Initial linking is potentially the most expensive portion of hierarchical radiosity algorithms, and constrains the complexity of the environments that can be simulated. The clustering algorithm presented here operates by estimating energy transfer between collections of objects while maintaining reliable error bounds on each transfer. Two methods of bounding the transfers are employed with different tradeoffs between accuracy and time. In contrast with the O(s2) time and space complexity of the initial linking in previous hierarchical radiosity algorithms, the new methods have complexities of O(slogs) and O(s) for both time and space. Using these methods we have obtained speedups of two orders of magnitude for environments of moderate complexity while maintaining comparable accuracy.", :doc-id "A clustering algorithm for radiosity in complex environments. 1994  ,  ,  "}, 1032258 #search_api.search_api.Paper{:id 1032258, :key "journals/pami/LiT01", :title "Hybrid Evolutionary Search Method Based on Clusters.", :abstract "This paper presents a hybrid evolutionary search method based on clusters (HESC). The method is specifically designed to enhance the search efficiency while alleviating the problem of premature convergence inherent in standard evolutionary search methods (SES). It involves the simultaneous evolution of a main species and an additional fast mutating species. A hybrid search method which includes a local parallel single agent search and a global multiagent evolutionary search is carried out for the main species. Effective utilization of the search history is achieved with the clustering and training of a fuzzy ART neural network (ART NN) during the search. The advantages of HESC include 1) guaranteed population diversity at each generation, 2) effective integration of local search for the exploitation of important regions and the global search for the exploration of the entire space, and 3) fast exploration ability of the fast mutating species and migration from the additional species to the main species. Those advantages have been confirmed with experiments in which hard optimization problems were successfully solved with HESC.", :author (#search_api.search_api.Author{:id 403809, :first-name nil, :last-name nil, :full-name "Ming Li"} #search_api.search_api.Author{:id 155750, :first-name nil, :last-name nil, :full-name "Hon-Yuen Tam"}), :year 2001, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 20, :string "Hybrid Evolutionary Search Method Based on Clusters.. This paper presents a hybrid evolutionary search method based on clusters (HESC). The method is specifically designed to enhance the search efficiency while alleviating the problem of premature convergence inherent in standard evolutionary search methods (SES). It involves the simultaneous evolution of a main species and an additional fast mutating species. A hybrid search method which includes a local parallel single agent search and a global multiagent evolutionary search is carried out for the main species. Effective utilization of the search history is achieved with the clustering and training of a fuzzy ART neural network (ART NN) during the search. The advantages of HESC include 1) guaranteed population diversity at each generation, 2) effective integration of local search for the exploitation of important regions and the global search for the exploration of the entire space, and 3) fast exploration ability of the fast mutating species and migration from the additional species to the main species. Those advantages have been confirmed with experiments in which hard optimization problems were successfully solved with HESC.", :doc-id "Hybrid Evolutionary Search Method Based on Clusters. 2001  ,  "}, 1031235 #search_api.search_api.Paper{:id 1031235, :key "journals/pami/CamastraV05", :title "A Novel Kernel Method for Clustering.", :abstract "Kernel Methods are algorithms that, by replacing the inner product with an appropriate positive definite function, implicitly perform a nonlinear mapping of the input data into a high-dimensional feature space. In this paper, we present a kernel method for clustering inspired by the classical K-Means algorithm in which each cluster is iteratively refined using a one-class Support Vector Machine. Our method, which can be easily implemented, compares favorably with respect to popular clustering algorithms, like K-Means, Neural Gas, and Self-Organizing Maps, on a synthetic data set and three UCI real data benchmarks (IRIS data, Wisconsin breast cancer database, Spam database).", :author (#search_api.search_api.Author{:id 662277, :first-name nil, :last-name nil, :full-name "Francesco Camastra"} #search_api.search_api.Author{:id 601093, :first-name nil, :last-name nil, :full-name "Alessandro Verri"}), :year 2005, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 223, :string "A Novel Kernel Method for Clustering.. Kernel Methods are algorithms that, by replacing the inner product with an appropriate positive definite function, implicitly perform a nonlinear mapping of the input data into a high-dimensional feature space. In this paper, we present a kernel method for clustering inspired by the classical K-Means algorithm in which each cluster is iteratively refined using a one-class Support Vector Machine. Our method, which can be easily implemented, compares favorably with respect to popular clustering algorithms, like K-Means, Neural Gas, and Self-Organizing Maps, on a synthetic data set and three UCI real data benchmarks (IRIS data, Wisconsin breast cancer database, Spam database).", :doc-id "A Novel Kernel Method for Clustering. 2005  ,  "}, 1009731 #search_api.search_api.Paper{:id 1009731, :key "journals/ml/MeilaH01", :title "An Experimental Comparison of Model-Based Clustering Methods.", :abstract "We compare the three basic algorithms for model-based clustering on high-dimensional discrete-variable datasets. All three algorithms use the same underlying model: a naive-Bayes model with a hidden root node, also known as a multinomial-mixture model. In the first part of the paper, we perform an experimental comparison between three batch algorithms that learn the parameters of this model: the Expectation&ndash;Maximization (EM) algorithm, a &ldquo;winner take all&rdquo; version of the EM algorithm reminiscent of the K-means algorithm, and model-based agglomerative clustering. We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization methods on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of agglomerative clustering. Although the methods are substantially different, they lead to learned models that are similar in quality.", :author (#search_api.search_api.Author{:id 564967, :first-name nil, :last-name nil, :full-name "Marina Meila"} #search_api.search_api.Author{:id 114083, :first-name nil, :last-name nil, :full-name "David Heckerman"}), :year 2001, :venue "Machine Learning", :ncit 145, :string "An Experimental Comparison of Model-Based Clustering Methods.. We compare the three basic algorithms for model-based clustering on high-dimensional discrete-variable datasets. All three algorithms use the same underlying model: a naive-Bayes model with a hidden root node, also known as a multinomial-mixture model. In the first part of the paper, we perform an experimental comparison between three batch algorithms that learn the parameters of this model: the Expectation&ndash;Maximization (EM) algorithm, a &ldquo;winner take all&rdquo; version of the EM algorithm reminiscent of the K-means algorithm, and model-based agglomerative clustering. We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization methods on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of agglomerative clustering. Although the methods are substantially different, they lead to learned models that are similar in quality.", :doc-id "An Experimental Comparison of Model-Based Clustering Methods. 2001  ,  "}, 3394083 #search_api.search_api.Paper{:id 3394083, :key "journals/jcst/PingTZY12", :title "Convex Decomposition Based Cluster Labeling Method for Support Vector Clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 1347038, :first-name nil, :last-name nil, :full-name "Yuan Ping"} #search_api.search_api.Author{:id 16774, :first-name nil, :last-name nil, :full-name "Ying-Jie Tian"} #search_api.search_api.Author{:id 14276041, :first-name nil, :last-name nil, :full-name "Ya-Jian Zhou"} #search_api.search_api.Author{:id 165956, :first-name nil, :last-name nil, :full-name "Yi-Xian Yang"}), :year 2012, :venue "J. Comput. Sci. Technol.", :ncit 1, :string "Convex Decomposition Based Cluster Labeling Method for Support Vector Clustering.. ", :doc-id "Convex Decomposition Based Cluster Labeling Method for Support Vector Clustering. 2012  ,  ,  ,  "}, 1032835 #search_api.search_api.Paper{:id 1032835, :key "journals/pami/RoseGF93", :title "Constrained Clustering as an Optimization Method.", :abstract "A deterministic annealing approach to clustering is derived on the basis of the principle of maximum entropy. This approach is independent of the initial state and produces natural hierarchical clustering solutions by going through a sequence of phase transitions. It is modified for a larger class of optimization problems by adding constraints to the free energy. The concept of constrained clustering is explained, and three examples are are given in which it is used to introduce deterministic annealing. The previous clustering method is improved by adding cluster mass variables and a total mass constraint. The traveling salesman problem is reformulated as constrained clustering, yielding the elastic net (EN) approach to the problem. More insight is gained by identifying a second Lagrange multiplier that is related to the tour length and can also be used to control the annealing process. The open path constraint formulation is shown to relate to dimensionality reduction by self-organization in unsupervised learning. A similar annealing procedure is applicable in this case as well.", :author (#search_api.search_api.Author{:id 644746, :first-name nil, :last-name nil, :full-name "Kenneth Rose"} #search_api.search_api.Author{:id 189455, :first-name nil, :last-name nil, :full-name "Eitan Gurewitz"} #search_api.search_api.Author{:id 851606, :first-name nil, :last-name nil, :full-name "Geoffrey Fox"}), :year 1993, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 161, :string "Constrained Clustering as an Optimization Method.. A deterministic annealing approach to clustering is derived on the basis of the principle of maximum entropy. This approach is independent of the initial state and produces natural hierarchical clustering solutions by going through a sequence of phase transitions. It is modified for a larger class of optimization problems by adding constraints to the free energy. The concept of constrained clustering is explained, and three examples are are given in which it is used to introduce deterministic annealing. The previous clustering method is improved by adding cluster mass variables and a total mass constraint. The traveling salesman problem is reformulated as constrained clustering, yielding the elastic net (EN) approach to the problem. More insight is gained by identifying a second Lagrange multiplier that is related to the tour length and can also be used to control the annealing process. The open path constraint formulation is shown to relate to dimensionality reduction by self-organization in unsupervised learning. A similar annealing procedure is applicable in this case as well.", :doc-id "Constrained Clustering as an Optimization Method. 1993  ,  ,  "}, 1031939 #search_api.search_api.Paper{:id 1031939, :key "journals/pami/JainDM00", :title "Statistical Pattern Recognition: A Review.", :abstract "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.", :author (#search_api.search_api.Author{:id 324696, :first-name nil, :last-name nil, :full-name "Anil K. Jain"} #search_api.search_api.Author{:id 189517, :first-name nil, :last-name nil, :full-name "Robert P. W. Duin"} #search_api.search_api.Author{:id 447337, :first-name nil, :last-name nil, :full-name "Jianchang Mao"}), :year 2000, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 4345, :string "Statistical Pattern Recognition: A Review.. The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.", :doc-id "Statistical Pattern Recognition: A Review. 2000  ,  ,  "}, 597891 #search_api.search_api.Paper{:id 597891, :key "conf/sigmod/AnkerstBKS99", :title "OPTICS: Ordering Points To Identify the Clustering Structure.", :abstract "Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only 'traditional' clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.", :author (#search_api.search_api.Author{:id 762749, :first-name nil, :last-name nil, :full-name "Mihael Ankerst"} #search_api.search_api.Author{:id 899900, :first-name nil, :last-name nil, :full-name "Markus M. Breunig"} #search_api.search_api.Author{:id 228306, :first-name nil, :last-name nil, :full-name "Hans-Peter Kriegel"} #search_api.search_api.Author{:id 940742, :first-name nil, :last-name nil, :full-name "Jörg Sander"}), :year 1999, :venue "SIGMOD Conference", :ncit 1541, :string "OPTICS: Ordering Points To Identify the Clustering Structure.. Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only 'traditional' clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.", :doc-id "OPTICS: Ordering Points To Identify the Clustering Structure. 1999  ,  ,  ,  "}, 985059 #search_api.search_api.Paper{:id 985059, :key "journals/jmlr/MarxDBS02", :title "Coupled Clustering: A Method for Detecting Structural Correspondence.", :abstract "This paper proposes a new paradigm and a computational framework for revealing equivalencies (analogies) between sub-structures of distinct composite systems that are initially represented by unstructured data sets. For this purpose, we introduce and investigate a variant of traditional data clustering, termed coupled clustering, which outputs a configuration of corresponding subsets of two such representative sets. We apply our method to synthetic as well as textual data. Its achievements in detecting topical correspondences between textual corpora are evaluated through comparison to performance of human experts.", :author (#search_api.search_api.Author{:id 793220, :first-name nil, :last-name nil, :full-name "Zvika Marx"} #search_api.search_api.Author{:id 135545, :first-name nil, :last-name nil, :full-name "Ido Dagan"} #search_api.search_api.Author{:id 1122223, :first-name nil, :last-name nil, :full-name "Joachim M. Buhmann"} #search_api.search_api.Author{:id 1191060, :first-name nil, :last-name nil, :full-name "Eli Shamir"}), :year 2002, :venue "Journal of Machine Learning Research", :ncit 41, :string "Coupled Clustering: A Method for Detecting Structural Correspondence.. This paper proposes a new paradigm and a computational framework for revealing equivalencies (analogies) between sub-structures of distinct composite systems that are initially represented by unstructured data sets. For this purpose, we introduce and investigate a variant of traditional data clustering, termed coupled clustering, which outputs a configuration of corresponding subsets of two such representative sets. We apply our method to synthetic as well as textual data. Its achievements in detecting topical correspondences between textual corpora are evaluated through comparison to performance of human experts.", :doc-id "Coupled Clustering: A Method for Detecting Structural Correspondence. 2002  ,  ,  ,  "}, 832677 #search_api.search_api.Paper{:id 832677, :key "journals/csur/JainMF99", :title "Data Clustering: A Review.", :abstract "Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.", :author (#search_api.search_api.Author{:id 324696, :first-name nil, :last-name nil, :full-name "Anil K. Jain"} #search_api.search_api.Author{:id 1191133, :first-name nil, :last-name nil, :full-name "M. Narasimha Murty"} #search_api.search_api.Author{:id 186342, :first-name nil, :last-name nil, :full-name "Patrick J. Flynn"}), :year 1999, :venue "ACM Comput. Surv.", :ncit 8116, :string "Data Clustering: A Review.. Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.", :doc-id "Data Clustering: A Review. 1999  ,  ,  "}, 1033413 #search_api.search_api.Paper{:id 1033413, :key "journals/pami/YipDC06", :title "Dynamic Cluster Formation Using Level Set Methods.", :abstract "Density-based clustering has the advantages for 1) allowing arbitrary shape of cluster and 2) not requiring the number of clusters as input. However, when clusters touch each other, both the cluster centers and cluster boundaries (as the peaks and valleys of the density distribution) become fuzzy and difficult to determine. We introduce the notion of cluster intensity function (CIF) which captures the important characteristics of clusters. When clusters are well-separated, CIFs are similar to density functions. But, when clusters become closed to each other, CIFs still clearly reveal cluster centers, cluster boundaries, and degree of membership of each data point to the cluster that it belongs. Clustering through bump hunting and valley seeking based on these functions are more robust than that based on density functions obtained by kernel density estimation, which are often oscillatory or oversmoothed. These problems of kernel density estimation are resolved using Level Set Methods and related techniques. Comparisons with two existing density-based methods, valley seeking and DBSCAN, are presented which illustrate the advantages of our approach.", :author (#search_api.search_api.Author{:id 457109, :first-name nil, :last-name nil, :full-name "Andy M. Yip"} #search_api.search_api.Author{:id 54204, :first-name nil, :last-name nil, :full-name "Chris H. Q. Ding"} #search_api.search_api.Author{:id 246588, :first-name nil, :last-name nil, :full-name "Tony F. Chan"}), :year 2006, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 43, :string "Dynamic Cluster Formation Using Level Set Methods.. Density-based clustering has the advantages for 1) allowing arbitrary shape of cluster and 2) not requiring the number of clusters as input. However, when clusters touch each other, both the cluster centers and cluster boundaries (as the peaks and valleys of the density distribution) become fuzzy and difficult to determine. We introduce the notion of cluster intensity function (CIF) which captures the important characteristics of clusters. When clusters are well-separated, CIFs are similar to density functions. But, when clusters become closed to each other, CIFs still clearly reveal cluster centers, cluster boundaries, and degree of membership of each data point to the cluster that it belongs. Clustering through bump hunting and valley seeking based on these functions are more robust than that based on density functions obtained by kernel density estimation, which are often oscillatory or oversmoothed. These problems of kernel density estimation are resolved using Level Set Methods and related techniques. Comparisons with two existing density-based methods, valley seeking and DBSCAN, are presented which illustrate the advantages of our approach.", :doc-id "Dynamic Cluster Formation Using Level Set Methods. 2006  ,  ,  "}, 3509574 #search_api.search_api.Paper{:id 3509574, :key "conf/c3s2e/HossainBWH12", :title "An effective ensemble method for hierarchical clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 283398, :first-name nil, :last-name nil, :full-name "Mahmood Hossain"} #search_api.search_api.Author{:id 769857, :first-name nil, :last-name nil, :full-name "Susan M. Bridges"} #search_api.search_api.Author{:id 28232, :first-name nil, :last-name nil, :full-name "Yong Wang"} #search_api.search_api.Author{:id 471152, :first-name nil, :last-name nil, :full-name "Julia E. Hodges"}), :year 2012, :venue "C3S2E", :ncit 0, :string "An effective ensemble method for hierarchical clustering.. ", :doc-id "An effective ensemble method for hierarchical clustering. 2012  ,  ,  ,  "}, 839752 #search_api.search_api.Paper{:id 839752, :key "journals/datamine/PeiJHZZ09", :title "DECODE: a new method for discovering clusters of different densities in spatial data.", :abstract "When clusters with different densities and noise lie in a spatial point set, the major obstacle to classifying these data is the determination of the thresholds for classification, which may form a series of bins for allocating each point to different clusters. Much of the previous work has adopted a model-based approach, but is either incapable of estimating the thresholds in an automatic way, or limited to only two point processes, i.e. noise and clusters with the same density. In this paper, we present a new density-based cluster method (DECODE), in which a spatial data set is presumed to consist of different point processes and clusters with different densities belong to different point processes. DECODE is based upon a reversible jump Markov Chain Monte Carlo (MCMC) strategy and divided into three steps. The first step is to map each point in the data to its mth nearest distance, which is referred to as the distance between a point and its mth nearest neighbor. In the second step, classification thresholds are determined via a reversible jump MCMC strategy. In the third step, clusters are formed by spatially connecting the points whose mth nearest distances fall into a particular bin defined by the thresholds. Four experiments, including two simulated data sets and two seismic data sets, are used to evaluate the algorithm. Results on simulated data show that our approach is capable of discovering the clusters automatically. Results on seismic data suggest that the clustered earthquakes, identified by DECODE, either imply the epicenters of forthcoming strong earthquakes or indicate the areas with the most intensive seismicity, this is consistent with the tectonic states and estimated stress distribution in the associated areas. The comparison between DECODE and other state-of-the-art methods, such as DBSCAN, OPTICS and Wavelet Cluster, illustrates the contribution of our approach: although DECODE can be computationally expensive, it is capable of identifying the number of point processes and simultaneously estimating the classification thresholds with little prior knowledge.", :author (#search_api.search_api.Author{:id 17009, :first-name nil, :last-name nil, :full-name "Tao Pei"} #search_api.search_api.Author{:id 444275, :first-name nil, :last-name nil, :full-name "Ajay Jasra"} #search_api.search_api.Author{:id 882980, :first-name nil, :last-name nil, :full-name "David J. Hand"} #search_api.search_api.Author{:id 1195063, :first-name nil, :last-name nil, :full-name "A-Xing Zhu"} #search_api.search_api.Author{:id 58862, :first-name nil, :last-name nil, :full-name "Chenghu Zhou"}), :year 2009, :venue "Data Min. Knowl. Discov.", :ncit 13, :string "DECODE: a new method for discovering clusters of different densities in spatial data.. When clusters with different densities and noise lie in a spatial point set, the major obstacle to classifying these data is the determination of the thresholds for classification, which may form a series of bins for allocating each point to different clusters. Much of the previous work has adopted a model-based approach, but is either incapable of estimating the thresholds in an automatic way, or limited to only two point processes, i.e. noise and clusters with the same density. In this paper, we present a new density-based cluster method (DECODE), in which a spatial data set is presumed to consist of different point processes and clusters with different densities belong to different point processes. DECODE is based upon a reversible jump Markov Chain Monte Carlo (MCMC) strategy and divided into three steps. The first step is to map each point in the data to its mth nearest distance, which is referred to as the distance between a point and its mth nearest neighbor. In the second step, classification thresholds are determined via a reversible jump MCMC strategy. In the third step, clusters are formed by spatially connecting the points whose mth nearest distances fall into a particular bin defined by the thresholds. Four experiments, including two simulated data sets and two seismic data sets, are used to evaluate the algorithm. Results on simulated data show that our approach is capable of discovering the clusters automatically. Results on seismic data suggest that the clustered earthquakes, identified by DECODE, either imply the epicenters of forthcoming strong earthquakes or indicate the areas with the most intensive seismicity, this is consistent with the tectonic states and estimated stress distribution in the associated areas. The comparison between DECODE and other state-of-the-art methods, such as DBSCAN, OPTICS and Wavelet Cluster, illustrates the contribution of our approach: although DECODE can be computationally expensive, it is capable of identifying the number of point processes and simultaneously estimating the classification thresholds with little prior knowledge.", :doc-id "DECODE: a new method for discovering clusters of different densities in spatial data. 2009  ,  ,  ,  ,  "}, 1009800 #search_api.search_api.Paper{:id 1009800, :key "journals/ml/MontiTMG03", :title "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data.", :abstract "In this paper we present a new methodology of class discovery and clustering validation tailored to the task of analyzing gene expression data. The method can best be thought of as an analysis approach, to guide and assist in the use of any of a wide range of available clustering algorithms. We call the new methodology consensus clustering, and in conjunction with resampling techniques, it provides for a method to represent the consensus across multiple runs of a clustering algorithm and to assess the stability of the discovered clusters. The method can also be used to represent the consensus over multiple runs of a clustering algorithm with random restart (such as K-means, model-based Bayesian clustering, SOM, etc.), so as to account for its sensitivity to the initial conditions. Finally, it provides for a visualization tool to inspect cluster number, membership, and boundaries. We present the results of our experiments on both simulated data and real gene expression data aimed at evaluating the effectiveness of the methodology in discovering biologically meaningful clusters.", :author (#search_api.search_api.Author{:id 220806, :first-name nil, :last-name nil, :full-name "Stefano Monti"} #search_api.search_api.Author{:id 1414792, :first-name nil, :last-name nil, :full-name "Pablo Tamayo"} #search_api.search_api.Author{:id 312859, :first-name nil, :last-name nil, :full-name "Jill P. Mesirov"} #search_api.search_api.Author{:id 1071454, :first-name nil, :last-name nil, :full-name "Todd R. Golub"}), :year 2003, :venue "Machine Learning", :ncit 563, :string "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data.. In this paper we present a new methodology of class discovery and clustering validation tailored to the task of analyzing gene expression data. The method can best be thought of as an analysis approach, to guide and assist in the use of any of a wide range of available clustering algorithms. We call the new methodology consensus clustering, and in conjunction with resampling techniques, it provides for a method to represent the consensus across multiple runs of a clustering algorithm and to assess the stability of the discovered clusters. The method can also be used to represent the consensus over multiple runs of a clustering algorithm with random restart (such as K-means, model-based Bayesian clustering, SOM, etc.), so as to account for its sensitivity to the initial conditions. Finally, it provides for a visualization tool to inspect cluster number, membership, and boundaries. We present the results of our experiments on both simulated data and real gene expression data aimed at evaluating the effectiveness of the methodology in discovering biologically meaningful clusters.", :doc-id "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data. 2003  ,  ,  ,  "}, 3307625 #search_api.search_api.Paper{:id 3307625, :key "journals/wicomm/LiMS12", :title "Determination method of optimal number of clusters for clustered wireless sensor networks.", :abstract nil, :author (#search_api.search_api.Author{:id 823, :first-name nil, :last-name nil, :full-name "Wenfeng Li"} #search_api.search_api.Author{:id 1328653, :first-name nil, :last-name nil, :full-name "Philippe Martins"} #search_api.search_api.Author{:id 22605, :first-name nil, :last-name nil, :full-name "Lianfeng Shen"}), :year 2012, :venue "Wireless Communications and Mobile Computing", :ncit 4, :string "Determination method of optimal number of clusters for clustered wireless sensor networks.. ", :doc-id "Determination method of optimal number of clusters for clustered wireless sensor networks. 2012  ,  ,  "}, 27498 #search_api.search_api.Paper{:id 27498, :key "conf/adma/WangW07", :title "A Fuzzy Comprehensive Clustering Method.", :abstract "Fuzzy comprehensive evaluation cannot reasonably differentiate the close membership values, e.g. 0.70 and 0.69. When the results have to be decided on the basis of maximum fuzzy membership value, some related information among similar objects may be neglected. At the same time, supervised fuzzy clustering analysis selects the threshold according to subjective experience. But different users may give different thresholds, and different thresholds may further get different clustering results. Integrating both fuzzy comprehensive evaluation and fuzzy clustering analysis in a unified way, this paper proposes a fuzzy comprehensive clustering method based on the maximum remainder algorithms and maximum characteristics algorithms. First, the principle of fuzzy comprehensive clustering is given. Based on the membership matrix of fuzzy comprehensive evaluation, fuzzy similar matrix is generated. Then a fuzzy equivalent matrix is produced from the fuzzy similar matrix. According to the fuzzy equivalent matrix, fuzzy clustering is implemented via the maximum remainder algorithms on the basis of fuzzy confidence level. And the grades of the resulting clusters are computed by using the maximum characteristics algorithms. Finally, a case study is given on land grading in Nanning city, the results of which show the proposed fuzzy comprehensive clustering method is able to overcome the disadvantages of either fuzzy comprehensive evaluation or fuzzy clustering analysis.", :author (#search_api.search_api.Author{:id 936520, :first-name nil, :last-name nil, :full-name "Shuliang Wang"} #search_api.search_api.Author{:id 604069, :first-name nil, :last-name nil, :full-name "Xinzhou Wang"}), :year 2007, :venue "ADMA", :ncit 3, :string "A Fuzzy Comprehensive Clustering Method.. Fuzzy comprehensive evaluation cannot reasonably differentiate the close membership values, e.g. 0.70 and 0.69. When the results have to be decided on the basis of maximum fuzzy membership value, some related information among similar objects may be neglected. At the same time, supervised fuzzy clustering analysis selects the threshold according to subjective experience. But different users may give different thresholds, and different thresholds may further get different clustering results. Integrating both fuzzy comprehensive evaluation and fuzzy clustering analysis in a unified way, this paper proposes a fuzzy comprehensive clustering method based on the maximum remainder algorithms and maximum characteristics algorithms. First, the principle of fuzzy comprehensive clustering is given. Based on the membership matrix of fuzzy comprehensive evaluation, fuzzy similar matrix is generated. Then a fuzzy equivalent matrix is produced from the fuzzy similar matrix. According to the fuzzy equivalent matrix, fuzzy clustering is implemented via the maximum remainder algorithms on the basis of fuzzy confidence level. And the grades of the resulting clusters are computed by using the maximum characteristics algorithms. Finally, a case study is given on land grading in Nanning city, the results of which show the proposed fuzzy comprehensive clustering method is able to overcome the disadvantages of either fuzzy comprehensive evaluation or fuzzy clustering analysis.", :doc-id "A Fuzzy Comprehensive Clustering Method. 2007  ,  "}, 527435 #search_api.search_api.Paper{:id 527435, :key "conf/pakdd/CrabtreeAG07", :title "QC4 - A Clustering Evaluation Method.", :abstract "Many clustering algorithms have been developed and researchers need to be able to compare their effectiveness. For some clustering problems, like web page clustering, different algorithms produce clusterings with different characteristics: coarse vs fine granularity, disjoint vs overlapping, flat vs hierarchical. The lack of a clustering evaluation method that can evaluate clusterings with different characteristics has led to incomparable research and results. QC4 solves this by providing a new structure for defining general ideal clusterings and new measurements for evaluating clusterings with different characteristics with respect to a general ideal clustering. The paper describes QC4 and evaluates it within the web clustering domain by comparison to existing evaluation measurements on synthetic test cases and on real world web page clustering tasks. The synthetic test cases show that only QC4 can cope correctly with overlapping clusters, hierarchical clusterings, and all the difficult boundary cases. In the real world tasks, which represent simple clustering situations, QC4 is mostly consistent with the existing measurements and makes better conclusions in some cases.", :author (#search_api.search_api.Author{:id 698966, :first-name nil, :last-name nil, :full-name "Daniel Crabtree"} #search_api.search_api.Author{:id 97078, :first-name nil, :last-name nil, :full-name "Peter Andreae"} #search_api.search_api.Author{:id 286163, :first-name nil, :last-name nil, :full-name "Xiaoying Gao"}), :year 2007, :venue "PAKDD", :ncit 9, :string "QC4 - A Clustering Evaluation Method.. Many clustering algorithms have been developed and researchers need to be able to compare their effectiveness. For some clustering problems, like web page clustering, different algorithms produce clusterings with different characteristics: coarse vs fine granularity, disjoint vs overlapping, flat vs hierarchical. The lack of a clustering evaluation method that can evaluate clusterings with different characteristics has led to incomparable research and results. QC4 solves this by providing a new structure for defining general ideal clusterings and new measurements for evaluating clusterings with different characteristics with respect to a general ideal clustering. The paper describes QC4 and evaluates it within the web clustering domain by comparison to existing evaluation measurements on synthetic test cases and on real world web page clustering tasks. The synthetic test cases show that only QC4 can cope correctly with overlapping clusters, hierarchical clusterings, and all the difficult boundary cases. In the real world tasks, which represent simple clustering situations, QC4 is mostly consistent with the existing measurements and makes better conclusions in some cases.", :doc-id "QC4 - A Clustering Evaluation Method. 2007  ,  ,  "}, 1219659 #search_api.search_api.Paper{:id 1219659, :key "journals/bioinformatics/LinTCBSF08", :title "Smarter clustering methods for SNP genotype calling.", :abstract "Motivation: Most genotyping technologies for single nucleotide polymorphism (SNP) markers use standard clustering methods to ‘call’ the SNP genotypes. These methods are not always optimal in distinguishing the genotype clusters of a SNP because they do not take advantage of specific features of the genotype calling problem. In particular, when family data are available, pedigree information is ignored. Furthermore, prior information about the distribution of the measurements for each cluster can be used to choose an appropriate model-based clustering method and can significantly improve the genotype calls. One special genotyping problem that has never been discussed in the literature is that of genotyping of trisomic individuals, such as individuals with Down syndrome. Calling trisomic genotypes is a more complicated problem, and the addition of external information becomes very important. Results: In this article, we discuss the impact of incorporating external information into clustering algorithms to call the genotypes for both disomic and trisomic data. We also propose two new methods to call genotypes using family data. One is a modification of the K-means method and uses the pedigree information by updating all members of a family together. The other is a likelihood-based method that combines the Gaussian or beta-mixture model with pedigree information. We compare the performance of these two methods and some other existing methods using simulation studies. We also compare the performance of these methods on a real dataset generated by the Illumina platform ( www.illumina.com). Availability: The R code for the family-based genotype calling methods (SNPCaller) is available to be downloaded from the following website: http://watson.hgen.pitt.edu/register. Contact: liny@upmc.edu Supplementary information:Supplementary data are available at Bioinformatics online.", :author (#search_api.search_api.Author{:id 293647, :first-name nil, :last-name nil, :full-name "Yan Lin"} #search_api.search_api.Author{:id 503391, :first-name nil, :last-name nil, :full-name "George C. Tseng"} #search_api.search_api.Author{:id 1480924, :first-name nil, :last-name nil, :full-name "Soo Yeon Cheong"} #search_api.search_api.Author{:id 65191, :first-name nil, :last-name nil, :full-name "Lora J. H. Bean"} #search_api.search_api.Author{:id 1388696, :first-name nil, :last-name nil, :full-name "Stephanie L. Sherman"} #search_api.search_api.Author{:id 632614, :first-name nil, :last-name nil, :full-name "Eleanor Feingold"}), :year 2008, :venue "Bioinformatics", :ncit 8, :string "Smarter clustering methods for SNP genotype calling.. Motivation: Most genotyping technologies for single nucleotide polymorphism (SNP) markers use standard clustering methods to ‘call’ the SNP genotypes. These methods are not always optimal in distinguishing the genotype clusters of a SNP because they do not take advantage of specific features of the genotype calling problem. In particular, when family data are available, pedigree information is ignored. Furthermore, prior information about the distribution of the measurements for each cluster can be used to choose an appropriate model-based clustering method and can significantly improve the genotype calls. One special genotyping problem that has never been discussed in the literature is that of genotyping of trisomic individuals, such as individuals with Down syndrome. Calling trisomic genotypes is a more complicated problem, and the addition of external information becomes very important. Results: In this article, we discuss the impact of incorporating external information into clustering algorithms to call the genotypes for both disomic and trisomic data. We also propose two new methods to call genotypes using family data. One is a modification of the K-means method and uses the pedigree information by updating all members of a family together. The other is a likelihood-based method that combines the Gaussian or beta-mixture model with pedigree information. We compare the performance of these two methods and some other existing methods using simulation studies. We also compare the performance of these methods on a real dataset generated by the Illumina platform ( www.illumina.com). Availability: The R code for the family-based genotype calling methods (SNPCaller) is available to be downloaded from the following website: http://watson.hgen.pitt.edu/register. Contact: liny@upmc.edu Supplementary information:Supplementary data are available at Bioinformatics online.", :doc-id "Smarter clustering methods for SNP genotype calling. 2008  ,  ,  ,  ,  ,  "}, 1023181 #search_api.search_api.Paper{:id 1023181, :key "journals/neco/LevineD01", :title "Resampling Method for Unsupervised Estimation of Cluster Validity.", :abstract "We introduce a method for validation of results obtained by clustering analysis of data. The method is based on resampling the available data. A figure of merit that measures the stability of clustering solutions against resampling is introduced. Clusters that are stable against resampling give rise to local maxima of this figure of merit. This is presented first for a one-dimensional data set, for which an analytic approximation for the figure of merit is derived and compared with numerical measurements. Next, the applicability of the method is demonstrated for higher-dimensional data, including gene microarray expression data.", :author (#search_api.search_api.Author{:id 702949, :first-name nil, :last-name nil, :full-name "Erel Levine"} #search_api.search_api.Author{:id 151361, :first-name nil, :last-name nil, :full-name "Eytan Domany"}), :year 2001, :venue "Neural Computation", :ncit 204, :string "Resampling Method for Unsupervised Estimation of Cluster Validity.. We introduce a method for validation of results obtained by clustering analysis of data. The method is based on resampling the available data. A figure of merit that measures the stability of clustering solutions against resampling is introduced. Clusters that are stable against resampling give rise to local maxima of this figure of merit. This is presented first for a one-dimensional data set, for which an analytic approximation for the figure of merit is derived and compared with numerical measurements. Next, the applicability of the method is demonstrated for higher-dimensional data, including gene microarray expression data.", :doc-id "Resampling Method for Unsupervised Estimation of Cluster Validity. 2001  ,  "}, 839501 #search_api.search_api.Paper{:id 839501, :key "journals/datamine/Xia09", :title "A global optimization method for semi-supervised clustering.", :abstract "In this paper, we adapt Tuy's concave cutting plane method to the semi-supervised clustering. We also give properties of local optimal solutions of the semi-supervised clustering. Numerical examples show that this method can give a better solution than other semi-supervised clustering algorithms do.", :author (#search_api.search_api.Author{:id 412580, :first-name nil, :last-name nil, :full-name "Yu Xia"}), :year 2009, :venue "Data Min. Knowl. Discov.", :ncit 3, :string "A global optimization method for semi-supervised clustering.. In this paper, we adapt Tuy's concave cutting plane method to the semi-supervised clustering. We also give properties of local optimal solutions of the semi-supervised clustering. Numerical examples show that this method can give a better solution than other semi-supervised clustering algorithms do.", :doc-id "A global optimization method for semi-supervised clustering. 2009  "}, 939118 #search_api.search_api.Paper{:id 939118, :key "journals/is/YunCC06", :title "Adherence clustering: an efficient method for mining market-basket clusters.", :abstract "We explore in this paper the efficient clustering of market-basket data. Different from those of the traditional data, the features of market-basket data are known to be of high dimensionality and sparsity. Without explicitly considering the presence of the taxonomy, most prior efforts on clustering market-basket data can be viewed as dealing with items in the leaf level of the taxonomy tree. Clustering transactions across different levels of the taxonomy is of great importance for marketing strategies as well as for the result representation of the clustering techniques for market-basket data. In view of the features of market-basket data, we devise in this paper a novel measurement, called the category-based adherence, and utilize this measurement to perform the clustering. With this category-based adherence measurement, we develop an efficient clustering algorithm, called algorithm k-todes, for market-basket data with the objective to minimize the category-based adherence. The distance of an item to a given cluster is defined as the number of links between this item and its nearest tode. The category-based adherence of a transaction to a cluster is then defined as the average distance of the items in this transaction to that cluster. A validation model based on information gain is also devised to assess the quality of clustering for market-basket data. As validated by both real and synthetic datasets, it is shown by our experimental results, with the taxonomy information, algorithm k-todes devised in this paper significantly outperforms the prior works in both the execution efficiency and the clustering quality as measured by information gain, indicating the usefulness of category-based adherence in market-basket data clustering.", :author (#search_api.search_api.Author{:id 698395, :first-name nil, :last-name nil, :full-name "Ching-Huang Yun"} #search_api.search_api.Author{:id 901470, :first-name nil, :last-name nil, :full-name "Kun-Ta Chuang"} #search_api.search_api.Author{:id 6987, :first-name nil, :last-name nil, :full-name "Ming-Syan Chen"}), :year 2006, :venue "Inf. Syst.", :ncit 10, :string "Adherence clustering: an efficient method for mining market-basket clusters.. We explore in this paper the efficient clustering of market-basket data. Different from those of the traditional data, the features of market-basket data are known to be of high dimensionality and sparsity. Without explicitly considering the presence of the taxonomy, most prior efforts on clustering market-basket data can be viewed as dealing with items in the leaf level of the taxonomy tree. Clustering transactions across different levels of the taxonomy is of great importance for marketing strategies as well as for the result representation of the clustering techniques for market-basket data. In view of the features of market-basket data, we devise in this paper a novel measurement, called the category-based adherence, and utilize this measurement to perform the clustering. With this category-based adherence measurement, we develop an efficient clustering algorithm, called algorithm k-todes, for market-basket data with the objective to minimize the category-based adherence. The distance of an item to a given cluster is defined as the number of links between this item and its nearest tode. The category-based adherence of a transaction to a cluster is then defined as the average distance of the items in this transaction to that cluster. A validation model based on information gain is also devised to assess the quality of clustering for market-basket data. As validated by both real and synthetic datasets, it is shown by our experimental results, with the taxonomy information, algorithm k-todes devised in this paper significantly outperforms the prior works in both the execution efficiency and the clustering quality as measured by information gain, indicating the usefulness of category-based adherence in market-basket data clustering.", :doc-id "Adherence clustering: an efficient method for mining market-basket clusters. 2006  ,  ,  "}, 893422 #search_api.search_api.Paper{:id 893422, :key "journals/ida/OmranES07", :title "An overview of clustering methods.", :abstract "Data clustering is the process of identifying natural groupings or clusters within multidimensional data based on some similarity measure. Clustering is a fundamental process in many different disciplines. Hence, researchers from different fields are actively working on the clustering problem. This paper provides an overview of the different representative clustering methods. In addition, several clustering validations indices are shown. Furthermore, approaches to automatically determine the number of clusters are presented. Finally, application of different heuristic approaches to the clustering problem is also investigated.", :author (#search_api.search_api.Author{:id 117152, :first-name nil, :last-name nil, :full-name "Mahamed G. Omran"} #search_api.search_api.Author{:id 621177, :first-name nil, :last-name nil, :full-name "Andries Petrus Engelbrecht"} #search_api.search_api.Author{:id 319269, :first-name nil, :last-name nil, :full-name "Ayed A. Salman"}), :year 2007, :venue "Intell. Data Anal.", :ncit 45, :string "An overview of clustering methods.. Data clustering is the process of identifying natural groupings or clusters within multidimensional data based on some similarity measure. Clustering is a fundamental process in many different disciplines. Hence, researchers from different fields are actively working on the clustering problem. This paper provides an overview of the different representative clustering methods. In addition, several clustering validations indices are shown. Furthermore, approaches to automatically determine the number of clusters are presented. Finally, application of different heuristic approaches to the clustering problem is also investigated.", :doc-id "An overview of clustering methods. 2007  ,  ,  "}, 1031215 #search_api.search_api.Paper{:id 1031215, :key "journals/pami/CaelliK04", :title "An Eigenspace Projection Clustering Method for Inexact Graph Matching.", :abstract "Abstract--In this paper, we show how inexact graph matching (that is, the correspondence between sets of vertices of pairs of graphs) can be solved using the renormalization of projections of the vertices (as defined in this case by their connectivities) into the joint eigenspace of a pair of graphs and a form of relational clustering. An important feature of this eigenspace renormalization projection clustering (EPC) method is its ability to match graphs with different number of vertices. Shock graph-based shape matching is used to illustrate the model and a more objective method for evaluating the approach using random graphs is explored with encouraging results.", :author (#search_api.search_api.Author{:id 627606, :first-name nil, :last-name nil, :full-name "Terry Caelli"} #search_api.search_api.Author{:id 484276, :first-name nil, :last-name nil, :full-name "Serhiy Kosinov"}), :year 2004, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 121, :string "An Eigenspace Projection Clustering Method for Inexact Graph Matching.. Abstract--In this paper, we show how inexact graph matching (that is, the correspondence between sets of vertices of pairs of graphs) can be solved using the renormalization of projections of the vertices (as defined in this case by their connectivities) into the joint eigenspace of a pair of graphs and a form of relational clustering. An important feature of this eigenspace renormalization projection clustering (EPC) method is its ability to match graphs with different number of vertices. Shock graph-based shape matching is used to illustrate the model and a more objective method for evaluating the approach using random graphs is explored with encouraging results.", :doc-id "An Eigenspace Projection Clustering Method for Inexact Graph Matching. 2004  ,  "}, 1033455 #search_api.search_api.Paper{:id 1033455, :key "journals/pami/YangW04", :title "A Similarity-Based Robust Clustering Method.", :abstract "Abstract--This paper presents an alternating optimization clustering procedure called a similarity-based clustering method (SCM). It is an effective and robust approach to clustering on the basis of a total similarity objective function related to the approximate density shape estimation. We show that the data points in SCM can self-organize local optimal cluster number and volumes without using cluster validity functions or a variance-covariance matrix. The proposed clustering method is also robust to noise and outliers based on the influence function and gross error sensitivity analysis. Therefore, SCM exhibits three robust clustering characteristics: 1) robust to the initialization (cluster number and initial guesses), 2) robust to cluster volumes (ability to detect different volumes of clusters), and 3) robust to noise and outliers. Several numerical data sets and actual data are used in the SCM to show these good aspects. The computational complexity of SCM is also analyzed. Some experimental results of comparing the proposed SCM with the existing methods show the superiority of the SCM method.", :author (#search_api.search_api.Author{:id 1103232, :first-name nil, :last-name nil, :full-name "Miin-Shen Yang"} #search_api.search_api.Author{:id 61859, :first-name nil, :last-name nil, :full-name "Kuo-Lung Wu"}), :year 2004, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 138, :string "A Similarity-Based Robust Clustering Method.. Abstract--This paper presents an alternating optimization clustering procedure called a similarity-based clustering method (SCM). It is an effective and robust approach to clustering on the basis of a total similarity objective function related to the approximate density shape estimation. We show that the data points in SCM can self-organize local optimal cluster number and volumes without using cluster validity functions or a variance-covariance matrix. The proposed clustering method is also robust to noise and outliers based on the influence function and gross error sensitivity analysis. Therefore, SCM exhibits three robust clustering characteristics: 1) robust to the initialization (cluster number and initial guesses), 2) robust to cluster volumes (ability to detect different volumes of clusters), and 3) robust to noise and outliers. Several numerical data sets and actual data are used in the SCM to show these good aspects. The computational complexity of SCM is also analyzed. Some experimental results of comparing the proposed SCM with the existing methods show the superiority of the SCM method.", :doc-id "A Similarity-Based Robust Clustering Method. 2004  ,  "}, 2966831 #search_api.search_api.Paper{:id 2966831, :key "journals/corr/abs-1101-4270", :title "A Comparative Agglomerative Hierarchical Clustering Method to Cluster Implemented Course", :abstract nil, :author (#search_api.search_api.Author{:id 1596927, :first-name nil, :last-name nil, :full-name "Rahmat Widia Sembiring"} #search_api.search_api.Author{:id 1059116, :first-name nil, :last-name nil, :full-name "Jasni Mohamad Zain"} #search_api.search_api.Author{:id 882172, :first-name nil, :last-name nil, :full-name "Abdullah Embong"}), :year 2011, :venue "CoRR", :ncit 2, :string "A Comparative Agglomerative Hierarchical Clustering Method to Cluster Implemented Course. ", :doc-id "A Comparative Agglomerative Hierarchical Clustering Method to Cluster Implemented Course 2011  ,  ,  "}, 2878447 #search_api.search_api.Paper{:id 2878447, :key "journals/ftml/Luxburg09", :title "Clustering Stability: An Overview.", :abstract "A popular method for selecting the number of clusters is based on stability arguments: one chooses the number of clusters such that the corresponding clustering results are \"most stable\". In recent years, a series of papers has analyzed the behavior of this method from a theoretical point of view. However, the results are very technical and difficult to interpret for non-experts. In this monograph we give a high-level overview about the existing literature on clustering stability. In addition to presenting the results in a slightly informal but accessible way, we relate them to each other and discuss their different implications. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player", :author (#search_api.search_api.Author{:id 790641, :first-name nil, :last-name nil, :full-name "Ulrike von Luxburg"}), :year 2009, :venue "Foundations and Trends in Machine Learning", :ncit 1, :string "Clustering Stability: An Overview.. A popular method for selecting the number of clusters is based on stability arguments: one chooses the number of clusters such that the corresponding clustering results are \"most stable\". In recent years, a series of papers has analyzed the behavior of this method from a theoretical point of view. However, the results are very technical and difficult to interpret for non-experts. In this monograph we give a high-level overview about the existing literature on clustering stability. In addition to presenting the results in a slightly informal but accessible way, we relate them to each other and discuss their different implications. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player", :doc-id "Clustering Stability: An Overview. 2009  "}, 1042704 #search_api.search_api.Paper{:id 1042704, :key "journals/pr/FilipponeCMR08", :title "A survey of kernel and spectral methods for clustering.", :abstract "Clustering algorithms are a useful tool to explore data structures and have been employed in many disciplines. The focus of this paper is the partitioning clustering problem with a special interest in two recent approaches: kernel and spectral methods. The aim of this paper is to present a survey of kernel and spectral clustering methods, two approaches able to produce nonlinear separating hypersurfaces between clusters. The presented kernel clustering methods are the kernel version of many classical clustering algorithms, e.g., K-means, SOM and neural gas. Spectral clustering arise from concepts in spectral graph theory and the clustering problem is configured as a graph cut problem where an appropriate objective function has to be optimized. An explicit proof of the fact that these two paradigms have the same objective is reported since it has been proven that these two seemingly different approaches have the same mathematical foundation. Besides, fuzzy kernel clustering methods are presented as extensions of kernel K-means clustering algorithm.", :author (#search_api.search_api.Author{:id 309224, :first-name nil, :last-name nil, :full-name "Maurizio Filippone"} #search_api.search_api.Author{:id 662277, :first-name nil, :last-name nil, :full-name "Francesco Camastra"} #search_api.search_api.Author{:id 238014, :first-name nil, :last-name nil, :full-name "Francesco Masulli"} #search_api.search_api.Author{:id 459312, :first-name nil, :last-name nil, :full-name "Stefano Rovetta"}), :year 2008, :venue "Pattern Recognition", :ncit 309, :string "A survey of kernel and spectral methods for clustering.. Clustering algorithms are a useful tool to explore data structures and have been employed in many disciplines. The focus of this paper is the partitioning clustering problem with a special interest in two recent approaches: kernel and spectral methods. The aim of this paper is to present a survey of kernel and spectral clustering methods, two approaches able to produce nonlinear separating hypersurfaces between clusters. The presented kernel clustering methods are the kernel version of many classical clustering algorithms, e.g., K-means, SOM and neural gas. Spectral clustering arise from concepts in spectral graph theory and the clustering problem is configured as a graph cut problem where an appropriate objective function has to be optimized. An explicit proof of the fact that these two paradigms have the same objective is reported since it has been proven that these two seemingly different approaches have the same mathematical foundation. Besides, fuzzy kernel clustering methods are presented as extensions of kernel K-means clustering algorithm.", :doc-id "A survey of kernel and spectral methods for clustering. 2008  ,  ,  ,  "}, 3073360 #search_api.search_api.Paper{:id 3073360, :key "journals/jmlr/CarlssonM10", :title "Characterization, Stability and Convergence of Hierarchical Clustering Methods.", :abstract nil, :author (#search_api.search_api.Author{:id 1461383, :first-name nil, :last-name nil, :full-name "Gunnar Carlsson"} #search_api.search_api.Author{:id 258181, :first-name nil, :last-name nil, :full-name "Facundo Mémoli"}), :year 2010, :venue "Journal of Machine Learning Research", :ncit 28, :string "Characterization, Stability and Convergence of Hierarchical Clustering Methods.. ", :doc-id "Characterization, Stability and Convergence of Hierarchical Clustering Methods. 2010  ,  "}, 3700560 #search_api.search_api.Paper{:id 3700560, :key "journals/kais/BorjiginG13", :title "Non-unique cluster numbers determination methods based on stability in spectral clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 14417055, :first-name nil, :last-name nil, :full-name "Sumuya Borjigin"} #search_api.search_api.Author{:id 1214206, :first-name nil, :last-name nil, :full-name "Chonghui Guo"}), :year 2013, :venue "Knowl. Inf. Syst.", :ncit 0, :string "Non-unique cluster numbers determination methods based on stability in spectral clustering.. ", :doc-id "Non-unique cluster numbers determination methods based on stability in spectral clustering. 2013  ,  "}, 2870097 #search_api.search_api.Paper{:id 2870097, :key "journals/tkde/ConsoliDGKP10", :title "Heuristic Approaches for the Quartet Method of Hierarchical Clustering.", :abstract "Given a set of objects and their pairwise distances, we wish to determine a visual representation of the data. We use the quartet paradigm to compute a hierarchy of clusters of the objects. The method is based on an NP-hard graph optimization problem called the Minimum Quartet Tree Cost problem. This paper presents and compares several heuristic approaches to approximate the optimal hierarchy. The performance of the algorithms is tested through extensive computational experiments and it is shown that the Reduced Variable Neighborhood Search heuristic is the most effective approach to the problem, obtaining high-quality solutions in short computational running times.", :author (#search_api.search_api.Author{:id 533968, :first-name nil, :last-name nil, :full-name "Sergio Consoli"} #search_api.search_api.Author{:id 415373, :first-name nil, :last-name nil, :full-name "Kenneth Darby-Dowman"} #search_api.search_api.Author{:id 47173, :first-name nil, :last-name nil, :full-name "Gijs Geleijnse"} #search_api.search_api.Author{:id 656918, :first-name nil, :last-name nil, :full-name "Jan H. M. Korst"} #search_api.search_api.Author{:id 1326388, :first-name nil, :last-name nil, :full-name "Steffen Pauws"}), :year 2010, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 7, :string "Heuristic Approaches for the Quartet Method of Hierarchical Clustering.. Given a set of objects and their pairwise distances, we wish to determine a visual representation of the data. We use the quartet paradigm to compute a hierarchy of clusters of the objects. The method is based on an NP-hard graph optimization problem called the Minimum Quartet Tree Cost problem. This paper presents and compares several heuristic approaches to approximate the optimal hierarchy. The performance of the algorithms is tested through extensive computational experiments and it is shown that the Reduced Variable Neighborhood Search heuristic is the most effective approach to the problem, obtaining high-quality solutions in short computational running times.", :doc-id "Heuristic Approaches for the Quartet Method of Hierarchical Clustering. 2010  ,  ,  ,  ,  "}, 1257393 #search_api.search_api.Paper{:id 1257393, :key "conf/wirn/FilipponeMR08", :title "An Experimental Comparison of Kernel Clustering Methods.", :abstract "In this paper, we compare the performances of some among the most popular kernel clustering methods on several data sets. The methods are all based on central clustering and incorporate in various ways the concepts of fuzzy clustering and kernel machines. The data sets are a sample of several application domains and sizes. A thorough discussion about the techniques for validating results is also presented. Results indicate that clustering in kernel space generally outperforms standard clustering, although no method can be proven to be consistently better than the others.", :author (#search_api.search_api.Author{:id 309224, :first-name nil, :last-name nil, :full-name "Maurizio Filippone"} #search_api.search_api.Author{:id 238014, :first-name nil, :last-name nil, :full-name "Francesco Masulli"} #search_api.search_api.Author{:id 459312, :first-name nil, :last-name nil, :full-name "Stefano Rovetta"}), :year 2008, :venue "WIRN", :ncit 0, :string "An Experimental Comparison of Kernel Clustering Methods.. In this paper, we compare the performances of some among the most popular kernel clustering methods on several data sets. The methods are all based on central clustering and incorporate in various ways the concepts of fuzzy clustering and kernel machines. The data sets are a sample of several application domains and sizes. A thorough discussion about the techniques for validating results is also presented. Results indicate that clustering in kernel space generally outperforms standard clustering, although no method can be proven to be consistently better than the others.", :doc-id "An Experimental Comparison of Kernel Clustering Methods. 2008  ,  ,  "}, 2864403 #search_api.search_api.Paper{:id 2864403, :key "journals/jmlr/BubeckL09", :title "Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions.", :abstract "Clustering is often formulated as a discrete optimization problem. The objective is to find, among all partitions of the data set, the best one according to some quality measure. However, in the statistical setting where we assume that the finite data set has been sampled from some underlying space, the goal is not to find the best partition of the given sample, but to approximate the true partition of the underlying space. We argue that the discrete optimization approach usually does not achieve this goal, and instead can lead to inconsistency. We construct examples which provably have this behavior. As in the case of supervised learning, the cure is to restrict the size of the function classes under consideration. For appropriate \"small\" function classes we can prove very general consistency theorems for clustering optimization schemes. As one particular algorithm for clustering with a restricted function space we introduce \"nearest neighbor clustering\". Similar to the k-nearest neighbor classifier in supervised learning, this algorithm can be seen as a general baseline algorithm to minimize arbitrary clustering objective functions. We prove that it is statistically consistent for all commonly used clustering objective functions.", :author (#search_api.search_api.Author{:id 532244, :first-name nil, :last-name nil, :full-name "Sébastien Bubeck"} #search_api.search_api.Author{:id 790641, :first-name nil, :last-name nil, :full-name "Ulrike von Luxburg"}), :year 2009, :venue "Journal of Machine Learning Research", :ncit 14, :string "Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions.. Clustering is often formulated as a discrete optimization problem. The objective is to find, among all partitions of the data set, the best one according to some quality measure. However, in the statistical setting where we assume that the finite data set has been sampled from some underlying space, the goal is not to find the best partition of the given sample, but to approximate the true partition of the underlying space. We argue that the discrete optimization approach usually does not achieve this goal, and instead can lead to inconsistency. We construct examples which provably have this behavior. As in the case of supervised learning, the cure is to restrict the size of the function classes under consideration. For appropriate \"small\" function classes we can prove very general consistency theorems for clustering optimization schemes. As one particular algorithm for clustering with a restricted function space we introduce \"nearest neighbor clustering\". Similar to the k-nearest neighbor classifier in supervised learning, this algorithm can be seen as a general baseline algorithm to minimize arbitrary clustering objective functions. We prove that it is statistically consistent for all commonly used clustering objective functions.", :doc-id "Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions. 2009  ,  "}, 3679540 #search_api.search_api.Paper{:id 3679540, :key "journals/tkde/Park13", :title "The Adaptive Clustering Method for the Long Tail Problem of Recommender Systems.", :abstract nil, :author (#search_api.search_api.Author{:id 1106043, :first-name nil, :last-name nil, :full-name "Yoon-Joo Park"}), :year 2013, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 0, :string "The Adaptive Clustering Method for the Long Tail Problem of Recommender Systems.. ", :doc-id "The Adaptive Clustering Method for the Long Tail Problem of Recommender Systems. 2013  "}, 1273172 #search_api.search_api.Paper{:id 1273172, :key "journals/ida/MirzaeiRA08", :title "A new method for hierarchical clustering combination.", :abstract "In the field of pattern recognition, combining different classifiers into a robust classifier is a common approach for improving classification accuracy. Recently, this trend has also been used to improve clustering performance especially in non-hierarchical clustering approaches. Generally hierarchical clustering is preferred in comparison with the partitional clustering for applications when the exact number of the clusters is not determined or when we are interested in finding the relation between clusters. To the best of our knowledge clustering combination methods proposed so far are based on partitional clustering and hierarchical clustering has been ignored. In this paper, a new method for combining hierarchical clustering is proposed. In this method, in the first step the primary hierarchical clustering dendrograms are converted to matrices. Then these matrices, which describe the dendrograms, are aggregated (using the matrix summation operator) into a final matrix with which the final clustering is formed. The effectiveness of different well known dendrogram descriptors and the one proposed by us for representing the dendrograms are evaluated and compared. The results show that all these descriptor work well and more accurate results (hierarchy of clusters) are obtained using hierarchical combination than combination of partitional clusterings.", :author (#search_api.search_api.Author{:id 1263458, :first-name nil, :last-name nil, :full-name "Abdolreza Mirzaei"} #search_api.search_api.Author{:id 316580, :first-name nil, :last-name nil, :full-name "Mohammad Rahmati"} #search_api.search_api.Author{:id 1462614, :first-name nil, :last-name nil, :full-name "Majid Ahmadi"}), :year 2008, :venue "Intell. Data Anal.", :ncit 10, :string "A new method for hierarchical clustering combination.. In the field of pattern recognition, combining different classifiers into a robust classifier is a common approach for improving classification accuracy. Recently, this trend has also been used to improve clustering performance especially in non-hierarchical clustering approaches. Generally hierarchical clustering is preferred in comparison with the partitional clustering for applications when the exact number of the clusters is not determined or when we are interested in finding the relation between clusters. To the best of our knowledge clustering combination methods proposed so far are based on partitional clustering and hierarchical clustering has been ignored. In this paper, a new method for combining hierarchical clustering is proposed. In this method, in the first step the primary hierarchical clustering dendrograms are converted to matrices. Then these matrices, which describe the dendrograms, are aggregated (using the matrix summation operator) into a final matrix with which the final clustering is formed. The effectiveness of different well known dendrogram descriptors and the one proposed by us for representing the dendrograms are evaluated and compared. The results show that all these descriptor work well and more accurate results (hierarchy of clusters) are obtained using hierarchical combination than combination of partitional clusterings.", :doc-id "A new method for hierarchical clustering combination. 2008  ,  ,  "}, 600021 #search_api.search_api.Paper{:id 600021, :key "conf/sigmod/ZhangRL96", :title "BIRCH: An Efficient Data Clustering Method for Very Large Databases.", :abstract "Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle \"noise\" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.", :author (#search_api.search_api.Author{:id 267601, :first-name nil, :last-name nil, :full-name "Tian Zhang"} #search_api.search_api.Author{:id 464920, :first-name nil, :last-name nil, :full-name "Raghu Ramakrishnan"} #search_api.search_api.Author{:id 726591, :first-name nil, :last-name nil, :full-name "Miron Livny"}), :year 1996, :venue "SIGMOD Conference", :ncit 3214, :string "BIRCH: An Efficient Data Clustering Method for Very Large Databases.. Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle \"noise\" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.", :doc-id "BIRCH: An Efficient Data Clustering Method for Very Large Databases. 1996  ,  ,  "}, 346006 #search_api.search_api.Paper{:id 346006, :key "conf/icpr/Ben-HurSHV00", :title "A Support Vector Clustering Method.", :abstract nil, :author (#search_api.search_api.Author{:id 43180, :first-name nil, :last-name nil, :full-name "Asa Ben-Hur"} #search_api.search_api.Author{:id 352646, :first-name nil, :last-name nil, :full-name "Hava T. Siegelmann"} #search_api.search_api.Author{:id 1045131, :first-name nil, :last-name nil, :full-name "David Horn"} #search_api.search_api.Author{:id 125753, :first-name nil, :last-name nil, :full-name "Vladimir Vapnik"}), :year 2000, :venue "ICPR", :ncit 818, :string "A Support Vector Clustering Method.. ", :doc-id "A Support Vector Clustering Method. 2000  ,  ,  ,  "}, 3677399 #search_api.search_api.Paper{:id 3677399, :key "conf/nips/KalogeratosL12", :title "Dip-means: an incremental clustering method for estimating the number of clusters.", :abstract nil, :author (#search_api.search_api.Author{:id 1269438, :first-name nil, :last-name nil, :full-name "Argyris Kalogeratos"} #search_api.search_api.Author{:id 1236023, :first-name nil, :last-name nil, :full-name "Aristidis Likas"}), :year 2012, :venue "NIPS", :ncit 0, :string "Dip-means: an incremental clustering method for estimating the number of clusters.. ", :doc-id "Dip-means: an incremental clustering method for estimating the number of clusters. 2012  ,  "}, 1033911 #search_api.search_api.Paper{:id 1033911, :key "journals/pami/AyadK08", :title "Cumulative Voting Consensus Method for Partitions with Variable Number of Clusters.", :abstract "Over the past few years, there has been a renewed interest in the consensus clustering problem. Several new methods have been proposed for finding a consensus partition for a set of n data objects that optimally summarizes an ensemble. In this paper, we propose new consensus clustering algorithms with linear computational complexity in n. We consider clusterings generated with random number of clusters, which we describe by categorical random variables. We introduce the idea of cumulative voting as a solution for the problem of cluster label alignment, where, unlike the common one-to-one voting scheme, a probabilistic mapping is computed. We seek a first summary of the ensemble that minimizes the average squared distance between the mapped partitions and the optimal representation of the ensemble, where the selection criterion of the reference clustering is defined based on maximizing the information content as measured by the entropy. We describe cumulative vote weighting schemes and corresponding algorithms to compute an empirical probability distribution summarizing the ensemble. Given the arbitrary number of clusters of the input partitions, we formulate the problem of extracting the optimal consensus as that of finding a compressed summary of the estimated distribution that preserves maximum relevant information. An efficient solution is obtained using an agglomerative algorithm that minimizes the average generalized Jensen-Shannon divergence within the cluster. The empirical study demonstrates significant gains in accuracy and superior performance compared to several recent consensus clustering algorithms.", :author (#search_api.search_api.Author{:id 434087, :first-name nil, :last-name nil, :full-name "Hanan Ayad"} #search_api.search_api.Author{:id 830023, :first-name nil, :last-name nil, :full-name "Mohamed S. Kamel"}), :year 2008, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 107, :string "Cumulative Voting Consensus Method for Partitions with Variable Number of Clusters.. Over the past few years, there has been a renewed interest in the consensus clustering problem. Several new methods have been proposed for finding a consensus partition for a set of n data objects that optimally summarizes an ensemble. In this paper, we propose new consensus clustering algorithms with linear computational complexity in n. We consider clusterings generated with random number of clusters, which we describe by categorical random variables. We introduce the idea of cumulative voting as a solution for the problem of cluster label alignment, where, unlike the common one-to-one voting scheme, a probabilistic mapping is computed. We seek a first summary of the ensemble that minimizes the average squared distance between the mapped partitions and the optimal representation of the ensemble, where the selection criterion of the reference clustering is defined based on maximizing the information content as measured by the entropy. We describe cumulative vote weighting schemes and corresponding algorithms to compute an empirical probability distribution summarizing the ensemble. Given the arbitrary number of clusters of the input partitions, we formulate the problem of extracting the optimal consensus as that of finding a compressed summary of the estimated distribution that preserves maximum relevant information. An efficient solution is obtained using an agglomerative algorithm that minimizes the average generalized Jensen-Shannon divergence within the cluster. The empirical study demonstrates significant gains in accuracy and superior performance compared to several recent consensus clustering algorithms.", :doc-id "Cumulative Voting Consensus Method for Partitions with Variable Number of Clusters. 2008  ,  "}, 527448 #search_api.search_api.Paper{:id 527448, :key "conf/pakdd/TsaiC08", :title "A Clustering-Oriented Star Coordinate Translation Method for Reliable Clustering Parameterization.", :abstract "When conducting a clustering process, users are generally concerned whether the clustering result is reliable enough to reflect the actual clustering phenomenon. The number of clusters and initial cluster centers are two critical parameters that influence the reliability of clustering results highly. We propose a Clustering-Oriented Star Coordinate Translation (COSCT) method to help users determining the two parameters more confidently. Through COSCT all objects from a multi-dimensional space are adaptively translated to a 2D starcoordinate plane, so that the clustering parameterization can be easily conducted by observing the clustering phenomenon in the plane. To enhance the cluster-displaying quality of the star-coordinate plane, the feature weighting and coordinate arrangement procedures are developed. The effectiveness of the COSCT method is demonstrated using a set of experiments.", :author (#search_api.search_api.Author{:id 1486757, :first-name nil, :last-name nil, :full-name "Chieh-Yuan Tsai"} #search_api.search_api.Author{:id 1023677, :first-name nil, :last-name nil, :full-name "Chuang-Cheng Chiu"}), :year 2008, :venue "PAKDD", :ncit 0, :string "A Clustering-Oriented Star Coordinate Translation Method for Reliable Clustering Parameterization.. When conducting a clustering process, users are generally concerned whether the clustering result is reliable enough to reflect the actual clustering phenomenon. The number of clusters and initial cluster centers are two critical parameters that influence the reliability of clustering results highly. We propose a Clustering-Oriented Star Coordinate Translation (COSCT) method to help users determining the two parameters more confidently. Through COSCT all objects from a multi-dimensional space are adaptively translated to a 2D starcoordinate plane, so that the clustering parameterization can be easily conducted by observing the clustering phenomenon in the plane. To enhance the cluster-displaying quality of the star-coordinate plane, the feature weighting and coordinate arrangement procedures are developed. The effectiveness of the COSCT method is demonstrated using a set of experiments.", :doc-id "A Clustering-Oriented Star Coordinate Translation Method for Reliable Clustering Parameterization. 2008  ,  "}, 1065112 #search_api.search_api.Paper{:id 1065112, :key "journals/sigmod/HalkidiBV02", :title "Cluster Validity Methods: Part I.", :abstract "Clustering is an unsupervised process since there are no predefined classes and no examples that would indicate grouping properties in the data set. The majority of the clustering algorithms behave differently depending on the features of the data set and the initial assumptions for defining groups. Therefore, in most applications the resulting clustering scheme requires some sort of evaluation as regards its validity. Evaluating and assessing the results of a clustering algorithm is the main subject of cluster validity. In this paper we present a review of the clustering validity and methods. More specifically, Part I of the paper discusses the cluster validity approaches based on external and internal criteria.", :author (#search_api.search_api.Author{:id 1491231, :first-name nil, :last-name nil, :full-name "Maria Halkidi"} #search_api.search_api.Author{:id 438548, :first-name nil, :last-name nil, :full-name "Yannis Batistakis"} #search_api.search_api.Author{:id 88969, :first-name nil, :last-name nil, :full-name "Michalis Vazirgiannis"}), :year 2002, :venue "SIGMOD Record", :ncit 344, :string "Cluster Validity Methods: Part I.. Clustering is an unsupervised process since there are no predefined classes and no examples that would indicate grouping properties in the data set. The majority of the clustering algorithms behave differently depending on the features of the data set and the initial assumptions for defining groups. Therefore, in most applications the resulting clustering scheme requires some sort of evaluation as regards its validity. Evaluating and assessing the results of a clustering algorithm is the main subject of cluster validity. In this paper we present a review of the clustering validity and methods. More specifically, Part I of the paper discusses the cluster validity approaches based on external and internal criteria.", :doc-id "Cluster Validity Methods: Part I. 2002  ,  ,  "}, 2867384 #search_api.search_api.Paper{:id 2867384, :key "journals/pr/FalasconiGPSM10", :title "A stability based validity method for fuzzy clustering.", :abstract "An important goal in cluster analysis is the internal validation of results using an objective criterion. Of particular relevance in this respect is the estimation of the optimum number of clusters capturing the intrinsic structure of your data. This paper proposes a method to determine this optimum number based on the evaluation of fuzzy partition stability under bootstrap resampling. The method is first characterized on synthetic data with respect to hyper-parameters, like the fuzzifier, and spatial clustering parameters, such as feature space dimensionality, clusters degree of overlap, and number of clusters. The method is then validated on experimental datasets. Furthermore, the performance of the proposed method is compared to that obtained using a number of traditional fuzzy validity rules based on the cluster compactness-to-separation criteria. The proposed method provides accurate and reliable results, and offers better generalization capabilities than the classical approaches.", :author (#search_api.search_api.Author{:id 1262512, :first-name nil, :last-name nil, :full-name "M. Falasconi"} #search_api.search_api.Author{:id 704813, :first-name nil, :last-name nil, :full-name "A. Gutierrez"} #search_api.search_api.Author{:id 456104, :first-name nil, :last-name nil, :full-name "Matteo Pardo"} #search_api.search_api.Author{:id 39515, :first-name nil, :last-name nil, :full-name "Giorgio Sberveglieri"} #search_api.search_api.Author{:id 458618, :first-name nil, :last-name nil, :full-name "S. Marco"}), :year 2010, :venue "Pattern Recognition", :ncit 5, :string "A stability based validity method for fuzzy clustering.. An important goal in cluster analysis is the internal validation of results using an objective criterion. Of particular relevance in this respect is the estimation of the optimum number of clusters capturing the intrinsic structure of your data. This paper proposes a method to determine this optimum number based on the evaluation of fuzzy partition stability under bootstrap resampling. The method is first characterized on synthetic data with respect to hyper-parameters, like the fuzzifier, and spatial clustering parameters, such as feature space dimensionality, clusters degree of overlap, and number of clusters. The method is then validated on experimental datasets. Furthermore, the performance of the proposed method is compared to that obtained using a number of traditional fuzzy validity rules based on the cluster compactness-to-separation criteria. The proposed method provides accurate and reliable results, and offers better generalization capabilities than the classical approaches.", :doc-id "A stability based validity method for fuzzy clustering. 2010  ,  ,  ,  ,  "}, 3516632 #search_api.search_api.Paper{:id 3516632, :key "conf/fuzzIEEE/ParkerHB12", :title "Comparison of scalable fuzzy clustering methods.", :abstract nil, :author (#search_api.search_api.Author{:id 14199401, :first-name nil, :last-name nil, :full-name "Jonathon K. Parker"} #search_api.search_api.Author{:id 809652, :first-name nil, :last-name nil, :full-name "Lawrence O. Hall"} #search_api.search_api.Author{:id 18556, :first-name nil, :last-name nil, :full-name "James C. Bezdek"}), :year 2012, :venue "FUZZ-IEEE", :ncit 1, :string "Comparison of scalable fuzzy clustering methods.. ", :doc-id "Comparison of scalable fuzzy clustering methods. 2012  ,  ,  "}, 1031640 #search_api.search_api.Paper{:id 1031640, :key "journals/pami/GathG89", :title "Unsupervised Optimal Fuzzy Clustering.", :abstract "This study reports on a method for carrying out fuzzy classification without a priori assumptions on the number of clusters in the data set. Assessment of cluster validity is based on performance measures using hypervolume and density criteria. An algorithm is derived from a combination of the fuzzy K-means algorithm and fuzzy maximum-likelihood estimation. The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster. The algorithm was tested on different classes of simulated data, and on a real data set derived from sleep EEG signal.", :author (#search_api.search_api.Author{:id 552025, :first-name nil, :last-name nil, :full-name "Isak Gath"} #search_api.search_api.Author{:id 37593, :first-name nil, :last-name nil, :full-name "Amir B. Geva"}), :year 1989, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 1269, :string "Unsupervised Optimal Fuzzy Clustering.. This study reports on a method for carrying out fuzzy classification without a priori assumptions on the number of clusters in the data set. Assessment of cluster validity is based on performance measures using hypervolume and density criteria. An algorithm is derived from a combination of the fuzzy K-means algorithm and fuzzy maximum-likelihood estimation. The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster. The algorithm was tested on different classes of simulated data, and on a real data set derived from sleep EEG signal.", :doc-id "Unsupervised Optimal Fuzzy Clustering. 1989  ,  "}, 790361 #search_api.search_api.Paper{:id 790361, :key "journals/cj/FraleyR98", :title "How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis.", :abstract nil, :author (#search_api.search_api.Author{:id 512807, :first-name nil, :last-name nil, :full-name "Chris Fraley"} #search_api.search_api.Author{:id 891975, :first-name nil, :last-name nil, :full-name "Adrian E. Raftery"}), :year 1998, :venue "Comput. J.", :ncit 1214, :string "How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis.. ", :doc-id "How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis. 1998  ,  "}, 1032218 #search_api.search_api.Paper{:id 1032218, :key "journals/pami/LeeL05", :title "An Improved Cluster Labeling Method for Support Vector Clustering.", :abstract "The support vector clustering (SVC) algorithm is a recently emerged unsupervised learning method inspired by support vector machines. One key step involved in the SVC algorithm is the cluster assignment of each data point. A new cluster labeling method for SVC is developed based on some invariant topological properties of a trained kernel radius function. Benchmark results show that the proposed method outperforms previously reported labeling techniques.", :author (#search_api.search_api.Author{:id 1414613, :first-name nil, :last-name nil, :full-name "Jaewook Lee"} #search_api.search_api.Author{:id 831562, :first-name nil, :last-name nil, :full-name "Daewon Lee"}), :year 2005, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 185, :string "An Improved Cluster Labeling Method for Support Vector Clustering.. The support vector clustering (SVC) algorithm is a recently emerged unsupervised learning method inspired by support vector machines. One key step involved in the SVC algorithm is the cluster assignment of each data point. A new cluster labeling method for SVC is developed based on some invariant topological properties of a trained kernel radius function. Benchmark results show that the proposed method outperforms previously reported labeling techniques.", :doc-id "An Improved Cluster Labeling Method for Support Vector Clustering. 2005  ,  "}, 985178 #search_api.search_api.Paper{:id 985178, :key "journals/jmlr/BanerjeeMDG05", :title "Clustering with Bregman Divergences.", :abstract "A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we propose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based parametric clustering approaches, such as classical <tt>kmeans</tt>, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical <tt>kmeans</tt> algorithm, while generalizing the method to a large class of clustering loss functions. This is achieved by first posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically decreases this loss. In addition, we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternative interpretation of an efficient EM scheme for learning mixtures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Bregman clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.", :author (#search_api.search_api.Author{:id 1158718, :first-name nil, :last-name nil, :full-name "Arindam Banerjee"} #search_api.search_api.Author{:id 661837, :first-name nil, :last-name nil, :full-name "Srujana Merugu"} #search_api.search_api.Author{:id 161516, :first-name nil, :last-name nil, :full-name "Inderjit S. Dhillon"} #search_api.search_api.Author{:id 224463, :first-name nil, :last-name nil, :full-name "Joydeep Ghosh"}), :year 2005, :venue "Journal of Machine Learning Research", :ncit 663, :string "Clustering with Bregman Divergences.. A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we propose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based parametric clustering approaches, such as classical <tt>kmeans</tt>, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical <tt>kmeans</tt> algorithm, while generalizing the method to a large class of clustering loss functions. This is achieved by first posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically decreases this loss. In addition, we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternative interpretation of an efficient EM scheme for learning mixtures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Bregman clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.", :doc-id "Clustering with Bregman Divergences. 2005  ,  ,  ,  "}, 985307 #search_api.search_api.Paper{:id 985307, :key "journals/jmlr/Teboulle07", :title "A Unified Continuous Optimization Framework for Center-Based Clustering Methods.", :abstract "Center-based partitioning clustering algorithms rely on minimizing an appropriately formulated objective function, and different formulations suggest different possible algorithms. In this paper, we start with the standard nonconvex and nonsmooth formulation of the partitioning clustering problem. We demonstrate that within this elementary formulation, convex analysis tools and optimization theory provide a unifying language and framework to design, analyze and extend hard and soft center-based clustering algorithms, through a generic algorithm which retains the computational simplicity of the popular k-means scheme. We show that several well known and more recent center-based clustering algorithms, which have been derived either heuristically, or/and have emerged from intuitive analogies in physics, statistical techniques and information theoretic perspectives can be recovered as special cases of the proposed analysis and we streamline their relationships.", :author (#search_api.search_api.Author{:id 1515505, :first-name nil, :last-name nil, :full-name "Marc Teboulle"}), :year 2007, :venue "Journal of Machine Learning Research", :ncit 56, :string "A Unified Continuous Optimization Framework for Center-Based Clustering Methods.. Center-based partitioning clustering algorithms rely on minimizing an appropriately formulated objective function, and different formulations suggest different possible algorithms. In this paper, we start with the standard nonconvex and nonsmooth formulation of the partitioning clustering problem. We demonstrate that within this elementary formulation, convex analysis tools and optimization theory provide a unifying language and framework to design, analyze and extend hard and soft center-based clustering algorithms, through a generic algorithm which retains the computational simplicity of the popular k-means scheme. We show that several well known and more recent center-based clustering algorithms, which have been derived either heuristically, or/and have emerged from intuitive analogies in physics, statistical techniques and information theoretic perspectives can be recovered as special cases of the proposed analysis and we streamline their relationships.", :doc-id "A Unified Continuous Optimization Framework for Center-Based Clustering Methods. 2007  "}, 907739 #search_api.search_api.Paper{:id 907739, :key "journals/ijcv/Lowe04", :title "Distinctive Image Features from Scale-Invariant Keypoints.", :abstract "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.", :author (#search_api.search_api.Author{:id 337186, :first-name nil, :last-name nil, :full-name "David G. Lowe"}), :year 2004, :venue "International Journal of Computer Vision", :ncit 19774, :string "Distinctive Image Features from Scale-Invariant Keypoints.. This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.", :doc-id "Distinctive Image Features from Scale-Invariant Keypoints. 2004  "}, 1044411 #search_api.search_api.Paper{:id 1044411, :key "journals/prl/FrossyniotisLS04", :title "A clustering method based on boosting.", :abstract "It is widely recognized that the boosting methodology provides superior results for classification problems. In this paper, we propose the boost-clustering algorithm which constitutes a novel clustering methodology that exploits the general principles of boosting in order to provide a consistent partitioning of a dataset. The boost-clustering algorithm is a multi-clustering method. At each boosting iteration, a new training set is created using weighted random sampling from the original dataset and a simple clustering algorithm (e.g.k-means) is applied to provide a new data partitioning. The final clustering solution is produced by aggregating the multiple clustering results through weighted voting. Experiments on both artificial and real-world data sets indicate that boost-clustering provides solutions of improved quality.", :author (#search_api.search_api.Author{:id 715833, :first-name nil, :last-name nil, :full-name "Dimitrios S. Frossyniotis"} #search_api.search_api.Author{:id 1236023, :first-name nil, :last-name nil, :full-name "Aristidis Likas"} #search_api.search_api.Author{:id 863471, :first-name nil, :last-name nil, :full-name "Andreas Stafylopatis"}), :year 2004, :venue "Pattern Recognition Letters", :ncit 66, :string "A clustering method based on boosting.. It is widely recognized that the boosting methodology provides superior results for classification problems. In this paper, we propose the boost-clustering algorithm which constitutes a novel clustering methodology that exploits the general principles of boosting in order to provide a consistent partitioning of a dataset. The boost-clustering algorithm is a multi-clustering method. At each boosting iteration, a new training set is created using weighted random sampling from the original dataset and a simple clustering algorithm (e.g.k-means) is applied to provide a new data partitioning. The final clustering solution is produced by aggregating the multiple clustering results through weighted voting. Experiments on both artificial and real-world data sets indicate that boost-clustering provides solutions of improved quality.", :doc-id "A clustering method based on boosting. 2004  ,  ,  "}, 984956 #search_api.search_api.Paper{:id 984956, :key "journals/jmlr/Ben-HurHSV01", :title "Support Vector Clustering.", :abstract "We present a novel clustering method using the approach of support vector machines. Data points are mapped by means of a Gaussian kernel to a high dimensional feature space, where we search for the minimal enclosing sphere. This sphere, when mapped back to data space, can separate into several components, each enclosing a separate cluster of points. We present a simple algorithm for identifying these clusters. The width of the Gaussian kernel controls the scale at which the data is probed while the soft margin constant helps coping with outliers and overlapping clusters. The structure of a dataset is explored by varying the two parameters, maintaining a minimal number of support vectors to assure smooth cluster boundaries. We demonstrate the performance of our algorithm on several datasets.", :author (#search_api.search_api.Author{:id 43180, :first-name nil, :last-name nil, :full-name "Asa Ben-Hur"} #search_api.search_api.Author{:id 1045131, :first-name nil, :last-name nil, :full-name "David Horn"} #search_api.search_api.Author{:id 352646, :first-name nil, :last-name nil, :full-name "Hava T. Siegelmann"} #search_api.search_api.Author{:id 125753, :first-name nil, :last-name nil, :full-name "Vladimir Vapnik"}), :year 2001, :venue "Journal of Machine Learning Research", :ncit 828, :string "Support Vector Clustering.. We present a novel clustering method using the approach of support vector machines. Data points are mapped by means of a Gaussian kernel to a high dimensional feature space, where we search for the minimal enclosing sphere. This sphere, when mapped back to data space, can separate into several components, each enclosing a separate cluster of points. We present a simple algorithm for identifying these clusters. The width of the Gaussian kernel controls the scale at which the data is probed while the soft margin constant helps coping with outliers and overlapping clusters. The structure of a dataset is explored by varying the two parameters, maintaining a minimal number of support vectors to assure smooth cluster boundaries. We demonstrate the performance of our algorithm on several datasets.", :doc-id "Support Vector Clustering. 2001  ,  ,  ,  "}, 3548061 #search_api.search_api.Paper{:id 3548061, :key "journals/corr/abs-1210-6292", :title "A density-sensitive hierarchical clustering method", :abstract nil, :author (#search_api.search_api.Author{:id 14348081, :first-name nil, :last-name nil, :full-name "Álvaro Martínez-Pérez"}), :year 2012, :venue "CoRR", :ncit 0, :string "A density-sensitive hierarchical clustering method. ", :doc-id "A density-sensitive hierarchical clustering method 2012  "}, 1031101 #search_api.search_api.Paper{:id 1031101, :key "journals/pami/BeniL94", :title "A Least Biased Fuzzy Clustering Method.", :abstract "A new operational definition of cluster is proposed, and a fuzzy clustering algorithm with minimal biases is formulated by making use of the maximum entropy principle to maximize the entropy of the centroids with respect to the data points (clustering entropy). The authors make no assumptions on the number of clusters or their initial positions. For each value of an adimensional scale parameter /spl beta/', the clustering algorithm makes each data point iterate towards one of the cluster's centroids, so that both hard and fuzzy partitions are obtained. Since the clustering algorithm can make a multiscale analysis of the given data set one can obtain both hierarchy and partitioning type clustering. The relative stability with respect to /spl beta/' of each cluster structure is defined as the measurement of cluster validity. The authors determine the specific value of /spl beta/' which corresponds to the optimal positions of cluster centroids by minimizing the entropy of the data points with respect to the centroids (clustered entropy). Examples are given to show how this least biased method succeeds in getting perceptually correct clustering results.", :author (#search_api.search_api.Author{:id 122413, :first-name nil, :last-name nil, :full-name "Gerardo Beni"} #search_api.search_api.Author{:id 1061685, :first-name nil, :last-name nil, :full-name "Xiaomin Liu"}), :year 1994, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 99, :string "A Least Biased Fuzzy Clustering Method.. A new operational definition of cluster is proposed, and a fuzzy clustering algorithm with minimal biases is formulated by making use of the maximum entropy principle to maximize the entropy of the centroids with respect to the data points (clustering entropy). The authors make no assumptions on the number of clusters or their initial positions. For each value of an adimensional scale parameter /spl beta/', the clustering algorithm makes each data point iterate towards one of the cluster's centroids, so that both hard and fuzzy partitions are obtained. Since the clustering algorithm can make a multiscale analysis of the given data set one can obtain both hierarchy and partitioning type clustering. The relative stability with respect to /spl beta/' of each cluster structure is defined as the measurement of cluster validity. The authors determine the specific value of /spl beta/' which corresponds to the optimal positions of cluster centroids by minimizing the entropy of the data points with respect to the centroids (clustered entropy). Examples are given to show how this least biased method succeeds in getting perceptually correct clustering results.", :doc-id "A Least Biased Fuzzy Clustering Method. 1994  ,  "}, 3359998 #search_api.search_api.Paper{:id 3359998, :key "journals/eswa/BaiLDC12", :title "A cluster centers initialization method for clustering categorical data.", :abstract nil, :author (#search_api.search_api.Author{:id 92675, :first-name nil, :last-name nil, :full-name "Liang Bai"} #search_api.search_api.Author{:id 211040, :first-name nil, :last-name nil, :full-name "Jiye Liang"} #search_api.search_api.Author{:id 69946, :first-name nil, :last-name nil, :full-name "Chuangyin Dang"} #search_api.search_api.Author{:id 1342804, :first-name nil, :last-name nil, :full-name "Fuyuan Cao"}), :year 2012, :venue "Expert Syst. Appl.", :ncit 1, :string "A cluster centers initialization method for clustering categorical data.. ", :doc-id "A cluster centers initialization method for clustering categorical data. 2012  ,  ,  ,  "}, 1009438 #search_api.search_api.Paper{:id 1009438, :key "journals/ml/Lee02", :title "A Simple Method for Generating Additive Clustering Models with Limited Complexity.", :abstract "Additive clustering was originally developed within cognitive psychology to enable the development of featural models of human mental representation. The representational flexibility of additive clustering, however, suggests its more general application to modeling complicated relationships between objects in non-psychological domains of interest. This paper describes, demonstrates, and evaluates a simple method for learning additive clustering models, based on the combinatorial optimization approach known as Population-Based Incremental Learning. The performance of this new method is shown to be comparable with previously developed methods over a set of &lsquo;benchmark&rsquo; data sets. In addition, the method developed here has the potential, by using a Bayesian analysis of model complexity that relies on an estimate of data precision, to determine the appropriate number of clusters to include in a model.", :author (#search_api.search_api.Author{:id 873860, :first-name nil, :last-name nil, :full-name "Michael D. Lee"}), :year 2002, :venue "Machine Learning", :ncit 0, :string "A Simple Method for Generating Additive Clustering Models with Limited Complexity.. Additive clustering was originally developed within cognitive psychology to enable the development of featural models of human mental representation. The representational flexibility of additive clustering, however, suggests its more general application to modeling complicated relationships between objects in non-psychological domains of interest. This paper describes, demonstrates, and evaluates a simple method for learning additive clustering models, based on the combinatorial optimization approach known as Population-Based Incremental Learning. The performance of this new method is shown to be comparable with previously developed methods over a set of &lsquo;benchmark&rsquo; data sets. In addition, the method developed here has the potential, by using a Bayesian analysis of model complexity that relies on an estimate of data precision, to determine the appropriate number of clusters to include in a model.", :doc-id "A Simple Method for Generating Additive Clustering Models with Limited Complexity. 2002  "}, 3065726 #search_api.search_api.Paper{:id 3065726, :key "journals/corr/abs-1105-0121", :title "Methods of Hierarchical Clustering", :abstract nil, :author (#search_api.search_api.Author{:id 1321196, :first-name nil, :last-name nil, :full-name "Fionn Murtagh"} #search_api.search_api.Author{:id 174224, :first-name nil, :last-name nil, :full-name "Pedro Contreras"}), :year 2011, :venue "CoRR", :ncit 1, :string "Methods of Hierarchical Clustering. ", :doc-id "Methods of Hierarchical Clustering 2011  ,  "}, 1113151 #search_api.search_api.Paper{:id 1113151, :key "journals/tkde/NgH02", :title "CLARANS: A Method for Clustering Objects for Spatial Data Mining.", :abstract "Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. To this end, this paper has three main contributions. First, we propose a new clustering method called CLARANS, whose aim is to identify spatial structures that may be present in the data. Experimental results indicate that, when compared with existing clustering methods, CLARANS is very efficient and effective. Second, we investigate how CLARANS can handle not only points objects, but also polygon objects efficiently. One of the methods considered, called the IR-approximation, is very efficient in clustering convex and nonconvex polygon objects. Third, building on top of CLARANS, we develop two spatial data mining algorithms that aim to discover relationships between spatial and nonspatial attributes. Both algorithms can discover knowledge that is difficult to find with existing spatial data mining algorithms.", :author (#search_api.search_api.Author{:id 143327, :first-name nil, :last-name nil, :full-name "Raymond T. Ng"} #search_api.search_api.Author{:id 745329, :first-name nil, :last-name nil, :full-name "Jiawei Han"}), :year 2002, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 2121, :string "CLARANS: A Method for Clustering Objects for Spatial Data Mining.. Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. To this end, this paper has three main contributions. First, we propose a new clustering method called CLARANS, whose aim is to identify spatial structures that may be present in the data. Experimental results indicate that, when compared with existing clustering methods, CLARANS is very efficient and effective. Second, we investigate how CLARANS can handle not only points objects, but also polygon objects efficiently. One of the methods considered, called the IR-approximation, is very efficient in clustering convex and nonconvex polygon objects. Third, building on top of CLARANS, we develop two spatial data mining algorithms that aim to discover relationships between spatial and nonspatial attributes. Both algorithms can discover knowledge that is difficult to find with existing spatial data mining algorithms.", :doc-id "CLARANS: A Method for Clustering Objects for Spatial Data Mining. 2002  ,  "}, 642207 #search_api.search_api.Paper{:id 642207, :key "conf/vldb/NgH94", :title "Efficient and Effective Clustering Methods for Spatial Data Mining.", :abstract "Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. In this paper, we explore whether clustering methods have a role to play in spatial data mining. To this end, we develop a new clustering method called CLARANS which is based on randomized search. We also develop two spatial data mining algorithms that use CLARANS. Our analysis and experiments show that with the assistance of CLARANS, these two algorithms are very effective and can lead to discoveries that are difficult to find with current spatial data mining algorithms. Furthermore, experiments conducted to compare the performance of CLARANS with that of existing clustering methods show that CLARANS is the most efficient.", :author (#search_api.search_api.Author{:id 143327, :first-name nil, :last-name nil, :full-name "Raymond T. Ng"} #search_api.search_api.Author{:id 745329, :first-name nil, :last-name nil, :full-name "Jiawei Han"}), :year 1994, :venue "VLDB", :ncit 2121, :string "Efficient and Effective Clustering Methods for Spatial Data Mining.. Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. In this paper, we explore whether clustering methods have a role to play in spatial data mining. To this end, we develop a new clustering method called CLARANS which is based on randomized search. We also develop two spatial data mining algorithms that use CLARANS. Our analysis and experiments show that with the assistance of CLARANS, these two algorithms are very effective and can lead to discoveries that are difficult to find with current spatial data mining algorithms. Furthermore, experiments conducted to compare the performance of CLARANS with that of existing clustering methods show that CLARANS is the most efficient.", :doc-id "Efficient and Effective Clustering Methods for Spatial Data Mining. 1994  ,  "}}}