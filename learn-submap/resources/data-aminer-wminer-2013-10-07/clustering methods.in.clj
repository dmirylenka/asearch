#topic_maps.core.TopicMap{:topic-graph #graphs.core.Digraph{:nodes #{nil {:id 763505, :title "Signal processing", :type :wiki-api.core/category} {:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} {:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 745820, :title "DNA", :type :wiki-api.core/category} {:id 1034006, :title "Particle physics", :type :wiki-api.core/category} {:id 33432516, :title "Geometric centers", :type :wiki-api.core/category} {:id 690637, :title "Algebra", :type :wiki-api.core/category} {:id 18039672, :title "Uncertainty of numbers", :type :wiki-api.core/category} {:id 33432527, :title "Triangle centers", :type :wiki-api.core/category} {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 26201577, :title "Texture filtering", :type :wiki-api.core/category} {:id 9614183, :title "Design for X", :type :wiki-api.core/category} {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} {:id 744360, :title "Networks", :type :wiki-api.core/category} {:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} {:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} {:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category} {:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} {:id 746340, :title "Gene expression", :type :wiki-api.core/category} {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 693992, :title "Measure theory", :type :wiki-api.core/category} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 30982373, :title "Missing data", :type :wiki-api.core/category} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 772270, :title "Philosophy of science", :type :wiki-api.core/category} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 691898, :title "Graph theory", :type :wiki-api.core/category} {:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} {:id 26304777, :title "Graph theory objects", :type :wiki-api.core/category} {:id 31195693, :title "Design of experiments", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 987553, :title "Interpolation", :type :wiki-api.core/category} {:id 16989227, :title "Data", :type :wiki-api.core/category} {:id 2302180, :title "Integrals", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 30636687, :title "Network analysis", :type :wiki-api.core/category} {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 5438220, :title "Cheminformatics", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 716309, :title "Cartography", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} {:id 2871217, :title "Educational psychology", :type :wiki-api.core/category} {:id 20417300, :title "Types of functions", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 1114964, :title "Digital television", :type :wiki-api.core/category} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 4594748, :title "Computational problems", :type :wiki-api.core/category} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 2865929, :title "Entropy", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 36911884, :title "Utility software types", :type :wiki-api.core/category} {:id 21764485, :title "Statistical ratios", :type :wiki-api.core/category} {:id 8761328, :title "Articles with example pseudocode", :type :wiki-api.core/category} {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} {:id 21067529, :title "Outlines", :type :wiki-api.core/category} {:id 20745673, :title "Medical statistics", :type :wiki-api.core/category} {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 4873906, :title "Systems engineering", :type :wiki-api.core/category} {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 762162, :title "Data management", :type :wiki-api.core/category} {:id 25866614, :title "Videotelephony", :type :wiki-api.core/category} {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} {:id 160951, :title "Outlier", :type :wiki-api.core/article} {:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category} {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 694008, :title "Statistics", :type :wiki-api.core/category} {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} {:id 22166736, :title "Non-classical logic", :type :wiki-api.core/category} {:id 1645754, :title "Environmental science", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} {:id 4002768, :title "Evaluation", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category} {:id 3093070, :title "Philosophy of thermal and statistical physics", :type :wiki-api.core/category} {:id 692160, :title "Cryptography", :type :wiki-api.core/category} {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category} {:id 797088, :title "Computer vision", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 711721, :title "Computer storage", :type :wiki-api.core/category} {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} {:id 936702, :title "Audio engineering", :type :wiki-api.core/category} {:id 1855180, :title "Problem solving", :type :wiki-api.core/category} {:id 1557538, :title "Research methods", :type :wiki-api.core/category} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 709184, :title "Materials science", :type :wiki-api.core/category} {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category} {:id 5552682, :title "Film and video technology", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} {:id 23156296, :title "Linear operators in calculus", :type :wiki-api.core/category} {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 9579598, :title "Multivariate interpolation", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 693685, :title "Mathematical logic", :type :wiki-api.core/category} {:id 21753440, :title "Critical thinking", :type :wiki-api.core/category} {:id 973795, :title "Data compression", :type :wiki-api.core/category} {:id 6030151, :title "Probability", :type :wiki-api.core/category} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 7297665, :title "Qualities of thought", :type :wiki-api.core/category} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} {:id 27462792, :title "Sparse matrices", :type :wiki-api.core/category} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} {:id 22712867, :title "Justification", :type :wiki-api.core/category} {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category} {:id 1009209, :title "Information", :type :wiki-api.core/category} {:id 30174957, :title "Causal inference", :type :wiki-api.core/category} {:id 693800, :title "Geography", :type :wiki-api.core/category} {:id 700292, :title "Scientific method", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} {:id 1395115, :title "Research", :type :wiki-api.core/category} {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 187926, :title "Centroid", :type :wiki-api.core/article} {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} {:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category} {:id 9367153, :title "Arabic words and phrases", :type :wiki-api.core/category} {:id 34846657, :title "Syntax (logic)", :type :wiki-api.core/category} {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category} {:id 21917434, :title "Information Age", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category} {:id 1152426, :title "Philosophy of mathematics", :type :wiki-api.core/category} {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} {:id 19908698, :title "State functions", :type :wiki-api.core/category} {:id 18070174, :title "Engineering statistics", :type :wiki-api.core/category} {:id 880411, :title "Digital audio", :type :wiki-api.core/category} {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category} {:id 1098276, :title "Mathematical terminology", :type :wiki-api.core/category} {:id 1055691, :title "Learning", :type :wiki-api.core/category} {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 821959, :title "Matrices", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category} {:id 1087706, :title "Means", :type :wiki-api.core/category} {:id 20602339, :title "Variables", :type :wiki-api.core/category} {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category} {:id 6538827, :title "Statistical randomness", :type :wiki-api.core/category} {:id 26633572, :title "Approximations", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} {:id 15445741, :title "Software quality", :type :wiki-api.core/category} {:id 693986, :title "Probability and statistics", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, :in-map {nil #{}, {:id 763505, :title "Signal processing", :type :wiki-api.core/category} #{}, {:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} #{{:id 690637, :title "Algebra", :type :wiki-api.core/category}}, {:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} #{{:id 5438220, :title "Cheminformatics", :type :wiki-api.core/category} {:id 21764485, :title "Statistical ratios", :type :wiki-api.core/category} {:id 20745673, :title "Medical statistics", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category}}, {:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 745820, :title "DNA", :type :wiki-api.core/category} #{}, {:id 1034006, :title "Particle physics", :type :wiki-api.core/category} #{}, {:id 33432516, :title "Geometric centers", :type :wiki-api.core/category} #{}, {:id 690637, :title "Algebra", :type :wiki-api.core/category} #{}, {:id 18039672, :title "Uncertainty of numbers", :type :wiki-api.core/category} #{{:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category}}, {:id 33432527, :title "Triangle centers", :type :wiki-api.core/category} #{{:id 33432516, :title "Geometric centers", :type :wiki-api.core/category}}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{{:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category}}, {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} #{{:id 6030151, :title "Probability", :type :wiki-api.core/category}}, {:id 26201577, :title "Texture filtering", :type :wiki-api.core/category} #{}, {:id 9614183, :title "Design for X", :type :wiki-api.core/category} #{}, {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category}}, {:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} #{{:id 709184, :title "Materials science", :type :wiki-api.core/category}}, {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} #{}, {:id 744360, :title "Networks", :type :wiki-api.core/category} #{}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} #{{:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category}}, {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} #{}, {:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category} {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category}}, {:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} #{}, {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} #{{:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{{:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category}}, {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} #{}, {:id 746340, :title "Gene expression", :type :wiki-api.core/category} #{}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{{:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 693992, :title "Measure theory", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 30982373, :title "Missing data", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{{:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 709243, :title "Communication", :type :wiki-api.core/category} #{{:id 1009209, :title "Information", :type :wiki-api.core/category}}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{{:id 30636687, :title "Network analysis", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 772270, :title "Philosophy of science", :type :wiki-api.core/category} #{}, {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category}}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 742824, :title "Heuristics", :type :wiki-api.core/category} #{{:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category}}, {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} #{{:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} #{{:id 772270, :title "Philosophy of science", :type :wiki-api.core/category} {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category}}, {:id 691898, :title "Graph theory", :type :wiki-api.core/category} #{{:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category}}, {:id 1376472, :title "Randomness", :type :wiki-api.core/category} #{{:id 692160, :title "Cryptography", :type :wiki-api.core/category} {:id 6538827, :title "Statistical randomness", :type :wiki-api.core/category}}, {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} #{}, {:id 26304777, :title "Graph theory objects", :type :wiki-api.core/category} #{{:id 691898, :title "Graph theory", :type :wiki-api.core/category}}, {:id 31195693, :title "Design of experiments", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category} {:id 6030151, :title "Probability", :type :wiki-api.core/category}}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{{:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 987553, :title "Interpolation", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 16989227, :title "Data", :type :wiki-api.core/category} #{{:id 762162, :title "Data management", :type :wiki-api.core/category}}, {:id 2302180, :title "Integrals", :type :wiki-api.core/category} #{{:id 23156296, :title "Linear operators in calculus", :type :wiki-api.core/category} {:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category}}, {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category}}, {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{{:id 716309, :title "Cartography", :type :wiki-api.core/category} {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} {:id 693800, :title "Geography", :type :wiki-api.core/category}}, {:id 30636687, :title "Network analysis", :type :wiki-api.core/category} #{}, {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} #{{:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category}}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 691136, :title "Algorithms", :type :wiki-api.core/category} #{{:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category} {:id 8761328, :title "Articles with example pseudocode", :type :wiki-api.core/category} {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} {:id 693685, :title "Mathematical logic", :type :wiki-api.core/category} {:id 9367153, :title "Arabic words and phrases", :type :wiki-api.core/category}}, {:id 5438220, :title "Cheminformatics", :type :wiki-api.core/category} #{}, {:id 946892, :title "Econometrics", :type :wiki-api.core/category} #{{:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category}}, {:id 716309, :title "Cartography", :type :wiki-api.core/category} #{}, {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} #{{:id 957793, :title "Cognitive science", :type :wiki-api.core/category}}, {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 26304777, :title "Graph theory objects", :type :wiki-api.core/category}}, {:id 2871217, :title "Educational psychology", :type :wiki-api.core/category} #{}, {:id 20417300, :title "Types of functions", :type :wiki-api.core/category} #{{:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category}}, {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{{:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category}}, {:id 1114964, :title "Digital television", :type :wiki-api.core/category} #{}, {:id 25065, :title "Parameter", :type :wiki-api.core/article} #{{:id 1645754, :title "Environmental science", :type :wiki-api.core/category} {:id 1098276, :title "Mathematical terminology", :type :wiki-api.core/category}}, {:id 4594748, :title "Computational problems", :type :wiki-api.core/category} #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category}}, {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} #{{:id 6030151, :title "Probability", :type :wiki-api.core/category}}, {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} #{{:id 1754736, :title "Cybernetics", :type :wiki-api.core/category}}, {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{{:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} #{}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category}}, {:id 2865929, :title "Entropy", :type :wiki-api.core/category} #{{:id 3093070, :title "Philosophy of thermal and statistical physics", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 19908698, :title "State functions", :type :wiki-api.core/category}}, {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} #{{:id 18039672, :title "Uncertainty of numbers", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} {:id 7297665, :title "Qualities of thought", :type :wiki-api.core/category} {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category}}, {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} #{}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 30982373, :title "Missing data", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 36911884, :title "Utility software types", :type :wiki-api.core/category} #{}, {:id 21764485, :title "Statistical ratios", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 8761328, :title "Articles with example pseudocode", :type :wiki-api.core/category} #{}, {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} #{}, {:id 21067529, :title "Outlines", :type :wiki-api.core/category} #{}, {:id 20745673, :title "Medical statistics", :type :wiki-api.core/category} #{{:id 6537403, :title "Biostatistics", :type :wiki-api.core/category}}, {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} #{}, {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} #{}, {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 4873906, :title "Systems engineering", :type :wiki-api.core/category} #{}, {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} #{}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{{:id 4594748, :title "Computational problems", :type :wiki-api.core/category}}, {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} #{}, {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 1008581, :title "Operations research", :type :wiki-api.core/category} #{{:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} {:id 693986, :title "Probability and statistics", :type :wiki-api.core/category}}, {:id 734262, :title "Measurement", :type :wiki-api.core/category} #{}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category}}, {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} #{{:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category} {:id 22166736, :title "Non-classical logic", :type :wiki-api.core/category} {:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category}}, {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} #{{:id 772545, :title "Probability distributions", :type :wiki-api.core/category}}, {:id 762162, :title "Data management", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 25866614, :title "Videotelephony", :type :wiki-api.core/category} #{}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{{:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 160951, :title "Outlier", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 6030151, :title "Probability", :type :wiki-api.core/category}}, {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 962413, :title "Image processing", :type :wiki-api.core/category} #{{:id 763505, :title "Signal processing", :type :wiki-api.core/category}}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 694008, :title "Statistics", :type :wiki-api.core/category} #{{:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} {:id 1557538, :title "Research methods", :type :wiki-api.core/category} {:id 1009209, :title "Information", :type :wiki-api.core/category} {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} {:id 693986, :title "Probability and statistics", :type :wiki-api.core/category}}, {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} #{{:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} {:id 31195693, :title "Design of experiments", :type :wiki-api.core/category} {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category}}, {:id 22166736, :title "Non-classical logic", :type :wiki-api.core/category} #{{:id 693685, :title "Mathematical logic", :type :wiki-api.core/category}}, {:id 1645754, :title "Environmental science", :type :wiki-api.core/category} #{}, {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} #{}, {:id 4002768, :title "Evaluation", :type :wiki-api.core/category} #{}, {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category}}, {:id 706543, :title "Machine learning", :type :wiki-api.core/category} #{{:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} {:id 1055691, :title "Learning", :type :wiki-api.core/category}}, {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} #{{:id 734262, :title "Measurement", :type :wiki-api.core/category}}, {:id 3175294, :title "Dimension", :type :wiki-api.core/category} #{{:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} {:id 1098276, :title "Mathematical terminology", :type :wiki-api.core/category}}, {:id 3093070, :title "Philosophy of thermal and statistical physics", :type :wiki-api.core/category} #{{:id 693006, :title "Thermodynamics", :type :wiki-api.core/category}}, {:id 692160, :title "Cryptography", :type :wiki-api.core/category} #{}, {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} #{{:id 2871217, :title "Educational psychology", :type :wiki-api.core/category} {:id 734262, :title "Measurement", :type :wiki-api.core/category}}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{{:id 744360, :title "Networks", :type :wiki-api.core/category} {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} {:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category}}, {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category}}, {:id 1419629, :title "Searching", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 797088, :title "Computer vision", :type :wiki-api.core/category} #{{:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 962413, :title "Image processing", :type :wiki-api.core/category}}, {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} #{}, {:id 711721, :title "Computer storage", :type :wiki-api.core/category} #{{:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} #{{:id 877149, :title "Dynamical systems", :type :wiki-api.core/category}}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} #{{:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category}}, {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} #{}, {:id 936702, :title "Audio engineering", :type :wiki-api.core/category} #{}, {:id 1855180, :title "Problem solving", :type :wiki-api.core/category} #{{:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} {:id 21753440, :title "Critical thinking", :type :wiki-api.core/category}}, {:id 1557538, :title "Research methods", :type :wiki-api.core/category} #{{:id 1395115, :title "Research", :type :wiki-api.core/category}}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{{:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 709184, :title "Materials science", :type :wiki-api.core/category} #{}, {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category} #{}, {:id 5552682, :title "Film and video technology", :type :wiki-api.core/category} #{}, {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{{:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 21917434, :title "Information Age", :type :wiki-api.core/category}}, {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} #{{:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} {:id 34846657, :title "Syntax (logic)", :type :wiki-api.core/category} {:id 20602339, :title "Variables", :type :wiki-api.core/category}}, {:id 23156296, :title "Linear operators in calculus", :type :wiki-api.core/category} #{}, {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} #{{:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{{:id 763505, :title "Signal processing", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category}}, {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} #{{:id 9614183, :title "Design for X", :type :wiki-api.core/category} {:id 709184, :title "Materials science", :type :wiki-api.core/category} {:id 18070174, :title "Engineering statistics", :type :wiki-api.core/category} {:id 15445741, :title "Software quality", :type :wiki-api.core/category}}, {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} #{{:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category}}, {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category}}, {:id 9579598, :title "Multivariate interpolation", :type :wiki-api.core/category} #{{:id 987553, :title "Interpolation", :type :wiki-api.core/category}}, {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 21067529, :title "Outlines", :type :wiki-api.core/category} {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category}}, {:id 693685, :title "Mathematical logic", :type :wiki-api.core/category} #{{:id 1152426, :title "Philosophy of mathematics", :type :wiki-api.core/category}}, {:id 21753440, :title "Critical thinking", :type :wiki-api.core/category} #{{:id 4002768, :title "Evaluation", :type :wiki-api.core/category} {:id 1055691, :title "Learning", :type :wiki-api.core/category}}, {:id 973795, :title "Data compression", :type :wiki-api.core/category} #{{:id 1114964, :title "Digital television", :type :wiki-api.core/category} {:id 36911884, :title "Utility software types", :type :wiki-api.core/category} {:id 25866614, :title "Videotelephony", :type :wiki-api.core/category} {:id 711721, :title "Computer storage", :type :wiki-api.core/category} {:id 936702, :title "Audio engineering", :type :wiki-api.core/category} {:id 5552682, :title "Film and video technology", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 880411, :title "Digital audio", :type :wiki-api.core/category}}, {:id 6030151, :title "Probability", :type :wiki-api.core/category} #{{:id 693986, :title "Probability and statistics", :type :wiki-api.core/category}}, {:id 736442, :title "Real numbers", :type :wiki-api.core/category} #{{:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category}}, {:id 7297665, :title "Qualities of thought", :type :wiki-api.core/category} #{}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{{:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} {:id 25208324, :title "F-divergences", :type :wiki-api.core/category}}, {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} #{}, {:id 27462792, :title "Sparse matrices", :type :wiki-api.core/category} #{{:id 821959, :title "Matrices", :type :wiki-api.core/category}}, {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} #{{:id 772270, :title "Philosophy of science", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category} {:id 22712867, :title "Justification", :type :wiki-api.core/category} {:id 1152426, :title "Philosophy of mathematics", :type :wiki-api.core/category}}, {:id 22712867, :title "Justification", :type :wiki-api.core/category} #{}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{{:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} {:id 960021, :title "Natural language processing", :type :wiki-api.core/category}}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{{:id 17306305, :title "Statistical classification", :type :wiki-api.core/category}}, {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category} #{}, {:id 1009209, :title "Information", :type :wiki-api.core/category} #{{:id 16989227, :title "Data", :type :wiki-api.core/category}}, {:id 30174957, :title "Causal inference", :type :wiki-api.core/category} #{{:id 17193265, :title "Statistical inference", :type :wiki-api.core/category}}, {:id 693800, :title "Geography", :type :wiki-api.core/category} #{}, {:id 700292, :title "Scientific method", :type :wiki-api.core/category} #{{:id 1855180, :title "Problem solving", :type :wiki-api.core/category}}, {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} #{{:id 2865929, :title "Entropy", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{{:id 29421852, :title "M-estimators", :type :wiki-api.core/category}}, {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} #{{:id 4002768, :title "Evaluation", :type :wiki-api.core/category}}, {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} #{{:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} #{}, {:id 1395115, :title "Research", :type :wiki-api.core/category} #{{:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} #{}, {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} #{{:id 27462792, :title "Sparse matrices", :type :wiki-api.core/category}}, {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} #{{:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} #{{:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 187926, :title "Centroid", :type :wiki-api.core/article} #{{:id 33432527, :title "Triangle centers", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} {:id 1087706, :title "Means", :type :wiki-api.core/category}}, {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} #{{:id 26633572, :title "Approximations", :type :wiki-api.core/category}}, {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}, {:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category} #{{:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category} {:id 693685, :title "Mathematical logic", :type :wiki-api.core/category}}, {:id 9367153, :title "Arabic words and phrases", :type :wiki-api.core/category} #{}, {:id 34846657, :title "Syntax (logic)", :type :wiki-api.core/category} #{}, {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} #{{:id 26201577, :title "Texture filtering", :type :wiki-api.core/category} {:id 9579598, :title "Multivariate interpolation", :type :wiki-api.core/category}}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category}}, {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category} #{}, {:id 21917434, :title "Information Age", :type :wiki-api.core/category} #{}, {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} #{{:id 1034006, :title "Particle physics", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category} #{{:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 1152426, :title "Philosophy of mathematics", :type :wiki-api.core/category} #{}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{{:id 745820, :title "DNA", :type :wiki-api.core/category} {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} {:id 746340, :title "Gene expression", :type :wiki-api.core/category} {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category}}, {:id 19908698, :title "State functions", :type :wiki-api.core/category} #{}, {:id 18070174, :title "Engineering statistics", :type :wiki-api.core/category} #{{:id 4873906, :title "Systems engineering", :type :wiki-api.core/category} {:id 1008581, :title "Operations research", :type :wiki-api.core/category}}, {:id 880411, :title "Digital audio", :type :wiki-api.core/category} #{}, {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category} #{}, {:id 1098276, :title "Mathematical terminology", :type :wiki-api.core/category} #{}, {:id 1055691, :title "Learning", :type :wiki-api.core/category} #{}, {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} #{{:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{{:id 693992, :title "Measure theory", :type :wiki-api.core/category} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 20417300, :title "Types of functions", :type :wiki-api.core/category}}, {:id 821959, :title "Matrices", :type :wiki-api.core/category} #{}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{{:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 9500290, :title "Experiments", :type :wiki-api.core/category} #{{:id 31195693, :title "Design of experiments", :type :wiki-api.core/category} {:id 30174957, :title "Causal inference", :type :wiki-api.core/category}}, {:id 1087706, :title "Means", :type :wiki-api.core/category} #{{:id 33432516, :title "Geometric centers", :type :wiki-api.core/category} {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category}}, {:id 20602339, :title "Variables", :type :wiki-api.core/category} #{{:id 690637, :title "Algebra", :type :wiki-api.core/category}}, {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category} #{}, {:id 6538827, :title "Statistical randomness", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 26633572, :title "Approximations", :type :wiki-api.core/category} #{{:id 697506, :title "Numerical analysis", :type :wiki-api.core/category}}, {:id 951835, :title "Computer data", :type :wiki-api.core/category} #{{:id 16989227, :title "Data", :type :wiki-api.core/category}}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category}}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{{:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 15445741, :title "Software quality", :type :wiki-api.core/category} #{}, {:id 693986, :title "Probability and statistics", :type :wiki-api.core/category} #{{:id 734262, :title "Measurement", :type :wiki-api.core/category}}, {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{{:id 17193061, :title "Statistical data types", :type :wiki-api.core/category}}}, :out-map {nil #{}, {:id 763505, :title "Signal processing", :type :wiki-api.core/category} #{{:id 962413, :title "Image processing", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article}}, {:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} #{}, {:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} #{{:id 5175143, :title "Geostatistics", :type :wiki-api.core/category}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{}, {:id 745820, :title "DNA", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 1034006, :title "Particle physics", :type :wiki-api.core/category} #{{:id 14482748, :title "Data analysis", :type :wiki-api.core/category}}, {:id 33432516, :title "Geometric centers", :type :wiki-api.core/category} #{{:id 33432527, :title "Triangle centers", :type :wiki-api.core/category} {:id 1087706, :title "Means", :type :wiki-api.core/category}}, {:id 690637, :title "Algebra", :type :wiki-api.core/category} #{{:id 690672, :title "Abstract algebra", :type :wiki-api.core/category} {:id 20602339, :title "Variables", :type :wiki-api.core/category}}, {:id 18039672, :title "Uncertainty of numbers", :type :wiki-api.core/category} #{{:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article}}, {:id 33432527, :title "Triangle centers", :type :wiki-api.core/category} #{{:id 187926, :title "Centroid", :type :wiki-api.core/article}}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{}, {:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 26201577, :title "Texture filtering", :type :wiki-api.core/category} #{{:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article}}, {:id 9614183, :title "Design for X", :type :wiki-api.core/category} #{{:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category}}, {:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} #{{:id 8495, :title "Data set", :type :wiki-api.core/article}}, {:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} #{{:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article}}, {:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} #{{:id 24114689, :title "Microarrays", :type :wiki-api.core/category}}, {:id 957793, :title "Cognitive science", :type :wiki-api.core/category} #{{:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category} {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category}}, {:id 744360, :title "Networks", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 5206601, :title "Data mining", :type :wiki-api.core/category} #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 24114689, :title "Microarrays", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 17503782, :title "Formal sciences", :type :wiki-api.core/category} #{{:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category}}, {:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} #{{:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article}}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{}, {:id 990361, :title "Theoretical computer science", :type :wiki-api.core/category} #{{:id 691898, :title "Graph theory", :type :wiki-api.core/category} {:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category}}, {:id 25825321, :title "Mathematical sciences", :type :wiki-api.core/category} #{{:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} #{{:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article}}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{{:id 4594748, :title "Computational problems", :type :wiki-api.core/category}}, {:id 1179887, :title "Dimensionless numbers", :type :wiki-api.core/category} #{{:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article}}, {:id 746340, :title "Gene expression", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{}, {:id 693992, :title "Measure theory", :type :wiki-api.core/category} #{{:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{}, {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} #{{:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category}}, {:id 30982373, :title "Missing data", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article}}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{}, {:id 709243, :title "Communication", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{}, {:id 772270, :title "Philosophy of science", :type :wiki-api.core/category} #{{:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article}}, {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} #{{:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category}}, {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 160951, :title "Outlier", :type :wiki-api.core/article} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article}}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{}, {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 160951, :title "Outlier", :type :wiki-api.core/article}}, {:id 742824, :title "Heuristics", :type :wiki-api.core/category} #{}, {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category} #{{:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 187926, :title "Centroid", :type :wiki-api.core/article} {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category}}, {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} #{{:id 160951, :title "Outlier", :type :wiki-api.core/article}}, {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article}}, {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} #{}, {:id 691898, :title "Graph theory", :type :wiki-api.core/category} #{{:id 26304777, :title "Graph theory objects", :type :wiki-api.core/category}}, {:id 1376472, :title "Randomness", :type :wiki-api.core/category} #{{:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category}}, {:id 5065063, :title "Network architecture", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 26304777, :title "Graph theory objects", :type :wiki-api.core/category} #{{:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article}}, {:id 31195693, :title "Design of experiments", :type :wiki-api.core/category} #{{:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} #{{:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 30982373, :title "Missing data", :type :wiki-api.core/category} {:id 24960643, :title "Statistical outliers", :type :wiki-api.core/category} {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{{:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category}}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{}, {:id 987553, :title "Interpolation", :type :wiki-api.core/category} #{{:id 9579598, :title "Multivariate interpolation", :type :wiki-api.core/category}}, {:id 16989227, :title "Data", :type :wiki-api.core/category} #{{:id 1009209, :title "Information", :type :wiki-api.core/category} {:id 951835, :title "Computer data", :type :wiki-api.core/category}}, {:id 2302180, :title "Integrals", :type :wiki-api.core/category} #{}, {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 3867956, :title "Combinatorial optimization", :type :wiki-api.core/category}}, {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} #{{:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 30174957, :title "Causal inference", :type :wiki-api.core/category}}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{}, {:id 30636687, :title "Network analysis", :type :wiki-api.core/category} #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} #{{:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{}, {:id 691136, :title "Algorithms", :type :wiki-api.core/category} #{{:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category}}, {:id 5438220, :title "Cheminformatics", :type :wiki-api.core/category} #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article}}, {:id 946892, :title "Econometrics", :type :wiki-api.core/category} #{{:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 716309, :title "Cartography", :type :wiki-api.core/category} #{{:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 1754736, :title "Cybernetics", :type :wiki-api.core/category} #{{:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category}}, {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} #{{:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category}}, {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} #{}, {:id 2871217, :title "Educational psychology", :type :wiki-api.core/category} #{{:id 804551, :title "Psychometrics", :type :wiki-api.core/category}}, {:id 20417300, :title "Types of functions", :type :wiki-api.core/category} #{{:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} #{{:id 987553, :title "Interpolation", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 26633572, :title "Approximations", :type :wiki-api.core/category}}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{}, {:id 1114964, :title "Digital television", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 25065, :title "Parameter", :type :wiki-api.core/article} #{}, {:id 4594748, :title "Computational problems", :type :wiki-api.core/category} #{{:id 1126536, :title "Optimization problem", :type :wiki-api.core/article}}, {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article}}, {:id 700355, :title "Artificial intelligence", :type :wiki-api.core/category} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category} {:id 797088, :title "Computer vision", :type :wiki-api.core/category} {:id 1855180, :title "Problem solving", :type :wiki-api.core/category}}, {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} #{{:id 18039672, :title "Uncertainty of numbers", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{}, {:id 4822234, :title "Mathematical and quantitative methods (economics)", :type :wiki-api.core/category} #{{:id 946892, :title "Econometrics", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{{:id 34044100, :title "Optimization algorithms and methods", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 2865929, :title "Entropy", :type :wiki-api.core/category} #{{:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} #{}, {:id 694609, :title "Discrete geometry", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{}, {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category} #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article}}, {:id 36911884, :title "Utility software types", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 21764485, :title "Statistical ratios", :type :wiki-api.core/category} #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article}}, {:id 8761328, :title "Articles with example pseudocode", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category}}, {:id 26339806, :title "Auxiliary sciences of history", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 21067529, :title "Outlines", :type :wiki-api.core/category} #{{:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article}}, {:id 20745673, :title "Medical statistics", :type :wiki-api.core/category} #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article}}, {:id 18806314, :title "Articles containing video clips", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 28335948, :title "Articles with inconsistent citation formats", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} {:id 4861714, :title "Hypothesis testing", :type :wiki-api.core/category} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 4873906, :title "Systems engineering", :type :wiki-api.core/category} #{{:id 18070174, :title "Engineering statistics", :type :wiki-api.core/category}}, {:id 763625, :title "Affine geometry", :type :wiki-api.core/category} #{{:id 187926, :title "Centroid", :type :wiki-api.core/article}}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{}, {:id 27248985, :title "Mathematical concepts", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category}}, {:id 6539078, :title "Multivariate statistics", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 1008581, :title "Operations research", :type :wiki-api.core/category} #{{:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 18070174, :title "Engineering statistics", :type :wiki-api.core/category}}, {:id 734262, :title "Measurement", :type :wiki-api.core/category} #{{:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} {:id 693986, :title "Probability and statistics", :type :wiki-api.core/category}}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} #{}, {:id 17990732, :title "Theory of probability distributions", :type :wiki-api.core/category} #{{:id 6535800, :title "Covariance and correlation", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article}}, {:id 762162, :title "Data management", :type :wiki-api.core/category} #{{:id 16989227, :title "Data", :type :wiki-api.core/category}}, {:id 25866614, :title "Videotelephony", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{}, {:id 160951, :title "Outlier", :type :wiki-api.core/article} #{}, {:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category} #{{:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article}}, {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} #{}, {:id 962413, :title "Image processing", :type :wiki-api.core/category} #{{:id 987553, :title "Interpolation", :type :wiki-api.core/category} {:id 797088, :title "Computer vision", :type :wiki-api.core/category}}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{}, {:id 694008, :title "Statistics", :type :wiki-api.core/category} #{{:id 6538378, :title "Statistical data sets", :type :wiki-api.core/category} {:id 9387252, :title "Non-parametric statistics", :type :wiki-api.core/category} {:id 17338386, :title "Statistical terminology", :type :wiki-api.core/category} {:id 6535219, :title "Statistical charts and diagrams", :type :wiki-api.core/category} {:id 22042655, :title "Statistical principles", :type :wiki-api.core/category} {:id 31195693, :title "Design of experiments", :type :wiki-api.core/category} {:id 6533911, :title "Bayesian statistics", :type :wiki-api.core/category} {:id 17193061, :title "Statistical data types", :type :wiki-api.core/category} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 17193265, :title "Statistical inference", :type :wiki-api.core/category} {:id 17652827, :title "Statistical dependence", :type :wiki-api.core/category} {:id 5038508, :title "Information, knowledge, and uncertainty", :type :wiki-api.core/category} {:id 21764485, :title "Statistical ratios", :type :wiki-api.core/category} {:id 6539521, :title "Statistical theory", :type :wiki-api.core/category} {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} {:id 6538827, :title "Statistical randomness", :type :wiki-api.core/category}}, {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} #{}, {:id 22166736, :title "Non-classical logic", :type :wiki-api.core/category} #{{:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category}}, {:id 1645754, :title "Environmental science", :type :wiki-api.core/category} #{{:id 25065, :title "Parameter", :type :wiki-api.core/article}}, {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category}}, {:id 26308484, :title "Summary statistics for contingency tables", :type :wiki-api.core/category} #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article}}, {:id 4002768, :title "Evaluation", :type :wiki-api.core/category} #{{:id 21753440, :title "Critical thinking", :type :wiki-api.core/category} {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category}}, {:id 6536797, :title "Statistical algorithms", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category}}, {:id 706543, :title "Machine learning", :type :wiki-api.core/category} #{{:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 1991254, :title "Classification algorithms", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 33748657, :title "Geometric measurement", :type :wiki-api.core/category} #{{:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 3175294, :title "Dimension", :type :wiki-api.core/category} #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 29549713, :title "Dimension reduction", :type :wiki-api.core/category}}, {:id 3093070, :title "Philosophy of thermal and statistical physics", :type :wiki-api.core/category} #{{:id 2865929, :title "Entropy", :type :wiki-api.core/category}}, {:id 692160, :title "Cryptography", :type :wiki-api.core/category} #{{:id 1376472, :title "Randomness", :type :wiki-api.core/category}}, {:id 804551, :title "Psychometrics", :type :wiki-api.core/category} #{{:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article}}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article}}, {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category} #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} {:id 24114689, :title "Microarrays", :type :wiki-api.core/category}}, {:id 1419629, :title "Searching", :type :wiki-api.core/category} #{{:id 1406201, :title "Search algorithms", :type :wiki-api.core/category}}, {:id 797088, :title "Computer vision", :type :wiki-api.core/category} #{{:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category}}, {:id 36477012, :title "Concepts in physics", :type :wiki-api.core/category} #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 2865929, :title "Entropy", :type :wiki-api.core/category} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 711721, :title "Computer storage", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category} #{{:id 3093070, :title "Philosophy of thermal and statistical physics", :type :wiki-api.core/category}}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{}, {:id 22058368, :title "Mathematical principles", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article}}, {:id 960021, :title "Natural language processing", :type :wiki-api.core/category} #{{:id 7279789, :title "Information retrieval", :type :wiki-api.core/category}}, {:id 936702, :title "Audio engineering", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 1855180, :title "Problem solving", :type :wiki-api.core/category} #{{:id 700292, :title "Scientific method", :type :wiki-api.core/category}}, {:id 1557538, :title "Research methods", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{}, {:id 709184, :title "Materials science", :type :wiki-api.core/category} #{{:id 14631447, :title "Microtechnology", :type :wiki-api.core/category} {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category}}, {:id 4289067, :title "Computational neuroscience", :type :wiki-api.core/category} #{{:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 5552682, :title "Film and video technology", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 17506498, :title "Logic and statistics", :type :wiki-api.core/category} #{{:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article}}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category} {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category}}, {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} #{}, {:id 23156296, :title "Linear operators in calculus", :type :wiki-api.core/category} #{{:id 2302180, :title "Integrals", :type :wiki-api.core/category}}, {:id 31180880, :title "Asymptotic statistical theory", :type :wiki-api.core/category} #{{:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 693006, :title "Thermodynamics", :type :wiki-api.core/category}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} #{}, {:id 5175143, :title "Geostatistics", :type :wiki-api.core/category} #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 702582, :title "Geometric algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 9579598, :title "Multivariate interpolation", :type :wiki-api.core/category} #{{:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article}}, {:id 33547228, :title "Machine learning algorithms", :type :wiki-api.core/category} #{{:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article}}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{}, {:id 693685, :title "Mathematical logic", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category} {:id 22166736, :title "Non-classical logic", :type :wiki-api.core/category} {:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category}}, {:id 21753440, :title "Critical thinking", :type :wiki-api.core/category} #{{:id 1855180, :title "Problem solving", :type :wiki-api.core/category}}, {:id 973795, :title "Data compression", :type :wiki-api.core/category} #{}, {:id 6030151, :title "Probability", :type :wiki-api.core/category} #{{:id 22705265, :title "Probability assessment", :type :wiki-api.core/category} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 28927577, :title "Probabilistic models", :type :wiki-api.core/category} {:id 17735029, :title "Probability interpretations", :type :wiki-api.core/category}}, {:id 736442, :title "Real numbers", :type :wiki-api.core/category} #{}, {:id 7297665, :title "Qualities of thought", :type :wiki-api.core/category} #{{:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article}}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{}, {:id 1754928, :title "Elementary mathematics", :type :wiki-api.core/category} #{{:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category}}, {:id 27462792, :title "Sparse matrices", :type :wiki-api.core/category} #{{:id 341015, :title "Sparse matrix", :type :wiki-api.core/article}}, {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} #{}, {:id 22712867, :title "Justification", :type :wiki-api.core/category} #{{:id 4890, :title "Bayesian probability", :type :wiki-api.core/article}}, {:id 7279789, :title "Information retrieval", :type :wiki-api.core/category} #{{:id 762162, :title "Data management", :type :wiki-api.core/category} {:id 1419629, :title "Searching", :type :wiki-api.core/category}}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{}, {:id 15668807, :title "Molecular biology techniques", :type :wiki-api.core/category} #{{:id 24114689, :title "Microarrays", :type :wiki-api.core/category}}, {:id 1009209, :title "Information", :type :wiki-api.core/category} #{{:id 709243, :title "Communication", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 30174957, :title "Causal inference", :type :wiki-api.core/category} #{{:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 693800, :title "Geography", :type :wiki-api.core/category} #{{:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article}}, {:id 700292, :title "Scientific method", :type :wiki-api.core/category} #{{:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 1395115, :title "Research", :type :wiki-api.core/category}}, {:id 9910848, :title "Entropy and information", :type :wiki-api.core/category} #{{:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{}, {:id 4003390, :title "Evaluation methods", :type :wiki-api.core/category} #{{:id 694008, :title "Statistics", :type :wiki-api.core/category}}, {:id 15358536, :title "Object recognition and categorization", :type :wiki-api.core/category} #{{:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article}}, {:id 25208324, :title "F-divergences", :type :wiki-api.core/category} #{{:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article}}, {:id 1395115, :title "Research", :type :wiki-api.core/category} #{{:id 1557538, :title "Research methods", :type :wiki-api.core/category}}, {:id 6537403, :title "Biostatistics", :type :wiki-api.core/category} #{{:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 20745673, :title "Medical statistics", :type :wiki-api.core/category} {:id 726312, :title "Bioinformatics", :type :wiki-api.core/category}}, {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} #{}, {:id 17193471, :title "Statistical models", :type :wiki-api.core/category} #{{:id 20924581, :title "Latent variable models", :type :wiki-api.core/category}}, {:id 5200150, :title "Monte Carlo methods", :type :wiki-api.core/category} #{{:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category}}, {:id 19314112, :title "Learning in computer vision", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category}}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{}, {:id 187926, :title "Centroid", :type :wiki-api.core/article} #{}, {:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category} #{{:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article}}, {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} #{}, {:id 1010631, :title "Logic in computer science", :type :wiki-api.core/category} #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category}}, {:id 9367153, :title "Arabic words and phrases", :type :wiki-api.core/category} #{{:id 691136, :title "Algorithms", :type :wiki-api.core/category}}, {:id 34846657, :title "Syntax (logic)", :type :wiki-api.core/category} #{{:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article}}, {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} #{}, {:id 20924581, :title "Latent variable models", :type :wiki-api.core/category} #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article}}, {:id 691875, :title "Mathematical analysis", :type :wiki-api.core/category} #{{:id 693992, :title "Measure theory", :type :wiki-api.core/category} {:id 697506, :title "Numerical analysis", :type :wiki-api.core/category} {:id 877149, :title "Dynamical systems", :type :wiki-api.core/category} {:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category} {:id 1087706, :title "Means", :type :wiki-api.core/category}}, {:id 21917434, :title "Information Age", :type :wiki-api.core/category} #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, {:id 14482748, :title "Data analysis", :type :wiki-api.core/category} #{{:id 17228412, :title "Spatial data analysis", :type :wiki-api.core/category} {:id 5206601, :title "Data mining", :type :wiki-api.core/category} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 160951, :title "Outlier", :type :wiki-api.core/article}}, {:id 8111581, :title "Functions and mappings", :type :wiki-api.core/category} #{{:id 2302180, :title "Integrals", :type :wiki-api.core/category} {:id 691866, :title "Functional analysis", :type :wiki-api.core/category} {:id 20417300, :title "Types of functions", :type :wiki-api.core/category}}, {:id 1152426, :title "Philosophy of mathematics", :type :wiki-api.core/category} #{{:id 693685, :title "Mathematical logic", :type :wiki-api.core/category} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article}}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{}, {:id 19908698, :title "State functions", :type :wiki-api.core/category} #{{:id 2865929, :title "Entropy", :type :wiki-api.core/category}}, {:id 18070174, :title "Engineering statistics", :type :wiki-api.core/category} #{{:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category}}, {:id 880411, :title "Digital audio", :type :wiki-api.core/category} #{{:id 973795, :title "Data compression", :type :wiki-api.core/category}}, {:id 22369286, :title "Glass coating and surface modification", :type :wiki-api.core/category} #{{:id 255954, :title "DNA microarray", :type :wiki-api.core/article}}, {:id 1098276, :title "Mathematical terminology", :type :wiki-api.core/category} #{{:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 3175294, :title "Dimension", :type :wiki-api.core/category}}, {:id 1055691, :title "Learning", :type :wiki-api.core/category} #{{:id 706543, :title "Machine learning", :type :wiki-api.core/category} {:id 21753440, :title "Critical thinking", :type :wiki-api.core/category}}, {:id 29421852, :title "M-estimators", :type :wiki-api.core/category} #{{:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article}}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{}, {:id 821959, :title "Matrices", :type :wiki-api.core/category} #{{:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} {:id 27462792, :title "Sparse matrices", :type :wiki-api.core/category}}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{}, {:id 9500290, :title "Experiments", :type :wiki-api.core/category} #{}, {:id 1087706, :title "Means", :type :wiki-api.core/category} #{{:id 187926, :title "Centroid", :type :wiki-api.core/article}}, {:id 20602339, :title "Variables", :type :wiki-api.core/category} #{{:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article}}, {:id 3030686, :title "Real algebraic geometry", :type :wiki-api.core/category} #{{:id 736442, :title "Real numbers", :type :wiki-api.core/category}}, {:id 6538827, :title "Statistical randomness", :type :wiki-api.core/category} #{{:id 1376472, :title "Randomness", :type :wiki-api.core/category}}, {:id 26633572, :title "Approximations", :type :wiki-api.core/category} #{{:id 2597177, :title "Approximation algorithms", :type :wiki-api.core/category}}, {:id 951835, :title "Computer data", :type :wiki-api.core/category} #{{:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 711721, :title "Computer storage", :type :wiki-api.core/category}}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{}, {:id 15445741, :title "Software quality", :type :wiki-api.core/category} #{{:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category}}, {:id 693986, :title "Probability and statistics", :type :wiki-api.core/category} #{{:id 1008581, :title "Operations research", :type :wiki-api.core/category} {:id 694008, :title "Statistics", :type :wiki-api.core/category} {:id 6030151, :title "Probability", :type :wiki-api.core/category}}, {:id 15325165, :title "Data clustering algorithms", :type :wiki-api.core/category} #{{:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{}}}, :topic-docs #graphs.core.Digraph{:nodes #{nil 730336 3500384 {:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} 3663520 584416 595744 3078048 594049 {:id 501509, :title "Data point", :type :wiki-api.core/article} 3736161 588737 1032258 {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} 3023522 3525346 1031235 1009731 3394083 3060291 1032835 1031939 597891 985059 {:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} 3471908 {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} 832677 1033413 {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} 1297381 {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} 3509574 3708230 {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 1376472, :title "Randomness", :type :wiki-api.core/category} 839752 1009800 3307625 {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 2302180, :title "Integrals", :type :wiki-api.core/category} 3307209 {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} 27498 527435 1219659 {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} 3462412 {:id 25065, :title "Parameter", :type :wiki-api.core/article} 3482604 1023181 {:id 8495, :title "Data set", :type :wiki-api.core/article} 3447405 3383981 839501 3506029 {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 2865929, :title "Entropy", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} 939118 {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} 893422 1031215 1033455 2966831 3156815 2878447 {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} 1042704 3073360 {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} 3700560 {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} 3570833 {:id 160951, :title "Outlier", :type :wiki-api.core/article} {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} 3233265 {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} 2870097 1257393 {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} 2864403 2771 {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} 3679540 1273172 3490997 600021 3365845 {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} 346006 {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} 3677399 {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} 1167799 {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 973795, :title "Data compression", :type :wiki-api.core/category} 1033911 570103 {:id 6030151, :title "Probability", :type :wiki-api.core/category} 527448 {:id 736442, :title "Real numbers", :type :wiki-api.core/category} 1065112 2867384 3516632 {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} 3691896 1031640 {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} 3526009 {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} 790361 3346425 1032218 985178 1239162 {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 187926, :title "Centroid", :type :wiki-api.core/article} {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} 985307 3483899 {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} 907739 3620443 3395323 1044411 3061755 {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} 984956 3486588 {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} 3548061 1031101 {:id 9500290, :title "Experiments", :type :wiki-api.core/category} 3359998 {:id 26633572, :title "Approximations", :type :wiki-api.core/category} 515774 1009438 {:id 472877, :title "Prior probability", :type :wiki-api.core/article} 1199966 3065726 3358654 {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} 1113151 642207 2867423 {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, :in-map {nil #{}, 730336 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article}}, 3500384 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} #{}, 3663520 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article}}, 584416 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, 595744 #{{:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 3078048 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 594049 #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{}, 3736161 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 588737 #{{:id 694025, :title "Information theory", :type :wiki-api.core/category}}, 1032258 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 2302180, :title "Integrals", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{}, 3023522 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 3525346 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, 1031235 #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, 1009731 #{nil {:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, 3394083 #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, 3060291 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1032835 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article}}, 1031939 #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, 597891 #{{:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article}}, 985059 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{}, 3471908 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category}}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{}, 832677 #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article}}, 1033413 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article}}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{}, 1297381 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{}, 3509574 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 3708230 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} #{}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{}, {:id 742824, :title "Heuristics", :type :wiki-api.core/category} #{}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{}, {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} #{}, {:id 1376472, :title "Randomness", :type :wiki-api.core/category} #{}, 839752 #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category} {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article}}, 1009800 #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 3307625 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1171513, :title "Neural networks", :type :wiki-api.core/category}}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{}, {:id 2302180, :title "Integrals", :type :wiki-api.core/category} #{}, 3307209 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{}, 27498 #{{:id 2302180, :title "Integrals", :type :wiki-api.core/category} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, 527435 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, 1219659 #{{:id 871681, :title "Mixture model", :type :wiki-api.core/article} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} {:id 472877, :title "Prior probability", :type :wiki-api.core/article}}, {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} #{}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{}, 3462412 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 25065, :title "Parameter", :type :wiki-api.core/article} #{}, 3482604 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category}}, 1023181 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} {:id 26633572, :title "Approximations", :type :wiki-api.core/category}}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{}, 3447405 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 3383981 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 839501 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category}}, 3506029 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{}, {:id 2865929, :title "Entropy", :type :wiki-api.core/category} #{}, {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} #{}, 939118 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{}, 893422 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article}}, 1031215 #{{:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article}}, 1033455 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 160951, :title "Outlier", :type :wiki-api.core/article} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, 2966831 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 3156815 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, 2878447 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 25065, :title "Parameter", :type :wiki-api.core/article}}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{}, 1042704 #{{:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article}}, 3073360 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{}, {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} #{}, 3700560 #{{:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article}}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{}, 3570833 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 160951, :title "Outlier", :type :wiki-api.core/article} #{}, {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} #{}, 3233265 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{}, {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} #{}, 2870097 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 1257393 #{{:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{}, 2864403 #{nil {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, 2771 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{}, 3679540 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1273172 #{{:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article}}, 3490997 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 600021 #{{:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} {:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 3365845 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{}, {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} #{}, 346006 #{{:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{}, 3677399 #{{:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category}}, {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} #{}, 1167799 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{}, {:id 973795, :title "Data compression", :type :wiki-api.core/category} #{}, 1033911 #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} {:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 2865929, :title "Entropy", :type :wiki-api.core/category} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} {:id 973795, :title "Data compression", :type :wiki-api.core/category} {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} {:id 245523, :title "Weight function", :type :wiki-api.core/article}}, 570103 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 6030151, :title "Probability", :type :wiki-api.core/category} #{}, 527448 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 736442, :title "Real numbers", :type :wiki-api.core/category} #{}, 1065112 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article}}, 2867384 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 3516632 #{{:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article}}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{}, 3691896 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1031640 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 43487, :title "Probability density function", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article}}, {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} #{}, 3526009 #{{:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{}, 790361 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 3346425 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1032218 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category}}, 985178 #{{:id 772545, :title "Probability distributions", :type :wiki-api.core/category} {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 973795, :title "Data compression", :type :wiki-api.core/category} {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} {:id 187926, :title "Centroid", :type :wiki-api.core/article}}, 1239162 #{{:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category} {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{}, {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} #{}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{}, {:id 187926, :title "Centroid", :type :wiki-api.core/article} #{}, {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} #{}, 985307 #{{:id 742824, :title "Heuristics", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 694025, :title "Information theory", :type :wiki-api.core/category}}, 3483899 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category}}, {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} #{}, 907739 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} {:id 6030151, :title "Probability", :type :wiki-api.core/category} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, 3620443 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 3395323 #{{:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1044411 #{nil {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} {:id 736442, :title "Real numbers", :type :wiki-api.core/category} {:id 245523, :title "Weight function", :type :wiki-api.core/article} {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article}}, 3061755 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article}}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{}, 984956 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 5245063, :title "Feature space", :type :wiki-api.core/article} {:id 25065, :title "Parameter", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 160951, :title "Outlier", :type :wiki-api.core/article} {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} {:id 821148, :title "Level of measurement", :type :wiki-api.core/article}}, 3486588 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{}, 3548061 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 1031101 #{{:id 501509, :title "Data point", :type :wiki-api.core/article} {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 8495, :title "Data set", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} {:id 187926, :title "Centroid", :type :wiki-api.core/article}}, {:id 9500290, :title "Experiments", :type :wiki-api.core/category} #{}, 3359998 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 26633572, :title "Approximations", :type :wiki-api.core/category} #{}, 515774 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 1009438 #{{:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article}}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{}, 1199966 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, 3065726 #{{:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article}}, 3358654 #{{:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category}}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{}, 1113151 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category} {:id 26633572, :title "Approximations", :type :wiki-api.core/category}}, 642207 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 1376472, :title "Randomness", :type :wiki-api.core/category} {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, 2867423 #{{:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} {:id 9500290, :title "Experiments", :type :wiki-api.core/category}}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{}}, :out-map {nil #{1009731 2864403 1044411}, 730336 #{}, 3500384 #{}, {:id 5599330, :title "Sensitivity and specificity", :type :wiki-api.core/article} #{1009800 600021}, 3663520 #{}, 584416 #{}, 595744 #{}, 3078048 #{}, 594049 #{}, {:id 501509, :title "Data point", :type :wiki-api.core/article} #{1033413 1033455 600021 1031640 1032218 1031101}, 3736161 #{}, 588737 #{}, 1032258 #{}, {:id 34760990, :title "Nonlinear systems", :type :wiki-api.core/category} #{1031235 1042704}, 3023522 #{}, 3525346 #{}, 1031235 #{}, 1009731 #{}, 3394083 #{}, 3060291 #{}, 1032835 #{}, 1031939 #{}, 597891 #{}, 985059 #{}, {:id 871681, :title "Mixture model", :type :wiki-api.core/article} #{1009731 1219659}, {:id 693727, :title "Computational complexity theory", :type :wiki-api.core/category} #{594049 839752 1033911 1009438}, 3471908 #{}, {:id 76996, :title "Self-organizing map", :type :wiki-api.core/article} #{1009800 1042704}, 832677 #{}, 1033413 #{}, {:id 8398, :title "Dimension (mathematics and physics)", :type :wiki-api.core/article} #{584416 1031235 1009731 839752 1023181 939118 893422 600021 1167799 570103 527448 2867384 907739 984956 1113151 642207 2867423}, {:id 5245063, :title "Feature space", :type :wiki-api.core/article} #{1031235 2867384 984956}, {:id 126706, :title "Pattern recognition", :type :wiki-api.core/article} #{1031939 832677 1273172}, {:id 18462661, :title "Resampling (statistics)", :type :wiki-api.core/category} #{1009800 1023181 2867384}, 1297381 #{}, {:id 477573, :title "Hierarchical clustering", :type :wiki-api.core/article} #{1032258 3023522 1009731 1032835 3509574 1023181 2966831 3073360 2870097 1273172 1033911 790361 3548061 3065726}, 3509574 #{}, 3708230 #{}, {:id 17401622, :title "Robust statistics", :type :wiki-api.core/category} #{1031939 1033413 1273172 1167799 1239162 907739 3395323}, {:id 7309022, :title "Nearest neighbor search", :type :wiki-api.core/article} #{839752 2864403}, {:id 201718, :title "Principle of maximum entropy", :type :wiki-api.core/article} #{1032835 1031101}, {:id 742824, :title "Heuristics", :type :wiki-api.core/category} #{893422 2870097 3526009 985307}, {:id 22532673, :title "Cluster analysis", :type :wiki-api.core/category} #{730336 3500384 3663520 3078048 594049 3736161 3525346 3060291 985059 3471908 1297381 3708230 3307209 527435 3462412 3482604 3447405 3383981 839501 3506029 1033455 3156815 3570833 3233265 2771 3679540 3490997 3365845 1065112 3691896 3526009 3346425 3483899 3620443 3395323 3061755 3486588 3359998 515774 1199966 3358654}, {:id 16244271, :title "Validity (statistics)", :type :wiki-api.core/category} #{584416 1009800 3482604 1023181 939118 1033455 1065112 2867384 1031640 1031101}, {:id 1376472, :title "Randomness", :type :wiki-api.core/category} #{1009731 1033911 642207}, 839752 #{}, 1009800 #{}, 3307625 #{}, {:id 772545, :title "Probability distributions", :type :wiki-api.core/category} #{1219659 1033911 985178}, {:id 157057, :title "Correlation and dependence", :type :wiki-api.core/article} #{584416 595744 597891}, {:id 2302180, :title "Integrals", :type :wiki-api.core/category} #{1032258 27498}, 3307209 #{}, {:id 3190431, :title "Spatial analysis", :type :wiki-api.core/article} #{839752 1113151 642207}, {:id 2422496, :title "Fuzzy clustering", :type :wiki-api.core/article} #{27498 1257393 2867384 3516632 1031101}, {:id 22324566, :title "Determining the number of clusters in a data set", :type :wiki-api.core/article} #{1033413 3307625 893422 2878447 3677399 1033911 527448 2867384 1031640 1031101 1009438}, 27498 #{}, 527435 #{}, 1219659 #{}, {:id 325806, :title "Graph (mathematics)", :type :wiki-api.core/article} #{1031215 1042704 2870097}, {:id 43487, :title "Probability density function", :type :wiki-api.core/article} #{1033413 839752 1031640}, 3462412 #{}, {:id 25065, :title "Parameter", :type :wiki-api.core/article} #{1009731 597891 2878447 527448 2867384 907739 984956}, 3482604 #{}, 1023181 #{}, {:id 8495, :title "Data set", :type :wiki-api.core/article} #{3663520 1031235 1009731 597891 1219659 1023181 939118 2864403 600021 1167799 1065112 2867384 1031640 1239162 1044411 984956 1031101}, 3447405 #{}, 3383981 #{}, 839501 #{}, 3506029 #{}, {:id 18956829, :title "Mathematical optimization", :type :wiki-api.core/category} #{584416 1032258 1032835 3307625 1219659 839501 1033455 1042704 2870097 600021 1031640 985307 3483899 1031101 2867423}, {:id 2865929, :title "Entropy", :type :wiki-api.core/category} #{1033911}, {:id 41932, :title "Accuracy and precision", :type :wiki-api.core/article} #{594049 1273172 1167799 1033911 1239162 1009438}, 939118 #{}, {:id 470752, :title "Expectation–maximization algorithm", :type :wiki-api.core/article} #{1009731 985178}, 893422 #{}, 1031215 #{}, 1033455 #{}, 2966831 #{}, 3156815 #{}, 2878447 #{}, {:id 1126536, :title "Optimization problem", :type :wiki-api.core/article} #{1033455 1042704 2870097 2864403 985307}, 1042704 #{}, 3073360 #{}, {:id 17306305, :title "Statistical classification", :type :wiki-api.core/category} #{1031939 839752 2864403 1273172 1031640 1044411}, {:id 957250, :title "Fuzzy logic", :type :wiki-api.core/category} #{1032258 3471908 1033413 27498 1042704 2867384 1031640 1031101}, 3700560 #{}, {:id 20556859, :title "Matrix (mathematics)", :type :wiki-api.core/article} #{27498 1273172}, 3570833 #{}, {:id 160951, :title "Outlier", :type :wiki-api.core/article} #{1033455 984956}, {:id 6536652, :title "Sampling (statistics)", :type :wiki-api.core/category} #{1031939 1257393 2864403}, 3233265 #{}, {:id 13651683, :title "Spectral clustering", :type :wiki-api.core/article} #{1042704 3700560}, {:id 30284, :title "Statistical hypothesis testing", :type :wiki-api.core/article} #{839752 27498}, 2870097 #{}, 1257393 #{}, {:id 1171513, :title "Neural networks", :type :wiki-api.core/category} #{584416 1032258 3525346 1031939 3307625}, 2864403 #{}, 2771 #{}, {:id 233497, :title "Unsupervised learning", :type :wiki-api.core/article} #{595744 1032835 1031939 832677 1065112 1031640 1032218 3061755}, 3679540 #{}, 1273172 #{}, 3490997 #{}, 600021 #{}, 3365845 #{}, {:id 1860407, :title "K-means clustering", :type :wiki-api.core/article} #{1009731 1009800 1219659 1042704 1031640 985178 985307 1044411}, {:id 694025, :title "Information theory", :type :wiki-api.core/category} #{595744 588737 597891 27498 1219659 1239162 985307}, {:id 3728109, :title "Variable (mathematics)", :type :wiki-api.core/article} #{1009731 1032835 2870097 1033911}, 346006 #{}, {:id 1587689, :title "Estimation theory", :type :wiki-api.core/category} #{594049 1033455 3677399}, 3677399 #{}, {:id 2225244, :title "Reliability engineering", :type :wiki-api.core/category} #{527448 2867423}, 1167799 #{}, {:id 14661466, :title "Outline of object recognition", :type :wiki-api.core/article} #{832677 907739}, {:id 973795, :title "Data compression", :type :wiki-api.core/category} #{1033911 985178}, 1033911 #{}, 570103 #{}, {:id 6030151, :title "Probability", :type :wiki-api.core/category} #{907739}, 527448 #{}, {:id 736442, :title "Real numbers", :type :wiki-api.core/category} #{1031235 597891 1009800 527435 1219659 939118 1167799 1031640 907739 1044411}, 1065112 #{}, 2867384 #{}, 3516632 #{}, {:id 467527, :title "Kullback–Leibler divergence", :type :wiki-api.core/article} #{939118 985178}, 3691896 #{}, 1031640 #{}, {:id 4890, :title "Bayesian probability", :type :wiki-api.core/article} #{1009800 3061755}, 3526009 #{}, {:id 31176997, :title "Support vector machines", :type :wiki-api.core/category} #{1031235 3394083 346006 1032218 984956}, 790361 #{}, 3346425 #{}, 1032218 #{}, 985178 #{}, 1239162 #{}, {:id 140806, :title "Maximum likelihood", :type :wiki-api.core/article} #{1219659 1031640}, {:id 341015, :title "Sparse matrix", :type :wiki-api.core/article} #{595744 939118}, {:id 13747309, :title "DBSCAN", :type :wiki-api.core/article} #{1033413 839752}, {:id 187926, :title "Centroid", :type :wiki-api.core/article} #{985178 1031101}, {:id 821165, :title "Categorical variable", :type :wiki-api.core/article} #{1033911 1239162}, 985307 #{}, 3483899 #{}, {:id 2905498, :title "Nearest-neighbor interpolation", :type :wiki-api.core/article} #{730336 907739}, 907739 #{}, 3620443 #{}, 3395323 #{}, 1044411 #{}, 3061755 #{}, {:id 255954, :title "DNA microarray", :type :wiki-api.core/article} #{1009800 1023181}, 984956 #{}, 3486588 #{}, {:id 245523, :title "Weight function", :type :wiki-api.core/article} #{3708230 3156815 1167799 1033911 527448 1044411}, {:id 1497569, :title "Consistent estimator", :type :wiki-api.core/article} #{839752 527435 2864403 907739 1044411}, 3548061 #{}, 1031101 #{}, {:id 9500290, :title "Experiments", :type :wiki-api.core/category} #{595744 1032258 1009731 839752 1009800 939118 1033455 2870097 1257393 600021 1167799 570103 527448 2867384 1239162 3620443 1113151 642207 2867423}, 3359998 #{}, {:id 26633572, :title "Approximations", :type :wiki-api.core/category} #{1023181 1113151}, 515774 #{}, 1009438 #{}, {:id 472877, :title "Prior probability", :type :wiki-api.core/article} #{1009731 1219659}, 1199966 #{}, 3065726 #{}, 3358654 #{}, {:id 22509799, :title "OPTICS algorithm", :type :wiki-api.core/article} #{597891 839752}, 1113151 #{}, 642207 #{}, 2867423 #{}, {:id 821148, :title "Level of measurement", :type :wiki-api.core/article} #{1031939 1033455 907739 984956}}}, :doc-map {730336 #search_api.search_api.Paper{:id 730336, :key "conf/icycs/Wang08", :title "A Subsystem Division Method by Clustering.", :abstract "State explosion problem is the primary obstacle to model complex system with Petri nets; modularization and hierarchy provide ways to solve this problem. When the bottom-up method is adopted, system functions in the lower layers are combined to obtain sub systems. The idea of clustering is introduced to decide which functions should be combined. The operation to combine two functions is defined; the distance between two functions is calculated by the degree of relevancy; a clustering algorithm with the idea of nearest-neighbor-first is designed to divide functions into sub systems. The function clustering method presented in this paper facilitates the Petri nets based system developing process.", :author (#search_api.search_api.Author{:id 451015, :first-name nil, :last-name nil, :full-name "Zhijian Wang"}), :year 2008, :venue "ICYCS", :ncit 0, :string "A Subsystem Division Method by Clustering.. State explosion problem is the primary obstacle to model complex system with Petri nets; modularization and hierarchy provide ways to solve this problem. When the bottom-up method is adopted, system functions in the lower layers are combined to obtain sub systems. The idea of clustering is introduced to decide which functions should be combined. The operation to combine two functions is defined; the distance between two functions is calculated by the degree of relevancy; a clustering algorithm with the idea of nearest-neighbor-first is designed to divide functions into sub systems. The function clustering method presented in this paper facilitates the Petri nets based system developing process.", :doc-id "A Subsystem Division Method by Clustering. 2008  "}, 3500384 #search_api.search_api.Paper{:id 3500384, :key "conf/wcnc/ZhaoL12", :title "Clustering methods for base station cooperation.", :abstract nil, :author (#search_api.search_api.Author{:id 161969, :first-name nil, :last-name nil, :full-name "Jian Zhao"} #search_api.search_api.Author{:id 1336465, :first-name nil, :last-name nil, :full-name "Zhongding Lei"}), :year 2012, :venue "WCNC", :ncit 3, :string "Clustering methods for base station cooperation.. ", :doc-id "Clustering methods for base station cooperation. 2012  ,  "}, 3663520 #search_api.search_api.Paper{:id 3663520, :key "conf/icpr/FausserS12", :title "Clustering large datasets with kernel methods.", :abstract nil, :author (#search_api.search_api.Author{:id 1557097, :first-name nil, :last-name nil, :full-name "Stefan Faußer"} #search_api.search_api.Author{:id 104411, :first-name nil, :last-name nil, :full-name "Friedhelm Schwenker"}), :year 2012, :venue "ICPR", :ncit 0, :string "Clustering large datasets with kernel methods.. ", :doc-id "Clustering large datasets with kernel methods. 2012  ,  "}, 584416 #search_api.search_api.Paper{:id 584416, :key "conf/sensys/JindalP04", :title "A clustering method that uses lossy aggregation of data.", :abstract "Wireless sensor networks are characterized by dense deployment of sensor nodes which collectively communicate sensed data to the sink. However, due to the spatial correlation between sensor observations, it is not necessary for every node to transmit its data. We propose a clustering method which exploits the above observation. We do not make any assumption on the nature of data, and hence the algorithm will be valid for a broad range of conditions. The paper shows how to calculate the optimal cluster size. We also discuss the structure of the complete architecture which is still under development.", :author (#search_api.search_api.Author{:id 483438, :first-name nil, :last-name nil, :full-name "Apoorva Jindal"} #search_api.search_api.Author{:id 312507, :first-name nil, :last-name nil, :full-name "Konstantinos Psounis"}), :year 2004, :venue "SenSys", :ncit 5, :string "A clustering method that uses lossy aggregation of data.. Wireless sensor networks are characterized by dense deployment of sensor nodes which collectively communicate sensed data to the sink. However, due to the spatial correlation between sensor observations, it is not necessary for every node to transmit its data. We propose a clustering method which exploits the above observation. We do not make any assumption on the nature of data, and hence the algorithm will be valid for a broad range of conditions. The paper shows how to calculate the optimal cluster size. We also discuss the structure of the complete architecture which is still under development.", :doc-id "A clustering method that uses lossy aggregation of data. 2004  ,  "}, 595744 #search_api.search_api.Paper{:id 595744, :key "conf/sigir/SlonimT00", :title "Document clustering using word clusters via the information bottleneck method.", :abstract "We present a novel implementation of the recently introduced information bottleneck method for unsupervised document clustering. Given a joint empirical distribution of words and documents, p(x, y), we first cluster the words, Y, so that the obtained word clusters, Ytilde;, maximally preserve the information on the documents. The resulting joint distribution. p(X, Ytilde;), contains most of the original information about the documents, I(X; Ytilde;) &ap; I(X; Y), but it is much less sparse and noisy. Using the same procedure we then cluster the documents, X, so that the information about the word-clusters is preserved. Thus, we first find word-clusters that capture most of the mutual information about to set of documents, and then find document clusters, that preserve the information about the word clusters. We tested this procedure over several document collections based on subsets taken from the standard 20Newsgroups corpus. The results were assessed by calculating the correlation between the document clusters and the correct labels for these documents. Finding from our experiments show that this double clustering procedure, which uses the information bottleneck method, yields significantly superior performance compared to other common document distributional clustering algorithms. Moreover, the double clustering procedure improves all the distributional clustering methods examined here.", :author (#search_api.search_api.Author{:id 27645, :first-name nil, :last-name nil, :full-name "Noam Slonim"} #search_api.search_api.Author{:id 1164135, :first-name nil, :last-name nil, :full-name "Naftali Tishby"}), :year 2000, :venue "SIGIR", :ncit 364, :string "Document clustering using word clusters via the information bottleneck method.. We present a novel implementation of the recently introduced information bottleneck method for unsupervised document clustering. Given a joint empirical distribution of words and documents, p(x, y), we first cluster the words, Y, so that the obtained word clusters, Ytilde;, maximally preserve the information on the documents. The resulting joint distribution. p(X, Ytilde;), contains most of the original information about the documents, I(X; Ytilde;) &ap; I(X; Y), but it is much less sparse and noisy. Using the same procedure we then cluster the documents, X, so that the information about the word-clusters is preserved. Thus, we first find word-clusters that capture most of the mutual information about to set of documents, and then find document clusters, that preserve the information about the word clusters. We tested this procedure over several document collections based on subsets taken from the standard 20Newsgroups corpus. The results were assessed by calculating the correlation between the document clusters and the correct labels for these documents. Finding from our experiments show that this double clustering procedure, which uses the information bottleneck method, yields significantly superior performance compared to other common document distributional clustering algorithms. Moreover, the double clustering procedure improves all the distributional clustering methods examined here.", :doc-id "Document clustering using word clusters via the information bottleneck method. 2000  ,  "}, 3078048 #search_api.search_api.Paper{:id 3078048, :key "journals/pr/TanTT11", :title "A general stochastic clustering method for automatic cluster discovery.", :abstract nil, :author (#search_api.search_api.Author{:id 270660, :first-name nil, :last-name nil, :full-name "Swee Chuan Tan"} #search_api.search_api.Author{:id 556784, :first-name nil, :last-name nil, :full-name "Kai Ming Ting"} #search_api.search_api.Author{:id 867619, :first-name nil, :last-name nil, :full-name "Shyh Wei Teng"}), :year 2011, :venue "Pattern Recognition", :ncit 2, :string "A general stochastic clustering method for automatic cluster discovery.. ", :doc-id "A general stochastic clustering method for automatic cluster discovery. 2011  ,  ,  "}, 594049 #search_api.search_api.Paper{:id 594049, :key "conf/siggraph/SmitsAG94", :title "A clustering algorithm for radiosity in complex environments.", :abstract "We present an approach for accelerating hierarchical radiosity by clustering objects. Previous approaches constructed effective hierarchies by subdividing surfaces, but could not exploit a hierarchical grouping on existing surfaces. This limitation resulted in an excessive number of initial links in complex environments. Initial linking is potentially the most expensive portion of hierarchical radiosity algorithms, and constrains the complexity of the environments that can be simulated. The clustering algorithm presented here operates by estimating energy transfer between collections of objects while maintaining reliable error bounds on each transfer. Two methods of bounding the transfers are employed with different tradeoffs between accuracy and time. In contrast with the O(s2) time and space complexity of the initial linking in previous hierarchical radiosity algorithms, the new methods have complexities of O(slogs) and O(s) for both time and space. Using these methods we have obtained speedups of two orders of magnitude for environments of moderate complexity while maintaining comparable accuracy.", :author (#search_api.search_api.Author{:id 703081, :first-name nil, :last-name nil, :full-name "Brian E. Smits"} #search_api.search_api.Author{:id 365508, :first-name nil, :last-name nil, :full-name "James Arvo"} #search_api.search_api.Author{:id 1021389, :first-name nil, :last-name nil, :full-name "Donald P. Greenberg"}), :year 1994, :venue "SIGGRAPH", :ncit 238, :string "A clustering algorithm for radiosity in complex environments.. We present an approach for accelerating hierarchical radiosity by clustering objects. Previous approaches constructed effective hierarchies by subdividing surfaces, but could not exploit a hierarchical grouping on existing surfaces. This limitation resulted in an excessive number of initial links in complex environments. Initial linking is potentially the most expensive portion of hierarchical radiosity algorithms, and constrains the complexity of the environments that can be simulated. The clustering algorithm presented here operates by estimating energy transfer between collections of objects while maintaining reliable error bounds on each transfer. Two methods of bounding the transfers are employed with different tradeoffs between accuracy and time. In contrast with the O(s2) time and space complexity of the initial linking in previous hierarchical radiosity algorithms, the new methods have complexities of O(slogs) and O(s) for both time and space. Using these methods we have obtained speedups of two orders of magnitude for environments of moderate complexity while maintaining comparable accuracy.", :doc-id "A clustering algorithm for radiosity in complex environments. 1994  ,  ,  "}, 3736161 #search_api.search_api.Paper{:id 3736161, :key "journals/icae/RizziDC13", :title "A supervised method for microcalcification cluster diagnosis.", :abstract nil, :author (#search_api.search_api.Author{:id 958997, :first-name nil, :last-name nil, :full-name "Maria Rizzi"} #search_api.search_api.Author{:id 942058, :first-name nil, :last-name nil, :full-name "Matteo D'Aloia"} #search_api.search_api.Author{:id 831411, :first-name nil, :last-name nil, :full-name "Beniamino Castagnolo"}), :year 2013, :venue "Integrated Computer-Aided Engineering", :ncit 0, :string "A supervised method for microcalcification cluster diagnosis.. ", :doc-id "A supervised method for microcalcification cluster diagnosis. 2013  ,  ,  "}, 588737 #search_api.search_api.Paper{:id 588737, :key "conf/sigcomm/KrishnamurthyW00", :title "On network-aware clustering of web clients.", :abstract "Being able to identify the groups of clients that are responsible for a significant portion of a Web site's requests can be helpful to both the Web site and the clients. In a Web application, it is beneficial to move content closer to groups of clients that are responsible for large subsets of requests to an origin server. We introduce clusters---a grouping of clients that are close together topologically and likely to be under common administrative control. We identify clusters using a ``network-aware\" method, based on information available from BGP routing table snapshots.", :author (#search_api.search_api.Author{:id 297285, :first-name nil, :last-name nil, :full-name "Balachander Krishnamurthy"} #search_api.search_api.Author{:id 128598, :first-name nil, :last-name nil, :full-name "Jia Wang"}), :year 2000, :venue "SIGCOMM", :ncit 397, :string "On network-aware clustering of web clients.. Being able to identify the groups of clients that are responsible for a significant portion of a Web site's requests can be helpful to both the Web site and the clients. In a Web application, it is beneficial to move content closer to groups of clients that are responsible for large subsets of requests to an origin server. We introduce clusters---a grouping of clients that are close together topologically and likely to be under common administrative control. We identify clusters using a ``network-aware\" method, based on information available from BGP routing table snapshots.", :doc-id "On network-aware clustering of web clients. 2000  ,  "}, 1032258 #search_api.search_api.Paper{:id 1032258, :key "journals/pami/LiT01", :title "Hybrid Evolutionary Search Method Based on Clusters.", :abstract "This paper presents a hybrid evolutionary search method based on clusters (HESC). The method is specifically designed to enhance the search efficiency while alleviating the problem of premature convergence inherent in standard evolutionary search methods (SES). It involves the simultaneous evolution of a main species and an additional fast mutating species. A hybrid search method which includes a local parallel single agent search and a global multiagent evolutionary search is carried out for the main species. Effective utilization of the search history is achieved with the clustering and training of a fuzzy ART neural network (ART NN) during the search. The advantages of HESC include 1) guaranteed population diversity at each generation, 2) effective integration of local search for the exploitation of important regions and the global search for the exploration of the entire space, and 3) fast exploration ability of the fast mutating species and migration from the additional species to the main species. Those advantages have been confirmed with experiments in which hard optimization problems were successfully solved with HESC.", :author (#search_api.search_api.Author{:id 403809, :first-name nil, :last-name nil, :full-name "Ming Li"} #search_api.search_api.Author{:id 155750, :first-name nil, :last-name nil, :full-name "Hon-Yuen Tam"}), :year 2001, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 20, :string "Hybrid Evolutionary Search Method Based on Clusters.. This paper presents a hybrid evolutionary search method based on clusters (HESC). The method is specifically designed to enhance the search efficiency while alleviating the problem of premature convergence inherent in standard evolutionary search methods (SES). It involves the simultaneous evolution of a main species and an additional fast mutating species. A hybrid search method which includes a local parallel single agent search and a global multiagent evolutionary search is carried out for the main species. Effective utilization of the search history is achieved with the clustering and training of a fuzzy ART neural network (ART NN) during the search. The advantages of HESC include 1) guaranteed population diversity at each generation, 2) effective integration of local search for the exploitation of important regions and the global search for the exploration of the entire space, and 3) fast exploration ability of the fast mutating species and migration from the additional species to the main species. Those advantages have been confirmed with experiments in which hard optimization problems were successfully solved with HESC.", :doc-id "Hybrid Evolutionary Search Method Based on Clusters. 2001  ,  "}, 3023522 #search_api.search_api.Paper{:id 3023522, :key "conf/ismis/PatraN11", :title "Neighborhood Based Clustering Method for Arbitrary Shaped Clusters.", :abstract nil, :author (#search_api.search_api.Author{:id 398488, :first-name nil, :last-name nil, :full-name "Bidyut Kr. Patra"} #search_api.search_api.Author{:id 1122902, :first-name nil, :last-name nil, :full-name "Sukumar Nandi"}), :year 2011, :venue "ISMIS", :ncit 0, :string "Neighborhood Based Clustering Method for Arbitrary Shaped Clusters.. ", :doc-id "Neighborhood Based Clustering Method for Arbitrary Shaped Clusters. 2011  ,  "}, 3525346 #search_api.search_api.Paper{:id 3525346, :key "conf/iscc/FouchalMMMI12", :title "A clustering method for wireless sensors networks.", :abstract nil, :author (#search_api.search_api.Author{:id 1611754, :first-name nil, :last-name nil, :full-name "Said Fouchal"} #search_api.search_api.Author{:id 14338268, :first-name nil, :last-name nil, :full-name "Quentin Monnet"} #search_api.search_api.Author{:id 14338269, :first-name nil, :last-name nil, :full-name "Djamel Mansouri"} #search_api.search_api.Author{:id 1038917, :first-name nil, :last-name nil, :full-name "Lynda Mokdad"} #search_api.search_api.Author{:id 794036, :first-name nil, :last-name nil, :full-name "Malika Ioualalen"}), :year 2012, :venue "ISCC", :ncit 0, :string "A clustering method for wireless sensors networks.. ", :doc-id "A clustering method for wireless sensors networks. 2012  ,  ,  ,  ,  "}, 1031235 #search_api.search_api.Paper{:id 1031235, :key "journals/pami/CamastraV05", :title "A Novel Kernel Method for Clustering.", :abstract "Kernel Methods are algorithms that, by replacing the inner product with an appropriate positive definite function, implicitly perform a nonlinear mapping of the input data into a high-dimensional feature space. In this paper, we present a kernel method for clustering inspired by the classical K-Means algorithm in which each cluster is iteratively refined using a one-class Support Vector Machine. Our method, which can be easily implemented, compares favorably with respect to popular clustering algorithms, like K-Means, Neural Gas, and Self-Organizing Maps, on a synthetic data set and three UCI real data benchmarks (IRIS data, Wisconsin breast cancer database, Spam database).", :author (#search_api.search_api.Author{:id 662277, :first-name nil, :last-name nil, :full-name "Francesco Camastra"} #search_api.search_api.Author{:id 601093, :first-name nil, :last-name nil, :full-name "Alessandro Verri"}), :year 2005, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 223, :string "A Novel Kernel Method for Clustering.. Kernel Methods are algorithms that, by replacing the inner product with an appropriate positive definite function, implicitly perform a nonlinear mapping of the input data into a high-dimensional feature space. In this paper, we present a kernel method for clustering inspired by the classical K-Means algorithm in which each cluster is iteratively refined using a one-class Support Vector Machine. Our method, which can be easily implemented, compares favorably with respect to popular clustering algorithms, like K-Means, Neural Gas, and Self-Organizing Maps, on a synthetic data set and three UCI real data benchmarks (IRIS data, Wisconsin breast cancer database, Spam database).", :doc-id "A Novel Kernel Method for Clustering. 2005  ,  "}, 1009731 #search_api.search_api.Paper{:id 1009731, :key "journals/ml/MeilaH01", :title "An Experimental Comparison of Model-Based Clustering Methods.", :abstract "We compare the three basic algorithms for model-based clustering on high-dimensional discrete-variable datasets. All three algorithms use the same underlying model: a naive-Bayes model with a hidden root node, also known as a multinomial-mixture model. In the first part of the paper, we perform an experimental comparison between three batch algorithms that learn the parameters of this model: the Expectation&ndash;Maximization (EM) algorithm, a &ldquo;winner take all&rdquo; version of the EM algorithm reminiscent of the K-means algorithm, and model-based agglomerative clustering. We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization methods on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of agglomerative clustering. Although the methods are substantially different, they lead to learned models that are similar in quality.", :author (#search_api.search_api.Author{:id 564967, :first-name nil, :last-name nil, :full-name "Marina Meila"} #search_api.search_api.Author{:id 114083, :first-name nil, :last-name nil, :full-name "David Heckerman"}), :year 2001, :venue "Machine Learning", :ncit 145, :string "An Experimental Comparison of Model-Based Clustering Methods.. We compare the three basic algorithms for model-based clustering on high-dimensional discrete-variable datasets. All three algorithms use the same underlying model: a naive-Bayes model with a hidden root node, also known as a multinomial-mixture model. In the first part of the paper, we perform an experimental comparison between three batch algorithms that learn the parameters of this model: the Expectation&ndash;Maximization (EM) algorithm, a &ldquo;winner take all&rdquo; version of the EM algorithm reminiscent of the K-means algorithm, and model-based agglomerative clustering. We find that the EM algorithm significantly outperforms the other methods, and proceed to investigate the effect of various initialization methods on the final solution produced by the EM algorithm. The initializations that we consider are (1) parameters sampled from an uninformative prior, (2) random perturbations of the marginal distribution of the data, and (3) the output of agglomerative clustering. Although the methods are substantially different, they lead to learned models that are similar in quality.", :doc-id "An Experimental Comparison of Model-Based Clustering Methods. 2001  ,  "}, 3394083 #search_api.search_api.Paper{:id 3394083, :key "journals/jcst/PingTZY12", :title "Convex Decomposition Based Cluster Labeling Method for Support Vector Clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 1347038, :first-name nil, :last-name nil, :full-name "Yuan Ping"} #search_api.search_api.Author{:id 16774, :first-name nil, :last-name nil, :full-name "Ying-Jie Tian"} #search_api.search_api.Author{:id 14276041, :first-name nil, :last-name nil, :full-name "Ya-Jian Zhou"} #search_api.search_api.Author{:id 165956, :first-name nil, :last-name nil, :full-name "Yi-Xian Yang"}), :year 2012, :venue "J. Comput. Sci. Technol.", :ncit 1, :string "Convex Decomposition Based Cluster Labeling Method for Support Vector Clustering.. ", :doc-id "Convex Decomposition Based Cluster Labeling Method for Support Vector Clustering. 2012  ,  ,  ,  "}, 3060291 #search_api.search_api.Paper{:id 3060291, :key "journals/acta/KabirWB11", :title "Efficient systematic clustering method for -anonymization.", :abstract nil, :author (#search_api.search_api.Author{:id 612341, :first-name nil, :last-name nil, :full-name "Md. Enamul Kabir"} #search_api.search_api.Author{:id 592843, :first-name nil, :last-name nil, :full-name "Hua Wang"} #search_api.search_api.Author{:id 130348, :first-name nil, :last-name nil, :full-name "Elisa Bertino"}), :year 2011, :venue "Acta Inf.", :ncit 3, :string "Efficient systematic clustering method for -anonymization.. ", :doc-id "Efficient systematic clustering method for -anonymization. 2011  ,  ,  "}, 1032835 #search_api.search_api.Paper{:id 1032835, :key "journals/pami/RoseGF93", :title "Constrained Clustering as an Optimization Method.", :abstract "A deterministic annealing approach to clustering is derived on the basis of the principle of maximum entropy. This approach is independent of the initial state and produces natural hierarchical clustering solutions by going through a sequence of phase transitions. It is modified for a larger class of optimization problems by adding constraints to the free energy. The concept of constrained clustering is explained, and three examples are are given in which it is used to introduce deterministic annealing. The previous clustering method is improved by adding cluster mass variables and a total mass constraint. The traveling salesman problem is reformulated as constrained clustering, yielding the elastic net (EN) approach to the problem. More insight is gained by identifying a second Lagrange multiplier that is related to the tour length and can also be used to control the annealing process. The open path constraint formulation is shown to relate to dimensionality reduction by self-organization in unsupervised learning. A similar annealing procedure is applicable in this case as well.", :author (#search_api.search_api.Author{:id 644746, :first-name nil, :last-name nil, :full-name "Kenneth Rose"} #search_api.search_api.Author{:id 189455, :first-name nil, :last-name nil, :full-name "Eitan Gurewitz"} #search_api.search_api.Author{:id 851606, :first-name nil, :last-name nil, :full-name "Geoffrey Fox"}), :year 1993, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 161, :string "Constrained Clustering as an Optimization Method.. A deterministic annealing approach to clustering is derived on the basis of the principle of maximum entropy. This approach is independent of the initial state and produces natural hierarchical clustering solutions by going through a sequence of phase transitions. It is modified for a larger class of optimization problems by adding constraints to the free energy. The concept of constrained clustering is explained, and three examples are are given in which it is used to introduce deterministic annealing. The previous clustering method is improved by adding cluster mass variables and a total mass constraint. The traveling salesman problem is reformulated as constrained clustering, yielding the elastic net (EN) approach to the problem. More insight is gained by identifying a second Lagrange multiplier that is related to the tour length and can also be used to control the annealing process. The open path constraint formulation is shown to relate to dimensionality reduction by self-organization in unsupervised learning. A similar annealing procedure is applicable in this case as well.", :doc-id "Constrained Clustering as an Optimization Method. 1993  ,  ,  "}, 1031939 #search_api.search_api.Paper{:id 1031939, :key "journals/pami/JainDM00", :title "Statistical Pattern Recognition: A Review.", :abstract "The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.", :author (#search_api.search_api.Author{:id 324696, :first-name nil, :last-name nil, :full-name "Anil K. Jain"} #search_api.search_api.Author{:id 189517, :first-name nil, :last-name nil, :full-name "Robert P. W. Duin"} #search_api.search_api.Author{:id 447337, :first-name nil, :last-name nil, :full-name "Jianchang Mao"}), :year 2000, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 4345, :string "Statistical Pattern Recognition: A Review.. The primary goal of pattern recognition is supervised or unsupervised classification. Among the various frameworks in which pattern recognition has been traditionally formulated, the statistical approach has been most intensively studied and used in practice. More recently, neural network techniques and methods imported from statistical learning theory have been receiving increasing attention. The design of a recognition system requires careful attention to the following issues: definition of pattern classes, sensing environment, pattern representation, feature extraction and selection, cluster analysis, classifier design and learning, selection of training and test samples, and performance evaluation. In spite of almost 50 years of research and development in this field, the general problem of recognizing complex patterns with arbitrary orientation, location, and scale remains unsolved. New and emerging applications, such as data mining, web searching, retrieval of multimedia data, face recognition, and cursive handwriting recognition, require robust and efficient pattern recognition techniques. The objective of this review paper is to summarize and compare some of the well-known methods used in various stages of a pattern recognition system and identify research topics and applications which are at the forefront of this exciting and challenging field.", :doc-id "Statistical Pattern Recognition: A Review. 2000  ,  ,  "}, 597891 #search_api.search_api.Paper{:id 597891, :key "conf/sigmod/AnkerstBKS99", :title "OPTICS: Ordering Points To Identify the Clustering Structure.", :abstract "Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only 'traditional' clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.", :author (#search_api.search_api.Author{:id 762749, :first-name nil, :last-name nil, :full-name "Mihael Ankerst"} #search_api.search_api.Author{:id 899900, :first-name nil, :last-name nil, :full-name "Markus M. Breunig"} #search_api.search_api.Author{:id 228306, :first-name nil, :last-name nil, :full-name "Hans-Peter Kriegel"} #search_api.search_api.Author{:id 940742, :first-name nil, :last-name nil, :full-name "Jörg Sander"}), :year 1999, :venue "SIGMOD Conference", :ncit 1541, :string "OPTICS: Ordering Points To Identify the Clustering Structure.. Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only 'traditional' clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.", :doc-id "OPTICS: Ordering Points To Identify the Clustering Structure. 1999  ,  ,  ,  "}, 985059 #search_api.search_api.Paper{:id 985059, :key "journals/jmlr/MarxDBS02", :title "Coupled Clustering: A Method for Detecting Structural Correspondence.", :abstract "This paper proposes a new paradigm and a computational framework for revealing equivalencies (analogies) between sub-structures of distinct composite systems that are initially represented by unstructured data sets. For this purpose, we introduce and investigate a variant of traditional data clustering, termed coupled clustering, which outputs a configuration of corresponding subsets of two such representative sets. We apply our method to synthetic as well as textual data. Its achievements in detecting topical correspondences between textual corpora are evaluated through comparison to performance of human experts.", :author (#search_api.search_api.Author{:id 793220, :first-name nil, :last-name nil, :full-name "Zvika Marx"} #search_api.search_api.Author{:id 135545, :first-name nil, :last-name nil, :full-name "Ido Dagan"} #search_api.search_api.Author{:id 1122223, :first-name nil, :last-name nil, :full-name "Joachim M. Buhmann"} #search_api.search_api.Author{:id 1191060, :first-name nil, :last-name nil, :full-name "Eli Shamir"}), :year 2002, :venue "Journal of Machine Learning Research", :ncit 41, :string "Coupled Clustering: A Method for Detecting Structural Correspondence.. This paper proposes a new paradigm and a computational framework for revealing equivalencies (analogies) between sub-structures of distinct composite systems that are initially represented by unstructured data sets. For this purpose, we introduce and investigate a variant of traditional data clustering, termed coupled clustering, which outputs a configuration of corresponding subsets of two such representative sets. We apply our method to synthetic as well as textual data. Its achievements in detecting topical correspondences between textual corpora are evaluated through comparison to performance of human experts.", :doc-id "Coupled Clustering: A Method for Detecting Structural Correspondence. 2002  ,  ,  ,  "}, 3471908 #search_api.search_api.Paper{:id 3471908, :key "journals/corr/abs-1207-4155", :title "Similarity-Driven Cluster Merging Method for Unsupervised Fuzzy Clustering", :abstract nil, :author (#search_api.search_api.Author{:id 191238, :first-name nil, :last-name nil, :full-name "Xuejian Xiong"} #search_api.search_api.Author{:id 327772, :first-name nil, :last-name nil, :full-name "Kap Luk Chan"} #search_api.search_api.Author{:id 773951, :first-name nil, :last-name nil, :full-name "Kian-Lee Tan"}), :year 2012, :venue "CoRR", :ncit 18, :string "Similarity-Driven Cluster Merging Method for Unsupervised Fuzzy Clustering. ", :doc-id "Similarity-Driven Cluster Merging Method for Unsupervised Fuzzy Clustering 2012  ,  ,  "}, 832677 #search_api.search_api.Paper{:id 832677, :key "journals/csur/JainMF99", :title "Data Clustering: A Review.", :abstract "Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.", :author (#search_api.search_api.Author{:id 324696, :first-name nil, :last-name nil, :full-name "Anil K. Jain"} #search_api.search_api.Author{:id 1191133, :first-name nil, :last-name nil, :full-name "M. Narasimha Murty"} #search_api.search_api.Author{:id 186342, :first-name nil, :last-name nil, :full-name "Patrick J. Flynn"}), :year 1999, :venue "ACM Comput. Surv.", :ncit 8116, :string "Data Clustering: A Review.. Clustering is the unsupervised classification of patterns (observations, data items, or feature vectors) into groups (clusters). The clustering problem has been addressed in many contexts and by researchers in many disciplines; this reflects its broad appeal and usefulness as one of the steps in exploratory data analysis. However, clustering is a difficult problem combinatorially, and differences in assumptions and contexts in different communities has made the transfer of useful generic concepts and methodologies slow to occur. This paper presents an overview of pattern clustering methods from a statistical pattern recognition perspective, with a goal of providing useful advice and references to fundamental concepts accessible to the broad community of clustering practitioners. We present a taxonomy of clustering techniques, and identify cross-cutting themes and recent advances. We also describe some important applications of clustering algorithms such as image segmentation, object recognition, and information retrieval.", :doc-id "Data Clustering: A Review. 1999  ,  ,  "}, 1033413 #search_api.search_api.Paper{:id 1033413, :key "journals/pami/YipDC06", :title "Dynamic Cluster Formation Using Level Set Methods.", :abstract "Density-based clustering has the advantages for 1) allowing arbitrary shape of cluster and 2) not requiring the number of clusters as input. However, when clusters touch each other, both the cluster centers and cluster boundaries (as the peaks and valleys of the density distribution) become fuzzy and difficult to determine. We introduce the notion of cluster intensity function (CIF) which captures the important characteristics of clusters. When clusters are well-separated, CIFs are similar to density functions. But, when clusters become closed to each other, CIFs still clearly reveal cluster centers, cluster boundaries, and degree of membership of each data point to the cluster that it belongs. Clustering through bump hunting and valley seeking based on these functions are more robust than that based on density functions obtained by kernel density estimation, which are often oscillatory or oversmoothed. These problems of kernel density estimation are resolved using Level Set Methods and related techniques. Comparisons with two existing density-based methods, valley seeking and DBSCAN, are presented which illustrate the advantages of our approach.", :author (#search_api.search_api.Author{:id 457109, :first-name nil, :last-name nil, :full-name "Andy M. Yip"} #search_api.search_api.Author{:id 54204, :first-name nil, :last-name nil, :full-name "Chris H. Q. Ding"} #search_api.search_api.Author{:id 246588, :first-name nil, :last-name nil, :full-name "Tony F. Chan"}), :year 2006, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 43, :string "Dynamic Cluster Formation Using Level Set Methods.. Density-based clustering has the advantages for 1) allowing arbitrary shape of cluster and 2) not requiring the number of clusters as input. However, when clusters touch each other, both the cluster centers and cluster boundaries (as the peaks and valleys of the density distribution) become fuzzy and difficult to determine. We introduce the notion of cluster intensity function (CIF) which captures the important characteristics of clusters. When clusters are well-separated, CIFs are similar to density functions. But, when clusters become closed to each other, CIFs still clearly reveal cluster centers, cluster boundaries, and degree of membership of each data point to the cluster that it belongs. Clustering through bump hunting and valley seeking based on these functions are more robust than that based on density functions obtained by kernel density estimation, which are often oscillatory or oversmoothed. These problems of kernel density estimation are resolved using Level Set Methods and related techniques. Comparisons with two existing density-based methods, valley seeking and DBSCAN, are presented which illustrate the advantages of our approach.", :doc-id "Dynamic Cluster Formation Using Level Set Methods. 2006  ,  ,  "}, 1297381 #search_api.search_api.Paper{:id 1297381, :key "reference/db/Li09d", :title "Database Clustering Methods.", :abstract nil, :author (#search_api.search_api.Author{:id 1316116, :first-name nil, :last-name nil, :full-name "Xue Li"}), :year 2009, :venue "Encyclopedia of Database Systems", :ncit 0, :string "Database Clustering Methods.. ", :doc-id "Database Clustering Methods. 2009  "}, 3509574 #search_api.search_api.Paper{:id 3509574, :key "conf/c3s2e/HossainBWH12", :title "An effective ensemble method for hierarchical clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 283398, :first-name nil, :last-name nil, :full-name "Mahmood Hossain"} #search_api.search_api.Author{:id 769857, :first-name nil, :last-name nil, :full-name "Susan M. Bridges"} #search_api.search_api.Author{:id 28232, :first-name nil, :last-name nil, :full-name "Yong Wang"} #search_api.search_api.Author{:id 471152, :first-name nil, :last-name nil, :full-name "Julia E. Hodges"}), :year 2012, :venue "C3S2E", :ncit 0, :string "An effective ensemble method for hierarchical clustering.. ", :doc-id "An effective ensemble method for hierarchical clustering. 2012  ,  ,  ,  "}, 3708230 #search_api.search_api.Paper{:id 3708230, :key "journals/jnw/WangZLWY13", :title "An Attribute-weighted Clustering Intrusion Detection Method.", :abstract nil, :author (#search_api.search_api.Author{:id 522856, :first-name nil, :last-name nil, :full-name "Lifang Wang"} #search_api.search_api.Author{:id 962291, :first-name nil, :last-name nil, :full-name "Shuhai Zhang"} #search_api.search_api.Author{:id 1145207, :first-name nil, :last-name nil, :full-name "Yurong Li"} #search_api.search_api.Author{:id 991435, :first-name nil, :last-name nil, :full-name "Ruijuan Wu"} #search_api.search_api.Author{:id 351984, :first-name nil, :last-name nil, :full-name "Yi Yu"}), :year 2013, :venue "JNW", :ncit 0, :string "An Attribute-weighted Clustering Intrusion Detection Method.. ", :doc-id "An Attribute-weighted Clustering Intrusion Detection Method. 2013  ,  ,  ,  ,  "}, 839752 #search_api.search_api.Paper{:id 839752, :key "journals/datamine/PeiJHZZ09", :title "DECODE: a new method for discovering clusters of different densities in spatial data.", :abstract "When clusters with different densities and noise lie in a spatial point set, the major obstacle to classifying these data is the determination of the thresholds for classification, which may form a series of bins for allocating each point to different clusters. Much of the previous work has adopted a model-based approach, but is either incapable of estimating the thresholds in an automatic way, or limited to only two point processes, i.e. noise and clusters with the same density. In this paper, we present a new density-based cluster method (DECODE), in which a spatial data set is presumed to consist of different point processes and clusters with different densities belong to different point processes. DECODE is based upon a reversible jump Markov Chain Monte Carlo (MCMC) strategy and divided into three steps. The first step is to map each point in the data to its mth nearest distance, which is referred to as the distance between a point and its mth nearest neighbor. In the second step, classification thresholds are determined via a reversible jump MCMC strategy. In the third step, clusters are formed by spatially connecting the points whose mth nearest distances fall into a particular bin defined by the thresholds. Four experiments, including two simulated data sets and two seismic data sets, are used to evaluate the algorithm. Results on simulated data show that our approach is capable of discovering the clusters automatically. Results on seismic data suggest that the clustered earthquakes, identified by DECODE, either imply the epicenters of forthcoming strong earthquakes or indicate the areas with the most intensive seismicity, this is consistent with the tectonic states and estimated stress distribution in the associated areas. The comparison between DECODE and other state-of-the-art methods, such as DBSCAN, OPTICS and Wavelet Cluster, illustrates the contribution of our approach: although DECODE can be computationally expensive, it is capable of identifying the number of point processes and simultaneously estimating the classification thresholds with little prior knowledge.", :author (#search_api.search_api.Author{:id 17009, :first-name nil, :last-name nil, :full-name "Tao Pei"} #search_api.search_api.Author{:id 444275, :first-name nil, :last-name nil, :full-name "Ajay Jasra"} #search_api.search_api.Author{:id 882980, :first-name nil, :last-name nil, :full-name "David J. Hand"} #search_api.search_api.Author{:id 1195063, :first-name nil, :last-name nil, :full-name "A-Xing Zhu"} #search_api.search_api.Author{:id 58862, :first-name nil, :last-name nil, :full-name "Chenghu Zhou"}), :year 2009, :venue "Data Min. Knowl. Discov.", :ncit 13, :string "DECODE: a new method for discovering clusters of different densities in spatial data.. When clusters with different densities and noise lie in a spatial point set, the major obstacle to classifying these data is the determination of the thresholds for classification, which may form a series of bins for allocating each point to different clusters. Much of the previous work has adopted a model-based approach, but is either incapable of estimating the thresholds in an automatic way, or limited to only two point processes, i.e. noise and clusters with the same density. In this paper, we present a new density-based cluster method (DECODE), in which a spatial data set is presumed to consist of different point processes and clusters with different densities belong to different point processes. DECODE is based upon a reversible jump Markov Chain Monte Carlo (MCMC) strategy and divided into three steps. The first step is to map each point in the data to its mth nearest distance, which is referred to as the distance between a point and its mth nearest neighbor. In the second step, classification thresholds are determined via a reversible jump MCMC strategy. In the third step, clusters are formed by spatially connecting the points whose mth nearest distances fall into a particular bin defined by the thresholds. Four experiments, including two simulated data sets and two seismic data sets, are used to evaluate the algorithm. Results on simulated data show that our approach is capable of discovering the clusters automatically. Results on seismic data suggest that the clustered earthquakes, identified by DECODE, either imply the epicenters of forthcoming strong earthquakes or indicate the areas with the most intensive seismicity, this is consistent with the tectonic states and estimated stress distribution in the associated areas. The comparison between DECODE and other state-of-the-art methods, such as DBSCAN, OPTICS and Wavelet Cluster, illustrates the contribution of our approach: although DECODE can be computationally expensive, it is capable of identifying the number of point processes and simultaneously estimating the classification thresholds with little prior knowledge.", :doc-id "DECODE: a new method for discovering clusters of different densities in spatial data. 2009  ,  ,  ,  ,  "}, 1009800 #search_api.search_api.Paper{:id 1009800, :key "journals/ml/MontiTMG03", :title "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data.", :abstract "In this paper we present a new methodology of class discovery and clustering validation tailored to the task of analyzing gene expression data. The method can best be thought of as an analysis approach, to guide and assist in the use of any of a wide range of available clustering algorithms. We call the new methodology consensus clustering, and in conjunction with resampling techniques, it provides for a method to represent the consensus across multiple runs of a clustering algorithm and to assess the stability of the discovered clusters. The method can also be used to represent the consensus over multiple runs of a clustering algorithm with random restart (such as K-means, model-based Bayesian clustering, SOM, etc.), so as to account for its sensitivity to the initial conditions. Finally, it provides for a visualization tool to inspect cluster number, membership, and boundaries. We present the results of our experiments on both simulated data and real gene expression data aimed at evaluating the effectiveness of the methodology in discovering biologically meaningful clusters.", :author (#search_api.search_api.Author{:id 220806, :first-name nil, :last-name nil, :full-name "Stefano Monti"} #search_api.search_api.Author{:id 1414792, :first-name nil, :last-name nil, :full-name "Pablo Tamayo"} #search_api.search_api.Author{:id 312859, :first-name nil, :last-name nil, :full-name "Jill P. Mesirov"} #search_api.search_api.Author{:id 1071454, :first-name nil, :last-name nil, :full-name "Todd R. Golub"}), :year 2003, :venue "Machine Learning", :ncit 563, :string "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data.. In this paper we present a new methodology of class discovery and clustering validation tailored to the task of analyzing gene expression data. The method can best be thought of as an analysis approach, to guide and assist in the use of any of a wide range of available clustering algorithms. We call the new methodology consensus clustering, and in conjunction with resampling techniques, it provides for a method to represent the consensus across multiple runs of a clustering algorithm and to assess the stability of the discovered clusters. The method can also be used to represent the consensus over multiple runs of a clustering algorithm with random restart (such as K-means, model-based Bayesian clustering, SOM, etc.), so as to account for its sensitivity to the initial conditions. Finally, it provides for a visualization tool to inspect cluster number, membership, and boundaries. We present the results of our experiments on both simulated data and real gene expression data aimed at evaluating the effectiveness of the methodology in discovering biologically meaningful clusters.", :doc-id "Consensus Clustering: A Resampling-Based Method for Class Discovery and Visualization of Gene Expression Microarray Data. 2003  ,  ,  ,  "}, 3307625 #search_api.search_api.Paper{:id 3307625, :key "journals/wicomm/LiMS12", :title "Determination method of optimal number of clusters for clustered wireless sensor networks.", :abstract nil, :author (#search_api.search_api.Author{:id 823, :first-name nil, :last-name nil, :full-name "Wenfeng Li"} #search_api.search_api.Author{:id 1328653, :first-name nil, :last-name nil, :full-name "Philippe Martins"} #search_api.search_api.Author{:id 22605, :first-name nil, :last-name nil, :full-name "Lianfeng Shen"}), :year 2012, :venue "Wireless Communications and Mobile Computing", :ncit 4, :string "Determination method of optimal number of clusters for clustered wireless sensor networks.. ", :doc-id "Determination method of optimal number of clusters for clustered wireless sensor networks. 2012  ,  ,  "}, 3307209 #search_api.search_api.Paper{:id 3307209, :key "journals/ijpp/Diday73", :title "The dynamic clusters method in nonhierarchical clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 349305, :first-name nil, :last-name nil, :full-name "Edwin Diday"}), :year 1973, :venue "International Journal of Parallel Programming", :ncit 66, :string "The dynamic clusters method in nonhierarchical clustering.. ", :doc-id "The dynamic clusters method in nonhierarchical clustering. 1973  "}, 27498 #search_api.search_api.Paper{:id 27498, :key "conf/adma/WangW07", :title "A Fuzzy Comprehensive Clustering Method.", :abstract "Fuzzy comprehensive evaluation cannot reasonably differentiate the close membership values, e.g. 0.70 and 0.69. When the results have to be decided on the basis of maximum fuzzy membership value, some related information among similar objects may be neglected. At the same time, supervised fuzzy clustering analysis selects the threshold according to subjective experience. But different users may give different thresholds, and different thresholds may further get different clustering results. Integrating both fuzzy comprehensive evaluation and fuzzy clustering analysis in a unified way, this paper proposes a fuzzy comprehensive clustering method based on the maximum remainder algorithms and maximum characteristics algorithms. First, the principle of fuzzy comprehensive clustering is given. Based on the membership matrix of fuzzy comprehensive evaluation, fuzzy similar matrix is generated. Then a fuzzy equivalent matrix is produced from the fuzzy similar matrix. According to the fuzzy equivalent matrix, fuzzy clustering is implemented via the maximum remainder algorithms on the basis of fuzzy confidence level. And the grades of the resulting clusters are computed by using the maximum characteristics algorithms. Finally, a case study is given on land grading in Nanning city, the results of which show the proposed fuzzy comprehensive clustering method is able to overcome the disadvantages of either fuzzy comprehensive evaluation or fuzzy clustering analysis.", :author (#search_api.search_api.Author{:id 936520, :first-name nil, :last-name nil, :full-name "Shuliang Wang"} #search_api.search_api.Author{:id 604069, :first-name nil, :last-name nil, :full-name "Xinzhou Wang"}), :year 2007, :venue "ADMA", :ncit 3, :string "A Fuzzy Comprehensive Clustering Method.. Fuzzy comprehensive evaluation cannot reasonably differentiate the close membership values, e.g. 0.70 and 0.69. When the results have to be decided on the basis of maximum fuzzy membership value, some related information among similar objects may be neglected. At the same time, supervised fuzzy clustering analysis selects the threshold according to subjective experience. But different users may give different thresholds, and different thresholds may further get different clustering results. Integrating both fuzzy comprehensive evaluation and fuzzy clustering analysis in a unified way, this paper proposes a fuzzy comprehensive clustering method based on the maximum remainder algorithms and maximum characteristics algorithms. First, the principle of fuzzy comprehensive clustering is given. Based on the membership matrix of fuzzy comprehensive evaluation, fuzzy similar matrix is generated. Then a fuzzy equivalent matrix is produced from the fuzzy similar matrix. According to the fuzzy equivalent matrix, fuzzy clustering is implemented via the maximum remainder algorithms on the basis of fuzzy confidence level. And the grades of the resulting clusters are computed by using the maximum characteristics algorithms. Finally, a case study is given on land grading in Nanning city, the results of which show the proposed fuzzy comprehensive clustering method is able to overcome the disadvantages of either fuzzy comprehensive evaluation or fuzzy clustering analysis.", :doc-id "A Fuzzy Comprehensive Clustering Method. 2007  ,  "}, 527435 #search_api.search_api.Paper{:id 527435, :key "conf/pakdd/CrabtreeAG07", :title "QC4 - A Clustering Evaluation Method.", :abstract "Many clustering algorithms have been developed and researchers need to be able to compare their effectiveness. For some clustering problems, like web page clustering, different algorithms produce clusterings with different characteristics: coarse vs fine granularity, disjoint vs overlapping, flat vs hierarchical. The lack of a clustering evaluation method that can evaluate clusterings with different characteristics has led to incomparable research and results. QC4 solves this by providing a new structure for defining general ideal clusterings and new measurements for evaluating clusterings with different characteristics with respect to a general ideal clustering. The paper describes QC4 and evaluates it within the web clustering domain by comparison to existing evaluation measurements on synthetic test cases and on real world web page clustering tasks. The synthetic test cases show that only QC4 can cope correctly with overlapping clusters, hierarchical clusterings, and all the difficult boundary cases. In the real world tasks, which represent simple clustering situations, QC4 is mostly consistent with the existing measurements and makes better conclusions in some cases.", :author (#search_api.search_api.Author{:id 698966, :first-name nil, :last-name nil, :full-name "Daniel Crabtree"} #search_api.search_api.Author{:id 97078, :first-name nil, :last-name nil, :full-name "Peter Andreae"} #search_api.search_api.Author{:id 286163, :first-name nil, :last-name nil, :full-name "Xiaoying Gao"}), :year 2007, :venue "PAKDD", :ncit 9, :string "QC4 - A Clustering Evaluation Method.. Many clustering algorithms have been developed and researchers need to be able to compare their effectiveness. For some clustering problems, like web page clustering, different algorithms produce clusterings with different characteristics: coarse vs fine granularity, disjoint vs overlapping, flat vs hierarchical. The lack of a clustering evaluation method that can evaluate clusterings with different characteristics has led to incomparable research and results. QC4 solves this by providing a new structure for defining general ideal clusterings and new measurements for evaluating clusterings with different characteristics with respect to a general ideal clustering. The paper describes QC4 and evaluates it within the web clustering domain by comparison to existing evaluation measurements on synthetic test cases and on real world web page clustering tasks. The synthetic test cases show that only QC4 can cope correctly with overlapping clusters, hierarchical clusterings, and all the difficult boundary cases. In the real world tasks, which represent simple clustering situations, QC4 is mostly consistent with the existing measurements and makes better conclusions in some cases.", :doc-id "QC4 - A Clustering Evaluation Method. 2007  ,  ,  "}, 1219659 #search_api.search_api.Paper{:id 1219659, :key "journals/bioinformatics/LinTCBSF08", :title "Smarter clustering methods for SNP genotype calling.", :abstract "Motivation: Most genotyping technologies for single nucleotide polymorphism (SNP) markers use standard clustering methods to ‘call’ the SNP genotypes. These methods are not always optimal in distinguishing the genotype clusters of a SNP because they do not take advantage of specific features of the genotype calling problem. In particular, when family data are available, pedigree information is ignored. Furthermore, prior information about the distribution of the measurements for each cluster can be used to choose an appropriate model-based clustering method and can significantly improve the genotype calls. One special genotyping problem that has never been discussed in the literature is that of genotyping of trisomic individuals, such as individuals with Down syndrome. Calling trisomic genotypes is a more complicated problem, and the addition of external information becomes very important. Results: In this article, we discuss the impact of incorporating external information into clustering algorithms to call the genotypes for both disomic and trisomic data. We also propose two new methods to call genotypes using family data. One is a modification of the K-means method and uses the pedigree information by updating all members of a family together. The other is a likelihood-based method that combines the Gaussian or beta-mixture model with pedigree information. We compare the performance of these two methods and some other existing methods using simulation studies. We also compare the performance of these methods on a real dataset generated by the Illumina platform ( www.illumina.com). Availability: The R code for the family-based genotype calling methods (SNPCaller) is available to be downloaded from the following website: http://watson.hgen.pitt.edu/register. Contact: liny@upmc.edu Supplementary information:Supplementary data are available at Bioinformatics online.", :author (#search_api.search_api.Author{:id 293647, :first-name nil, :last-name nil, :full-name "Yan Lin"} #search_api.search_api.Author{:id 503391, :first-name nil, :last-name nil, :full-name "George C. Tseng"} #search_api.search_api.Author{:id 1480924, :first-name nil, :last-name nil, :full-name "Soo Yeon Cheong"} #search_api.search_api.Author{:id 65191, :first-name nil, :last-name nil, :full-name "Lora J. H. Bean"} #search_api.search_api.Author{:id 1388696, :first-name nil, :last-name nil, :full-name "Stephanie L. Sherman"} #search_api.search_api.Author{:id 632614, :first-name nil, :last-name nil, :full-name "Eleanor Feingold"}), :year 2008, :venue "Bioinformatics", :ncit 8, :string "Smarter clustering methods for SNP genotype calling.. Motivation: Most genotyping technologies for single nucleotide polymorphism (SNP) markers use standard clustering methods to ‘call’ the SNP genotypes. These methods are not always optimal in distinguishing the genotype clusters of a SNP because they do not take advantage of specific features of the genotype calling problem. In particular, when family data are available, pedigree information is ignored. Furthermore, prior information about the distribution of the measurements for each cluster can be used to choose an appropriate model-based clustering method and can significantly improve the genotype calls. One special genotyping problem that has never been discussed in the literature is that of genotyping of trisomic individuals, such as individuals with Down syndrome. Calling trisomic genotypes is a more complicated problem, and the addition of external information becomes very important. Results: In this article, we discuss the impact of incorporating external information into clustering algorithms to call the genotypes for both disomic and trisomic data. We also propose two new methods to call genotypes using family data. One is a modification of the K-means method and uses the pedigree information by updating all members of a family together. The other is a likelihood-based method that combines the Gaussian or beta-mixture model with pedigree information. We compare the performance of these two methods and some other existing methods using simulation studies. We also compare the performance of these methods on a real dataset generated by the Illumina platform ( www.illumina.com). Availability: The R code for the family-based genotype calling methods (SNPCaller) is available to be downloaded from the following website: http://watson.hgen.pitt.edu/register. Contact: liny@upmc.edu Supplementary information:Supplementary data are available at Bioinformatics online.", :doc-id "Smarter clustering methods for SNP genotype calling. 2008  ,  ,  ,  ,  ,  "}, 3462412 #search_api.search_api.Paper{:id 3462412, :key "journals/tec/LiY12a", :title "A General Framework of Multipopulation Methods With Clustering in Undetectable Dynamic Environments.", :abstract nil, :author (#search_api.search_api.Author{:id 1165243, :first-name nil, :last-name nil, :full-name "Changhe Li"} #search_api.search_api.Author{:id 554649, :first-name nil, :last-name nil, :full-name "Shengxiang Yang"}), :year 2012, :venue "IEEE Trans. Evolutionary Computation", :ncit 12, :string "A General Framework of Multipopulation Methods With Clustering in Undetectable Dynamic Environments.. ", :doc-id "A General Framework of Multipopulation Methods With Clustering in Undetectable Dynamic Environments. 2012  ,  "}, 3482604 #search_api.search_api.Paper{:id 3482604, :key "journals/jiis/NaijaS12", :title "Interpretability-based validity methods for clustering results evaluation.", :abstract nil, :author (#search_api.search_api.Author{:id 14318277, :first-name nil, :last-name nil, :full-name "Yosr Naïja"} #search_api.search_api.Author{:id 14318278, :first-name nil, :last-name nil, :full-name "Kaouthar Blibech Sinaoui"}), :year 2012, :venue "J. Intell. Inf. Syst.", :ncit 0, :string "Interpretability-based validity methods for clustering results evaluation.. ", :doc-id "Interpretability-based validity methods for clustering results evaluation. 2012  ,  "}, 1023181 #search_api.search_api.Paper{:id 1023181, :key "journals/neco/LevineD01", :title "Resampling Method for Unsupervised Estimation of Cluster Validity.", :abstract "We introduce a method for validation of results obtained by clustering analysis of data. The method is based on resampling the available data. A figure of merit that measures the stability of clustering solutions against resampling is introduced. Clusters that are stable against resampling give rise to local maxima of this figure of merit. This is presented first for a one-dimensional data set, for which an analytic approximation for the figure of merit is derived and compared with numerical measurements. Next, the applicability of the method is demonstrated for higher-dimensional data, including gene microarray expression data.", :author (#search_api.search_api.Author{:id 702949, :first-name nil, :last-name nil, :full-name "Erel Levine"} #search_api.search_api.Author{:id 151361, :first-name nil, :last-name nil, :full-name "Eytan Domany"}), :year 2001, :venue "Neural Computation", :ncit 204, :string "Resampling Method for Unsupervised Estimation of Cluster Validity.. We introduce a method for validation of results obtained by clustering analysis of data. The method is based on resampling the available data. A figure of merit that measures the stability of clustering solutions against resampling is introduced. Clusters that are stable against resampling give rise to local maxima of this figure of merit. This is presented first for a one-dimensional data set, for which an analytic approximation for the figure of merit is derived and compared with numerical measurements. Next, the applicability of the method is demonstrated for higher-dimensional data, including gene microarray expression data.", :doc-id "Resampling Method for Unsupervised Estimation of Cluster Validity. 2001  ,  "}, 3447405 #search_api.search_api.Paper{:id 3447405, :key "journals/tkde/ChenJW12", :title "Model-Based Method for Projective Clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 1307912, :first-name nil, :last-name nil, :full-name "Lifei Chen"} #search_api.search_api.Author{:id 1176438, :first-name nil, :last-name nil, :full-name "Qingshan Jiang"} #search_api.search_api.Author{:id 148603, :first-name nil, :last-name nil, :full-name "Shengrui Wang"}), :year 2012, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 4, :string "Model-Based Method for Projective Clustering.. ", :doc-id "Model-Based Method for Projective Clustering. 2012  ,  ,  "}, 3383981 #search_api.search_api.Paper{:id 3383981, :key "journals/corr/abs-1205-1117", :title "An Overview on Clustering Methods", :abstract nil, :author (#search_api.search_api.Author{:id 14270410, :first-name nil, :last-name nil, :full-name "T. Soni Madhulatha"}), :year 2012, :venue "CoRR", :ncit 0, :string "An Overview on Clustering Methods. ", :doc-id "An Overview on Clustering Methods 2012  "}, 839501 #search_api.search_api.Paper{:id 839501, :key "journals/datamine/Xia09", :title "A global optimization method for semi-supervised clustering.", :abstract "In this paper, we adapt Tuy's concave cutting plane method to the semi-supervised clustering. We also give properties of local optimal solutions of the semi-supervised clustering. Numerical examples show that this method can give a better solution than other semi-supervised clustering algorithms do.", :author (#search_api.search_api.Author{:id 412580, :first-name nil, :last-name nil, :full-name "Yu Xia"}), :year 2009, :venue "Data Min. Knowl. Discov.", :ncit 3, :string "A global optimization method for semi-supervised clustering.. In this paper, we adapt Tuy's concave cutting plane method to the semi-supervised clustering. We also give properties of local optimal solutions of the semi-supervised clustering. Numerical examples show that this method can give a better solution than other semi-supervised clustering algorithms do.", :doc-id "A global optimization method for semi-supervised clustering. 2009  "}, 3506029 #search_api.search_api.Paper{:id 3506029, :key "conf/rskt/WangW12", :title "A Spatial Clustering Method for Points-with-Directions.", :abstract nil, :author (#search_api.search_api.Author{:id 1304716, :first-name nil, :last-name nil, :full-name "Jing Wang"} #search_api.search_api.Author{:id 1026850, :first-name nil, :last-name nil, :full-name "Xin Wang"}), :year 2012, :venue "RSKT", :ncit 0, :string "A Spatial Clustering Method for Points-with-Directions.. ", :doc-id "A Spatial Clustering Method for Points-with-Directions. 2012  ,  "}, 939118 #search_api.search_api.Paper{:id 939118, :key "journals/is/YunCC06", :title "Adherence clustering: an efficient method for mining market-basket clusters.", :abstract "We explore in this paper the efficient clustering of market-basket data. Different from those of the traditional data, the features of market-basket data are known to be of high dimensionality and sparsity. Without explicitly considering the presence of the taxonomy, most prior efforts on clustering market-basket data can be viewed as dealing with items in the leaf level of the taxonomy tree. Clustering transactions across different levels of the taxonomy is of great importance for marketing strategies as well as for the result representation of the clustering techniques for market-basket data. In view of the features of market-basket data, we devise in this paper a novel measurement, called the category-based adherence, and utilize this measurement to perform the clustering. With this category-based adherence measurement, we develop an efficient clustering algorithm, called algorithm k-todes, for market-basket data with the objective to minimize the category-based adherence. The distance of an item to a given cluster is defined as the number of links between this item and its nearest tode. The category-based adherence of a transaction to a cluster is then defined as the average distance of the items in this transaction to that cluster. A validation model based on information gain is also devised to assess the quality of clustering for market-basket data. As validated by both real and synthetic datasets, it is shown by our experimental results, with the taxonomy information, algorithm k-todes devised in this paper significantly outperforms the prior works in both the execution efficiency and the clustering quality as measured by information gain, indicating the usefulness of category-based adherence in market-basket data clustering.", :author (#search_api.search_api.Author{:id 698395, :first-name nil, :last-name nil, :full-name "Ching-Huang Yun"} #search_api.search_api.Author{:id 901470, :first-name nil, :last-name nil, :full-name "Kun-Ta Chuang"} #search_api.search_api.Author{:id 6987, :first-name nil, :last-name nil, :full-name "Ming-Syan Chen"}), :year 2006, :venue "Inf. Syst.", :ncit 10, :string "Adherence clustering: an efficient method for mining market-basket clusters.. We explore in this paper the efficient clustering of market-basket data. Different from those of the traditional data, the features of market-basket data are known to be of high dimensionality and sparsity. Without explicitly considering the presence of the taxonomy, most prior efforts on clustering market-basket data can be viewed as dealing with items in the leaf level of the taxonomy tree. Clustering transactions across different levels of the taxonomy is of great importance for marketing strategies as well as for the result representation of the clustering techniques for market-basket data. In view of the features of market-basket data, we devise in this paper a novel measurement, called the category-based adherence, and utilize this measurement to perform the clustering. With this category-based adherence measurement, we develop an efficient clustering algorithm, called algorithm k-todes, for market-basket data with the objective to minimize the category-based adherence. The distance of an item to a given cluster is defined as the number of links between this item and its nearest tode. The category-based adherence of a transaction to a cluster is then defined as the average distance of the items in this transaction to that cluster. A validation model based on information gain is also devised to assess the quality of clustering for market-basket data. As validated by both real and synthetic datasets, it is shown by our experimental results, with the taxonomy information, algorithm k-todes devised in this paper significantly outperforms the prior works in both the execution efficiency and the clustering quality as measured by information gain, indicating the usefulness of category-based adherence in market-basket data clustering.", :doc-id "Adherence clustering: an efficient method for mining market-basket clusters. 2006  ,  ,  "}, 893422 #search_api.search_api.Paper{:id 893422, :key "journals/ida/OmranES07", :title "An overview of clustering methods.", :abstract "Data clustering is the process of identifying natural groupings or clusters within multidimensional data based on some similarity measure. Clustering is a fundamental process in many different disciplines. Hence, researchers from different fields are actively working on the clustering problem. This paper provides an overview of the different representative clustering methods. In addition, several clustering validations indices are shown. Furthermore, approaches to automatically determine the number of clusters are presented. Finally, application of different heuristic approaches to the clustering problem is also investigated.", :author (#search_api.search_api.Author{:id 117152, :first-name nil, :last-name nil, :full-name "Mahamed G. Omran"} #search_api.search_api.Author{:id 621177, :first-name nil, :last-name nil, :full-name "Andries Petrus Engelbrecht"} #search_api.search_api.Author{:id 319269, :first-name nil, :last-name nil, :full-name "Ayed A. Salman"}), :year 2007, :venue "Intell. Data Anal.", :ncit 45, :string "An overview of clustering methods.. Data clustering is the process of identifying natural groupings or clusters within multidimensional data based on some similarity measure. Clustering is a fundamental process in many different disciplines. Hence, researchers from different fields are actively working on the clustering problem. This paper provides an overview of the different representative clustering methods. In addition, several clustering validations indices are shown. Furthermore, approaches to automatically determine the number of clusters are presented. Finally, application of different heuristic approaches to the clustering problem is also investigated.", :doc-id "An overview of clustering methods. 2007  ,  ,  "}, 1031215 #search_api.search_api.Paper{:id 1031215, :key "journals/pami/CaelliK04", :title "An Eigenspace Projection Clustering Method for Inexact Graph Matching.", :abstract "Abstract--In this paper, we show how inexact graph matching (that is, the correspondence between sets of vertices of pairs of graphs) can be solved using the renormalization of projections of the vertices (as defined in this case by their connectivities) into the joint eigenspace of a pair of graphs and a form of relational clustering. An important feature of this eigenspace renormalization projection clustering (EPC) method is its ability to match graphs with different number of vertices. Shock graph-based shape matching is used to illustrate the model and a more objective method for evaluating the approach using random graphs is explored with encouraging results.", :author (#search_api.search_api.Author{:id 627606, :first-name nil, :last-name nil, :full-name "Terry Caelli"} #search_api.search_api.Author{:id 484276, :first-name nil, :last-name nil, :full-name "Serhiy Kosinov"}), :year 2004, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 121, :string "An Eigenspace Projection Clustering Method for Inexact Graph Matching.. Abstract--In this paper, we show how inexact graph matching (that is, the correspondence between sets of vertices of pairs of graphs) can be solved using the renormalization of projections of the vertices (as defined in this case by their connectivities) into the joint eigenspace of a pair of graphs and a form of relational clustering. An important feature of this eigenspace renormalization projection clustering (EPC) method is its ability to match graphs with different number of vertices. Shock graph-based shape matching is used to illustrate the model and a more objective method for evaluating the approach using random graphs is explored with encouraging results.", :doc-id "An Eigenspace Projection Clustering Method for Inexact Graph Matching. 2004  ,  "}, 1033455 #search_api.search_api.Paper{:id 1033455, :key "journals/pami/YangW04", :title "A Similarity-Based Robust Clustering Method.", :abstract "Abstract--This paper presents an alternating optimization clustering procedure called a similarity-based clustering method (SCM). It is an effective and robust approach to clustering on the basis of a total similarity objective function related to the approximate density shape estimation. We show that the data points in SCM can self-organize local optimal cluster number and volumes without using cluster validity functions or a variance-covariance matrix. The proposed clustering method is also robust to noise and outliers based on the influence function and gross error sensitivity analysis. Therefore, SCM exhibits three robust clustering characteristics: 1) robust to the initialization (cluster number and initial guesses), 2) robust to cluster volumes (ability to detect different volumes of clusters), and 3) robust to noise and outliers. Several numerical data sets and actual data are used in the SCM to show these good aspects. The computational complexity of SCM is also analyzed. Some experimental results of comparing the proposed SCM with the existing methods show the superiority of the SCM method.", :author (#search_api.search_api.Author{:id 1103232, :first-name nil, :last-name nil, :full-name "Miin-Shen Yang"} #search_api.search_api.Author{:id 61859, :first-name nil, :last-name nil, :full-name "Kuo-Lung Wu"}), :year 2004, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 138, :string "A Similarity-Based Robust Clustering Method.. Abstract--This paper presents an alternating optimization clustering procedure called a similarity-based clustering method (SCM). It is an effective and robust approach to clustering on the basis of a total similarity objective function related to the approximate density shape estimation. We show that the data points in SCM can self-organize local optimal cluster number and volumes without using cluster validity functions or a variance-covariance matrix. The proposed clustering method is also robust to noise and outliers based on the influence function and gross error sensitivity analysis. Therefore, SCM exhibits three robust clustering characteristics: 1) robust to the initialization (cluster number and initial guesses), 2) robust to cluster volumes (ability to detect different volumes of clusters), and 3) robust to noise and outliers. Several numerical data sets and actual data are used in the SCM to show these good aspects. The computational complexity of SCM is also analyzed. Some experimental results of comparing the proposed SCM with the existing methods show the superiority of the SCM method.", :doc-id "A Similarity-Based Robust Clustering Method. 2004  ,  "}, 2966831 #search_api.search_api.Paper{:id 2966831, :key "journals/corr/abs-1101-4270", :title "A Comparative Agglomerative Hierarchical Clustering Method to Cluster Implemented Course", :abstract nil, :author (#search_api.search_api.Author{:id 1596927, :first-name nil, :last-name nil, :full-name "Rahmat Widia Sembiring"} #search_api.search_api.Author{:id 1059116, :first-name nil, :last-name nil, :full-name "Jasni Mohamad Zain"} #search_api.search_api.Author{:id 882172, :first-name nil, :last-name nil, :full-name "Abdullah Embong"}), :year 2011, :venue "CoRR", :ncit 2, :string "A Comparative Agglomerative Hierarchical Clustering Method to Cluster Implemented Course. ", :doc-id "A Comparative Agglomerative Hierarchical Clustering Method to Cluster Implemented Course 2011  ,  ,  "}, 3156815 #search_api.search_api.Paper{:id 3156815, :key "journals/cma/YuYL11", :title "Sample-weighted clustering methods.", :abstract nil, :author (#search_api.search_api.Author{:id 1225817, :first-name nil, :last-name nil, :full-name "Jian Yu"} #search_api.search_api.Author{:id 1103232, :first-name nil, :last-name nil, :full-name "Miin-Shen Yang"} #search_api.search_api.Author{:id 6725, :first-name nil, :last-name nil, :full-name "E. Stanley Lee"}), :year 2011, :venue "Computers & Mathematics with Applications", :ncit 0, :string "Sample-weighted clustering methods.. ", :doc-id "Sample-weighted clustering methods. 2011  ,  ,  "}, 2878447 #search_api.search_api.Paper{:id 2878447, :key "journals/ftml/Luxburg09", :title "Clustering Stability: An Overview.", :abstract "A popular method for selecting the number of clusters is based on stability arguments: one chooses the number of clusters such that the corresponding clustering results are \"most stable\". In recent years, a series of papers has analyzed the behavior of this method from a theoretical point of view. However, the results are very technical and difficult to interpret for non-experts. In this monograph we give a high-level overview about the existing literature on clustering stability. In addition to presenting the results in a slightly informal but accessible way, we relate them to each other and discuss their different implications. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player", :author (#search_api.search_api.Author{:id 790641, :first-name nil, :last-name nil, :full-name "Ulrike von Luxburg"}), :year 2009, :venue "Foundations and Trends in Machine Learning", :ncit 1, :string "Clustering Stability: An Overview.. A popular method for selecting the number of clusters is based on stability arguments: one chooses the number of clusters such that the corresponding clustering results are \"most stable\". In recent years, a series of papers has analyzed the behavior of this method from a theoretical point of view. However, the results are very technical and difficult to interpret for non-experts. In this monograph we give a high-level overview about the existing literature on clustering stability. In addition to presenting the results in a slightly informal but accessible way, we relate them to each other and discuss their different implications. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player", :doc-id "Clustering Stability: An Overview. 2009  "}, 1042704 #search_api.search_api.Paper{:id 1042704, :key "journals/pr/FilipponeCMR08", :title "A survey of kernel and spectral methods for clustering.", :abstract "Clustering algorithms are a useful tool to explore data structures and have been employed in many disciplines. The focus of this paper is the partitioning clustering problem with a special interest in two recent approaches: kernel and spectral methods. The aim of this paper is to present a survey of kernel and spectral clustering methods, two approaches able to produce nonlinear separating hypersurfaces between clusters. The presented kernel clustering methods are the kernel version of many classical clustering algorithms, e.g., K-means, SOM and neural gas. Spectral clustering arise from concepts in spectral graph theory and the clustering problem is configured as a graph cut problem where an appropriate objective function has to be optimized. An explicit proof of the fact that these two paradigms have the same objective is reported since it has been proven that these two seemingly different approaches have the same mathematical foundation. Besides, fuzzy kernel clustering methods are presented as extensions of kernel K-means clustering algorithm.", :author (#search_api.search_api.Author{:id 309224, :first-name nil, :last-name nil, :full-name "Maurizio Filippone"} #search_api.search_api.Author{:id 662277, :first-name nil, :last-name nil, :full-name "Francesco Camastra"} #search_api.search_api.Author{:id 238014, :first-name nil, :last-name nil, :full-name "Francesco Masulli"} #search_api.search_api.Author{:id 459312, :first-name nil, :last-name nil, :full-name "Stefano Rovetta"}), :year 2008, :venue "Pattern Recognition", :ncit 309, :string "A survey of kernel and spectral methods for clustering.. Clustering algorithms are a useful tool to explore data structures and have been employed in many disciplines. The focus of this paper is the partitioning clustering problem with a special interest in two recent approaches: kernel and spectral methods. The aim of this paper is to present a survey of kernel and spectral clustering methods, two approaches able to produce nonlinear separating hypersurfaces between clusters. The presented kernel clustering methods are the kernel version of many classical clustering algorithms, e.g., K-means, SOM and neural gas. Spectral clustering arise from concepts in spectral graph theory and the clustering problem is configured as a graph cut problem where an appropriate objective function has to be optimized. An explicit proof of the fact that these two paradigms have the same objective is reported since it has been proven that these two seemingly different approaches have the same mathematical foundation. Besides, fuzzy kernel clustering methods are presented as extensions of kernel K-means clustering algorithm.", :doc-id "A survey of kernel and spectral methods for clustering. 2008  ,  ,  ,  "}, 3073360 #search_api.search_api.Paper{:id 3073360, :key "journals/jmlr/CarlssonM10", :title "Characterization, Stability and Convergence of Hierarchical Clustering Methods.", :abstract nil, :author (#search_api.search_api.Author{:id 1461383, :first-name nil, :last-name nil, :full-name "Gunnar Carlsson"} #search_api.search_api.Author{:id 258181, :first-name nil, :last-name nil, :full-name "Facundo Mémoli"}), :year 2010, :venue "Journal of Machine Learning Research", :ncit 28, :string "Characterization, Stability and Convergence of Hierarchical Clustering Methods.. ", :doc-id "Characterization, Stability and Convergence of Hierarchical Clustering Methods. 2010  ,  "}, 3700560 #search_api.search_api.Paper{:id 3700560, :key "journals/kais/BorjiginG13", :title "Non-unique cluster numbers determination methods based on stability in spectral clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 14417055, :first-name nil, :last-name nil, :full-name "Sumuya Borjigin"} #search_api.search_api.Author{:id 1214206, :first-name nil, :last-name nil, :full-name "Chonghui Guo"}), :year 2013, :venue "Knowl. Inf. Syst.", :ncit 0, :string "Non-unique cluster numbers determination methods based on stability in spectral clustering.. ", :doc-id "Non-unique cluster numbers determination methods based on stability in spectral clustering. 2013  ,  "}, 3570833 #search_api.search_api.Paper{:id 3570833, :key "conf/amt/ZhangLX12", :title "A On-Line News Documents Clustering Method.", :abstract nil, :author (#search_api.search_api.Author{:id 552864, :first-name nil, :last-name nil, :full-name "Hui Zhang"} #search_api.search_api.Author{:id 602303, :first-name nil, :last-name nil, :full-name "Guo-Hui Li"} #search_api.search_api.Author{:id 351380, :first-name nil, :last-name nil, :full-name "Xin-Wen Xu"}), :year 2012, :venue "AMT", :ncit 0, :string "A On-Line News Documents Clustering Method.. ", :doc-id "A On-Line News Documents Clustering Method. 2012  ,  ,  "}, 3233265 #search_api.search_api.Paper{:id 3233265, :key "conf/ijcnn/Al-ShaqsiW10", :title "A clustering ensemble method for clustering mixed data.", :abstract nil, :author (#search_api.search_api.Author{:id 14205051, :first-name nil, :last-name nil, :full-name "J. Al-Shaqsi"} #search_api.search_api.Author{:id 1522132, :first-name nil, :last-name nil, :full-name "Wenjia Wang"}), :year 2010, :venue "IJCNN", :ncit 3, :string "A clustering ensemble method for clustering mixed data.. ", :doc-id "A clustering ensemble method for clustering mixed data. 2010  ,  "}, 2870097 #search_api.search_api.Paper{:id 2870097, :key "journals/tkde/ConsoliDGKP10", :title "Heuristic Approaches for the Quartet Method of Hierarchical Clustering.", :abstract "Given a set of objects and their pairwise distances, we wish to determine a visual representation of the data. We use the quartet paradigm to compute a hierarchy of clusters of the objects. The method is based on an NP-hard graph optimization problem called the Minimum Quartet Tree Cost problem. This paper presents and compares several heuristic approaches to approximate the optimal hierarchy. The performance of the algorithms is tested through extensive computational experiments and it is shown that the Reduced Variable Neighborhood Search heuristic is the most effective approach to the problem, obtaining high-quality solutions in short computational running times.", :author (#search_api.search_api.Author{:id 533968, :first-name nil, :last-name nil, :full-name "Sergio Consoli"} #search_api.search_api.Author{:id 415373, :first-name nil, :last-name nil, :full-name "Kenneth Darby-Dowman"} #search_api.search_api.Author{:id 47173, :first-name nil, :last-name nil, :full-name "Gijs Geleijnse"} #search_api.search_api.Author{:id 656918, :first-name nil, :last-name nil, :full-name "Jan H. M. Korst"} #search_api.search_api.Author{:id 1326388, :first-name nil, :last-name nil, :full-name "Steffen Pauws"}), :year 2010, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 7, :string "Heuristic Approaches for the Quartet Method of Hierarchical Clustering.. Given a set of objects and their pairwise distances, we wish to determine a visual representation of the data. We use the quartet paradigm to compute a hierarchy of clusters of the objects. The method is based on an NP-hard graph optimization problem called the Minimum Quartet Tree Cost problem. This paper presents and compares several heuristic approaches to approximate the optimal hierarchy. The performance of the algorithms is tested through extensive computational experiments and it is shown that the Reduced Variable Neighborhood Search heuristic is the most effective approach to the problem, obtaining high-quality solutions in short computational running times.", :doc-id "Heuristic Approaches for the Quartet Method of Hierarchical Clustering. 2010  ,  ,  ,  ,  "}, 1257393 #search_api.search_api.Paper{:id 1257393, :key "conf/wirn/FilipponeMR08", :title "An Experimental Comparison of Kernel Clustering Methods.", :abstract "In this paper, we compare the performances of some among the most popular kernel clustering methods on several data sets. The methods are all based on central clustering and incorporate in various ways the concepts of fuzzy clustering and kernel machines. The data sets are a sample of several application domains and sizes. A thorough discussion about the techniques for validating results is also presented. Results indicate that clustering in kernel space generally outperforms standard clustering, although no method can be proven to be consistently better than the others.", :author (#search_api.search_api.Author{:id 309224, :first-name nil, :last-name nil, :full-name "Maurizio Filippone"} #search_api.search_api.Author{:id 238014, :first-name nil, :last-name nil, :full-name "Francesco Masulli"} #search_api.search_api.Author{:id 459312, :first-name nil, :last-name nil, :full-name "Stefano Rovetta"}), :year 2008, :venue "WIRN", :ncit 0, :string "An Experimental Comparison of Kernel Clustering Methods.. In this paper, we compare the performances of some among the most popular kernel clustering methods on several data sets. The methods are all based on central clustering and incorporate in various ways the concepts of fuzzy clustering and kernel machines. The data sets are a sample of several application domains and sizes. A thorough discussion about the techniques for validating results is also presented. Results indicate that clustering in kernel space generally outperforms standard clustering, although no method can be proven to be consistently better than the others.", :doc-id "An Experimental Comparison of Kernel Clustering Methods. 2008  ,  ,  "}, 2864403 #search_api.search_api.Paper{:id 2864403, :key "journals/jmlr/BubeckL09", :title "Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions.", :abstract "Clustering is often formulated as a discrete optimization problem. The objective is to find, among all partitions of the data set, the best one according to some quality measure. However, in the statistical setting where we assume that the finite data set has been sampled from some underlying space, the goal is not to find the best partition of the given sample, but to approximate the true partition of the underlying space. We argue that the discrete optimization approach usually does not achieve this goal, and instead can lead to inconsistency. We construct examples which provably have this behavior. As in the case of supervised learning, the cure is to restrict the size of the function classes under consideration. For appropriate \"small\" function classes we can prove very general consistency theorems for clustering optimization schemes. As one particular algorithm for clustering with a restricted function space we introduce \"nearest neighbor clustering\". Similar to the k-nearest neighbor classifier in supervised learning, this algorithm can be seen as a general baseline algorithm to minimize arbitrary clustering objective functions. We prove that it is statistically consistent for all commonly used clustering objective functions.", :author (#search_api.search_api.Author{:id 532244, :first-name nil, :last-name nil, :full-name "Sébastien Bubeck"} #search_api.search_api.Author{:id 790641, :first-name nil, :last-name nil, :full-name "Ulrike von Luxburg"}), :year 2009, :venue "Journal of Machine Learning Research", :ncit 14, :string "Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions.. Clustering is often formulated as a discrete optimization problem. The objective is to find, among all partitions of the data set, the best one according to some quality measure. However, in the statistical setting where we assume that the finite data set has been sampled from some underlying space, the goal is not to find the best partition of the given sample, but to approximate the true partition of the underlying space. We argue that the discrete optimization approach usually does not achieve this goal, and instead can lead to inconsistency. We construct examples which provably have this behavior. As in the case of supervised learning, the cure is to restrict the size of the function classes under consideration. For appropriate \"small\" function classes we can prove very general consistency theorems for clustering optimization schemes. As one particular algorithm for clustering with a restricted function space we introduce \"nearest neighbor clustering\". Similar to the k-nearest neighbor classifier in supervised learning, this algorithm can be seen as a general baseline algorithm to minimize arbitrary clustering objective functions. We prove that it is statistically consistent for all commonly used clustering objective functions.", :doc-id "Nearest Neighbor Clustering: A Baseline Method for Consistent Clustering with Arbitrary Objective Functions. 2009  ,  "}, 2771 #search_api.search_api.Paper{:id 2771, :key "books/sp/datamining2005/RokachM05a", :title "Clustering Methods.", :abstract nil, :author (#search_api.search_api.Author{:id 529112, :first-name nil, :last-name nil, :full-name "Lior Rokach"} #search_api.search_api.Author{:id 211259, :first-name nil, :last-name nil, :full-name "Oded Maimon"}), :year 2005, :venue "The Data Mining and Knowledge Discovery Handbook", :ncit 45, :string "Clustering Methods.. ", :doc-id "Clustering Methods. 2005  ,  "}, 3679540 #search_api.search_api.Paper{:id 3679540, :key "journals/tkde/Park13", :title "The Adaptive Clustering Method for the Long Tail Problem of Recommender Systems.", :abstract nil, :author (#search_api.search_api.Author{:id 1106043, :first-name nil, :last-name nil, :full-name "Yoon-Joo Park"}), :year 2013, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 0, :string "The Adaptive Clustering Method for the Long Tail Problem of Recommender Systems.. ", :doc-id "The Adaptive Clustering Method for the Long Tail Problem of Recommender Systems. 2013  "}, 1273172 #search_api.search_api.Paper{:id 1273172, :key "journals/ida/MirzaeiRA08", :title "A new method for hierarchical clustering combination.", :abstract "In the field of pattern recognition, combining different classifiers into a robust classifier is a common approach for improving classification accuracy. Recently, this trend has also been used to improve clustering performance especially in non-hierarchical clustering approaches. Generally hierarchical clustering is preferred in comparison with the partitional clustering for applications when the exact number of the clusters is not determined or when we are interested in finding the relation between clusters. To the best of our knowledge clustering combination methods proposed so far are based on partitional clustering and hierarchical clustering has been ignored. In this paper, a new method for combining hierarchical clustering is proposed. In this method, in the first step the primary hierarchical clustering dendrograms are converted to matrices. Then these matrices, which describe the dendrograms, are aggregated (using the matrix summation operator) into a final matrix with which the final clustering is formed. The effectiveness of different well known dendrogram descriptors and the one proposed by us for representing the dendrograms are evaluated and compared. The results show that all these descriptor work well and more accurate results (hierarchy of clusters) are obtained using hierarchical combination than combination of partitional clusterings.", :author (#search_api.search_api.Author{:id 1263458, :first-name nil, :last-name nil, :full-name "Abdolreza Mirzaei"} #search_api.search_api.Author{:id 316580, :first-name nil, :last-name nil, :full-name "Mohammad Rahmati"} #search_api.search_api.Author{:id 1462614, :first-name nil, :last-name nil, :full-name "Majid Ahmadi"}), :year 2008, :venue "Intell. Data Anal.", :ncit 10, :string "A new method for hierarchical clustering combination.. In the field of pattern recognition, combining different classifiers into a robust classifier is a common approach for improving classification accuracy. Recently, this trend has also been used to improve clustering performance especially in non-hierarchical clustering approaches. Generally hierarchical clustering is preferred in comparison with the partitional clustering for applications when the exact number of the clusters is not determined or when we are interested in finding the relation between clusters. To the best of our knowledge clustering combination methods proposed so far are based on partitional clustering and hierarchical clustering has been ignored. In this paper, a new method for combining hierarchical clustering is proposed. In this method, in the first step the primary hierarchical clustering dendrograms are converted to matrices. Then these matrices, which describe the dendrograms, are aggregated (using the matrix summation operator) into a final matrix with which the final clustering is formed. The effectiveness of different well known dendrogram descriptors and the one proposed by us for representing the dendrograms are evaluated and compared. The results show that all these descriptor work well and more accurate results (hierarchy of clusters) are obtained using hierarchical combination than combination of partitional clusterings.", :doc-id "A new method for hierarchical clustering combination. 2008  ,  ,  "}, 3490997 #search_api.search_api.Paper{:id 3490997, :key "conf/icic/ZhangH12", :title "A Novel Multiple Kernel Clustering Method.", :abstract nil, :author (#search_api.search_api.Author{:id 14321634, :first-name nil, :last-name nil, :full-name "Lujiang Zhang"} #search_api.search_api.Author{:id 25995, :first-name nil, :last-name nil, :full-name "Xiaohui Hu"}), :year 2012, :venue "ICIC (3)", :ncit 0, :string "A Novel Multiple Kernel Clustering Method.. ", :doc-id "A Novel Multiple Kernel Clustering Method. 2012  ,  "}, 600021 #search_api.search_api.Paper{:id 600021, :key "conf/sigmod/ZhangRL96", :title "BIRCH: An Efficient Data Clustering Method for Very Large Databases.", :abstract "Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle \"noise\" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.", :author (#search_api.search_api.Author{:id 267601, :first-name nil, :last-name nil, :full-name "Tian Zhang"} #search_api.search_api.Author{:id 464920, :first-name nil, :last-name nil, :full-name "Raghu Ramakrishnan"} #search_api.search_api.Author{:id 726591, :first-name nil, :last-name nil, :full-name "Miron Livny"}), :year 1996, :venue "SIGMOD Conference", :ncit 3214, :string "BIRCH: An Efficient Data Clustering Method for Very Large Databases.. Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle \"noise\" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.", :doc-id "BIRCH: An Efficient Data Clustering Method for Very Large Databases. 1996  ,  ,  "}, 3365845 #search_api.search_api.Paper{:id 3365845, :key "journals/kais/OnLL12", :title "Scalable clustering methods for the name disambiguation problem.", :abstract nil, :author (#search_api.search_api.Author{:id 1494929, :first-name nil, :last-name nil, :full-name "Byung-Won On"} #search_api.search_api.Author{:id 423695, :first-name nil, :last-name nil, :full-name "Ingyu Lee"} #search_api.search_api.Author{:id 76719, :first-name nil, :last-name nil, :full-name "Dongwon Lee"}), :year 2012, :venue "Knowl. Inf. Syst.", :ncit 7, :string "Scalable clustering methods for the name disambiguation problem.. ", :doc-id "Scalable clustering methods for the name disambiguation problem. 2012  ,  ,  "}, 346006 #search_api.search_api.Paper{:id 346006, :key "conf/icpr/Ben-HurSHV00", :title "A Support Vector Clustering Method.", :abstract nil, :author (#search_api.search_api.Author{:id 43180, :first-name nil, :last-name nil, :full-name "Asa Ben-Hur"} #search_api.search_api.Author{:id 352646, :first-name nil, :last-name nil, :full-name "Hava T. Siegelmann"} #search_api.search_api.Author{:id 1045131, :first-name nil, :last-name nil, :full-name "David Horn"} #search_api.search_api.Author{:id 125753, :first-name nil, :last-name nil, :full-name "Vladimir Vapnik"}), :year 2000, :venue "ICPR", :ncit 818, :string "A Support Vector Clustering Method.. ", :doc-id "A Support Vector Clustering Method. 2000  ,  ,  ,  "}, 3677399 #search_api.search_api.Paper{:id 3677399, :key "conf/nips/KalogeratosL12", :title "Dip-means: an incremental clustering method for estimating the number of clusters.", :abstract nil, :author (#search_api.search_api.Author{:id 1269438, :first-name nil, :last-name nil, :full-name "Argyris Kalogeratos"} #search_api.search_api.Author{:id 1236023, :first-name nil, :last-name nil, :full-name "Aristidis Likas"}), :year 2012, :venue "NIPS", :ncit 0, :string "Dip-means: an incremental clustering method for estimating the number of clusters.. ", :doc-id "Dip-means: an incremental clustering method for estimating the number of clusters. 2012  ,  "}, 1167799 #search_api.search_api.Paper{:id 1167799, :key "journals/tkdd/DomeniconiA09", :title "Weighted cluster ensembles: Methods and analysis.", :abstract "Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. Cluster ensembles can provide robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out emergent spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this article, we address the problem of combining multiple weighted clusters that belong to different subspaces of the input space. We leverage the diversity of the input clusterings in order to generate a consensus partition that is superior to the participating ones. Since we are dealing with weighted clusters, our consensus functions make use of the weight vectors associated with the clusters. We demonstrate the effectiveness of our techniques by running experiments with several real datasets, including high-dimensional text data. Furthermore, we investigate in depth the issue of diversity and accuracy for our ensemble methods. Our analysis and experimental results show that the proposed techniques are capable of producing a partition that is as good as or better than the best individual clustering.", :author (#search_api.search_api.Author{:id 1299027, :first-name nil, :last-name nil, :full-name "Carlotta Domeniconi"} #search_api.search_api.Author{:id 1046235, :first-name nil, :last-name nil, :full-name "Muna Al-Razgan"}), :year 2009, :venue "TKDD", :ncit 54, :string "Weighted cluster ensembles: Methods and analysis.. Cluster ensembles offer a solution to challenges inherent to clustering arising from its ill-posed nature. Cluster ensembles can provide robust and stable solutions by leveraging the consensus across multiple clustering results, while averaging out emergent spurious structures that arise due to the various biases to which each participating algorithm is tuned. In this article, we address the problem of combining multiple weighted clusters that belong to different subspaces of the input space. We leverage the diversity of the input clusterings in order to generate a consensus partition that is superior to the participating ones. Since we are dealing with weighted clusters, our consensus functions make use of the weight vectors associated with the clusters. We demonstrate the effectiveness of our techniques by running experiments with several real datasets, including high-dimensional text data. Furthermore, we investigate in depth the issue of diversity and accuracy for our ensemble methods. Our analysis and experimental results show that the proposed techniques are capable of producing a partition that is as good as or better than the best individual clustering.", :doc-id "Weighted cluster ensembles: Methods and analysis. 2009  ,  "}, 1033911 #search_api.search_api.Paper{:id 1033911, :key "journals/pami/AyadK08", :title "Cumulative Voting Consensus Method for Partitions with Variable Number of Clusters.", :abstract "Over the past few years, there has been a renewed interest in the consensus clustering problem. Several new methods have been proposed for finding a consensus partition for a set of n data objects that optimally summarizes an ensemble. In this paper, we propose new consensus clustering algorithms with linear computational complexity in n. We consider clusterings generated with random number of clusters, which we describe by categorical random variables. We introduce the idea of cumulative voting as a solution for the problem of cluster label alignment, where, unlike the common one-to-one voting scheme, a probabilistic mapping is computed. We seek a first summary of the ensemble that minimizes the average squared distance between the mapped partitions and the optimal representation of the ensemble, where the selection criterion of the reference clustering is defined based on maximizing the information content as measured by the entropy. We describe cumulative vote weighting schemes and corresponding algorithms to compute an empirical probability distribution summarizing the ensemble. Given the arbitrary number of clusters of the input partitions, we formulate the problem of extracting the optimal consensus as that of finding a compressed summary of the estimated distribution that preserves maximum relevant information. An efficient solution is obtained using an agglomerative algorithm that minimizes the average generalized Jensen-Shannon divergence within the cluster. The empirical study demonstrates significant gains in accuracy and superior performance compared to several recent consensus clustering algorithms.", :author (#search_api.search_api.Author{:id 434087, :first-name nil, :last-name nil, :full-name "Hanan Ayad"} #search_api.search_api.Author{:id 830023, :first-name nil, :last-name nil, :full-name "Mohamed S. Kamel"}), :year 2008, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 107, :string "Cumulative Voting Consensus Method for Partitions with Variable Number of Clusters.. Over the past few years, there has been a renewed interest in the consensus clustering problem. Several new methods have been proposed for finding a consensus partition for a set of n data objects that optimally summarizes an ensemble. In this paper, we propose new consensus clustering algorithms with linear computational complexity in n. We consider clusterings generated with random number of clusters, which we describe by categorical random variables. We introduce the idea of cumulative voting as a solution for the problem of cluster label alignment, where, unlike the common one-to-one voting scheme, a probabilistic mapping is computed. We seek a first summary of the ensemble that minimizes the average squared distance between the mapped partitions and the optimal representation of the ensemble, where the selection criterion of the reference clustering is defined based on maximizing the information content as measured by the entropy. We describe cumulative vote weighting schemes and corresponding algorithms to compute an empirical probability distribution summarizing the ensemble. Given the arbitrary number of clusters of the input partitions, we formulate the problem of extracting the optimal consensus as that of finding a compressed summary of the estimated distribution that preserves maximum relevant information. An efficient solution is obtained using an agglomerative algorithm that minimizes the average generalized Jensen-Shannon divergence within the cluster. The empirical study demonstrates significant gains in accuracy and superior performance compared to several recent consensus clustering algorithms.", :doc-id "Cumulative Voting Consensus Method for Partitions with Variable Number of Clusters. 2008  ,  "}, 570103 #search_api.search_api.Paper{:id 570103, :key "conf/sac/ChaovalitG09", :title "A method for clustering transient data streams.", :abstract "This paper describes a novel method for clustering single and multi-dimensional data streams. With incremental computation of the incoming data, our method determines if the cluster formation should change from an initial cluster formation. Four main types of cluster evolutions are studied: cluster appearance, cluster disappearance, cluster splitting, and cluster merging. We present experimental results of our algorithms both in terms of scalability and cluster quality, compared with recent work in this area.", :author (#search_api.search_api.Author{:id 1179435, :first-name nil, :last-name nil, :full-name "Pimwadee Chaovalit"} #search_api.search_api.Author{:id 188310, :first-name nil, :last-name nil, :full-name "Aryya Gangopadhyay"}), :year 2009, :venue "SAC", :ncit 2, :string "A method for clustering transient data streams.. This paper describes a novel method for clustering single and multi-dimensional data streams. With incremental computation of the incoming data, our method determines if the cluster formation should change from an initial cluster formation. Four main types of cluster evolutions are studied: cluster appearance, cluster disappearance, cluster splitting, and cluster merging. We present experimental results of our algorithms both in terms of scalability and cluster quality, compared with recent work in this area.", :doc-id "A method for clustering transient data streams. 2009  ,  "}, 527448 #search_api.search_api.Paper{:id 527448, :key "conf/pakdd/TsaiC08", :title "A Clustering-Oriented Star Coordinate Translation Method for Reliable Clustering Parameterization.", :abstract "When conducting a clustering process, users are generally concerned whether the clustering result is reliable enough to reflect the actual clustering phenomenon. The number of clusters and initial cluster centers are two critical parameters that influence the reliability of clustering results highly. We propose a Clustering-Oriented Star Coordinate Translation (COSCT) method to help users determining the two parameters more confidently. Through COSCT all objects from a multi-dimensional space are adaptively translated to a 2D starcoordinate plane, so that the clustering parameterization can be easily conducted by observing the clustering phenomenon in the plane. To enhance the cluster-displaying quality of the star-coordinate plane, the feature weighting and coordinate arrangement procedures are developed. The effectiveness of the COSCT method is demonstrated using a set of experiments.", :author (#search_api.search_api.Author{:id 1486757, :first-name nil, :last-name nil, :full-name "Chieh-Yuan Tsai"} #search_api.search_api.Author{:id 1023677, :first-name nil, :last-name nil, :full-name "Chuang-Cheng Chiu"}), :year 2008, :venue "PAKDD", :ncit 0, :string "A Clustering-Oriented Star Coordinate Translation Method for Reliable Clustering Parameterization.. When conducting a clustering process, users are generally concerned whether the clustering result is reliable enough to reflect the actual clustering phenomenon. The number of clusters and initial cluster centers are two critical parameters that influence the reliability of clustering results highly. We propose a Clustering-Oriented Star Coordinate Translation (COSCT) method to help users determining the two parameters more confidently. Through COSCT all objects from a multi-dimensional space are adaptively translated to a 2D starcoordinate plane, so that the clustering parameterization can be easily conducted by observing the clustering phenomenon in the plane. To enhance the cluster-displaying quality of the star-coordinate plane, the feature weighting and coordinate arrangement procedures are developed. The effectiveness of the COSCT method is demonstrated using a set of experiments.", :doc-id "A Clustering-Oriented Star Coordinate Translation Method for Reliable Clustering Parameterization. 2008  ,  "}, 1065112 #search_api.search_api.Paper{:id 1065112, :key "journals/sigmod/HalkidiBV02", :title "Cluster Validity Methods: Part I.", :abstract "Clustering is an unsupervised process since there are no predefined classes and no examples that would indicate grouping properties in the data set. The majority of the clustering algorithms behave differently depending on the features of the data set and the initial assumptions for defining groups. Therefore, in most applications the resulting clustering scheme requires some sort of evaluation as regards its validity. Evaluating and assessing the results of a clustering algorithm is the main subject of cluster validity. In this paper we present a review of the clustering validity and methods. More specifically, Part I of the paper discusses the cluster validity approaches based on external and internal criteria.", :author (#search_api.search_api.Author{:id 1491231, :first-name nil, :last-name nil, :full-name "Maria Halkidi"} #search_api.search_api.Author{:id 438548, :first-name nil, :last-name nil, :full-name "Yannis Batistakis"} #search_api.search_api.Author{:id 88969, :first-name nil, :last-name nil, :full-name "Michalis Vazirgiannis"}), :year 2002, :venue "SIGMOD Record", :ncit 344, :string "Cluster Validity Methods: Part I.. Clustering is an unsupervised process since there are no predefined classes and no examples that would indicate grouping properties in the data set. The majority of the clustering algorithms behave differently depending on the features of the data set and the initial assumptions for defining groups. Therefore, in most applications the resulting clustering scheme requires some sort of evaluation as regards its validity. Evaluating and assessing the results of a clustering algorithm is the main subject of cluster validity. In this paper we present a review of the clustering validity and methods. More specifically, Part I of the paper discusses the cluster validity approaches based on external and internal criteria.", :doc-id "Cluster Validity Methods: Part I. 2002  ,  ,  "}, 2867384 #search_api.search_api.Paper{:id 2867384, :key "journals/pr/FalasconiGPSM10", :title "A stability based validity method for fuzzy clustering.", :abstract "An important goal in cluster analysis is the internal validation of results using an objective criterion. Of particular relevance in this respect is the estimation of the optimum number of clusters capturing the intrinsic structure of your data. This paper proposes a method to determine this optimum number based on the evaluation of fuzzy partition stability under bootstrap resampling. The method is first characterized on synthetic data with respect to hyper-parameters, like the fuzzifier, and spatial clustering parameters, such as feature space dimensionality, clusters degree of overlap, and number of clusters. The method is then validated on experimental datasets. Furthermore, the performance of the proposed method is compared to that obtained using a number of traditional fuzzy validity rules based on the cluster compactness-to-separation criteria. The proposed method provides accurate and reliable results, and offers better generalization capabilities than the classical approaches.", :author (#search_api.search_api.Author{:id 1262512, :first-name nil, :last-name nil, :full-name "M. Falasconi"} #search_api.search_api.Author{:id 704813, :first-name nil, :last-name nil, :full-name "A. Gutierrez"} #search_api.search_api.Author{:id 456104, :first-name nil, :last-name nil, :full-name "Matteo Pardo"} #search_api.search_api.Author{:id 39515, :first-name nil, :last-name nil, :full-name "Giorgio Sberveglieri"} #search_api.search_api.Author{:id 458618, :first-name nil, :last-name nil, :full-name "S. Marco"}), :year 2010, :venue "Pattern Recognition", :ncit 5, :string "A stability based validity method for fuzzy clustering.. An important goal in cluster analysis is the internal validation of results using an objective criterion. Of particular relevance in this respect is the estimation of the optimum number of clusters capturing the intrinsic structure of your data. This paper proposes a method to determine this optimum number based on the evaluation of fuzzy partition stability under bootstrap resampling. The method is first characterized on synthetic data with respect to hyper-parameters, like the fuzzifier, and spatial clustering parameters, such as feature space dimensionality, clusters degree of overlap, and number of clusters. The method is then validated on experimental datasets. Furthermore, the performance of the proposed method is compared to that obtained using a number of traditional fuzzy validity rules based on the cluster compactness-to-separation criteria. The proposed method provides accurate and reliable results, and offers better generalization capabilities than the classical approaches.", :doc-id "A stability based validity method for fuzzy clustering. 2010  ,  ,  ,  ,  "}, 3516632 #search_api.search_api.Paper{:id 3516632, :key "conf/fuzzIEEE/ParkerHB12", :title "Comparison of scalable fuzzy clustering methods.", :abstract nil, :author (#search_api.search_api.Author{:id 14199401, :first-name nil, :last-name nil, :full-name "Jonathon K. Parker"} #search_api.search_api.Author{:id 809652, :first-name nil, :last-name nil, :full-name "Lawrence O. Hall"} #search_api.search_api.Author{:id 18556, :first-name nil, :last-name nil, :full-name "James C. Bezdek"}), :year 2012, :venue "FUZZ-IEEE", :ncit 1, :string "Comparison of scalable fuzzy clustering methods.. ", :doc-id "Comparison of scalable fuzzy clustering methods. 2012  ,  ,  "}, 3691896 #search_api.search_api.Paper{:id 3691896, :key "journals/pami/HuLTMZ13", :title "An Incremental DPMM-Based Method for Trajectory Clustering, Modeling, and Retrieval.", :abstract nil, :author (#search_api.search_api.Author{:id 573170, :first-name nil, :last-name nil, :full-name "Weiming Hu"} #search_api.search_api.Author{:id 482587, :first-name nil, :last-name nil, :full-name "Xi Li"} #search_api.search_api.Author{:id 14413337, :first-name nil, :last-name nil, :full-name "Guodong Tian"} #search_api.search_api.Author{:id 199664, :first-name nil, :last-name nil, :full-name "Stephen J. Maybank"} #search_api.search_api.Author{:id 608996, :first-name nil, :last-name nil, :full-name "Zhongfei Zhang"}), :year 2013, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 0, :string "An Incremental DPMM-Based Method for Trajectory Clustering, Modeling, and Retrieval.. ", :doc-id "An Incremental DPMM-Based Method for Trajectory Clustering, Modeling, and Retrieval. 2013  ,  ,  ,  ,  "}, 1031640 #search_api.search_api.Paper{:id 1031640, :key "journals/pami/GathG89", :title "Unsupervised Optimal Fuzzy Clustering.", :abstract "This study reports on a method for carrying out fuzzy classification without a priori assumptions on the number of clusters in the data set. Assessment of cluster validity is based on performance measures using hypervolume and density criteria. An algorithm is derived from a combination of the fuzzy K-means algorithm and fuzzy maximum-likelihood estimation. The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster. The algorithm was tested on different classes of simulated data, and on a real data set derived from sleep EEG signal.", :author (#search_api.search_api.Author{:id 552025, :first-name nil, :last-name nil, :full-name "Isak Gath"} #search_api.search_api.Author{:id 37593, :first-name nil, :last-name nil, :full-name "Amir B. Geva"}), :year 1989, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 1269, :string "Unsupervised Optimal Fuzzy Clustering.. This study reports on a method for carrying out fuzzy classification without a priori assumptions on the number of clusters in the data set. Assessment of cluster validity is based on performance measures using hypervolume and density criteria. An algorithm is derived from a combination of the fuzzy K-means algorithm and fuzzy maximum-likelihood estimation. The unsupervised fuzzy partition-optimal number of classes algorithm performs well in situations of large variability of cluster shapes, densities, and number of data points in each cluster. The algorithm was tested on different classes of simulated data, and on a real data set derived from sleep EEG signal.", :doc-id "Unsupervised Optimal Fuzzy Clustering. 1989  ,  "}, 3526009 #search_api.search_api.Paper{:id 3526009, :key "conf/ijcnn/ParedesV12", :title "Circle-Clustering: A new heuristic partitioning method for the clustering problem.", :abstract nil, :author (#search_api.search_api.Author{:id 14338572, :first-name nil, :last-name nil, :full-name "Gonzalo E. Paredes"} #search_api.search_api.Author{:id 14338573, :first-name nil, :last-name nil, :full-name "Luis S. Vargas"}), :year 2012, :venue "IJCNN", :ncit 0, :string "Circle-Clustering: A new heuristic partitioning method for the clustering problem.. ", :doc-id "Circle-Clustering: A new heuristic partitioning method for the clustering problem. 2012  ,  "}, 790361 #search_api.search_api.Paper{:id 790361, :key "journals/cj/FraleyR98", :title "How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis.", :abstract nil, :author (#search_api.search_api.Author{:id 512807, :first-name nil, :last-name nil, :full-name "Chris Fraley"} #search_api.search_api.Author{:id 891975, :first-name nil, :last-name nil, :full-name "Adrian E. Raftery"}), :year 1998, :venue "Comput. J.", :ncit 1214, :string "How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis.. ", :doc-id "How Many Clusters? Which Clustering Method? Answers Via Model-Based Cluster Analysis. 1998  ,  "}, 3346425 #search_api.search_api.Paper{:id 3346425, :key "journals/tse/BrickeyWB12", :title "Comparing Semi-Automated Clustering Methods for Persona Development.", :abstract nil, :author (#search_api.search_api.Author{:id 14250893, :first-name nil, :last-name nil, :full-name "Jonalan Brickey"} #search_api.search_api.Author{:id 242511, :first-name nil, :last-name nil, :full-name "Steven Walczak"} #search_api.search_api.Author{:id 14224843, :first-name nil, :last-name nil, :full-name "Tony Burgess"}), :year 2012, :venue "IEEE Trans. Software Eng.", :ncit 0, :string "Comparing Semi-Automated Clustering Methods for Persona Development.. ", :doc-id "Comparing Semi-Automated Clustering Methods for Persona Development. 2012  ,  ,  "}, 1032218 #search_api.search_api.Paper{:id 1032218, :key "journals/pami/LeeL05", :title "An Improved Cluster Labeling Method for Support Vector Clustering.", :abstract "The support vector clustering (SVC) algorithm is a recently emerged unsupervised learning method inspired by support vector machines. One key step involved in the SVC algorithm is the cluster assignment of each data point. A new cluster labeling method for SVC is developed based on some invariant topological properties of a trained kernel radius function. Benchmark results show that the proposed method outperforms previously reported labeling techniques.", :author (#search_api.search_api.Author{:id 1414613, :first-name nil, :last-name nil, :full-name "Jaewook Lee"} #search_api.search_api.Author{:id 831562, :first-name nil, :last-name nil, :full-name "Daewon Lee"}), :year 2005, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 185, :string "An Improved Cluster Labeling Method for Support Vector Clustering.. The support vector clustering (SVC) algorithm is a recently emerged unsupervised learning method inspired by support vector machines. One key step involved in the SVC algorithm is the cluster assignment of each data point. A new cluster labeling method for SVC is developed based on some invariant topological properties of a trained kernel radius function. Benchmark results show that the proposed method outperforms previously reported labeling techniques.", :doc-id "An Improved Cluster Labeling Method for Support Vector Clustering. 2005  ,  "}, 985178 #search_api.search_api.Paper{:id 985178, :key "journals/jmlr/BanerjeeMDG05", :title "Clustering with Bregman Divergences.", :abstract "A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we propose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based parametric clustering approaches, such as classical <tt>kmeans</tt>, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical <tt>kmeans</tt> algorithm, while generalizing the method to a large class of clustering loss functions. This is achieved by first posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically decreases this loss. In addition, we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternative interpretation of an efficient EM scheme for learning mixtures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Bregman clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.", :author (#search_api.search_api.Author{:id 1158718, :first-name nil, :last-name nil, :full-name "Arindam Banerjee"} #search_api.search_api.Author{:id 661837, :first-name nil, :last-name nil, :full-name "Srujana Merugu"} #search_api.search_api.Author{:id 161516, :first-name nil, :last-name nil, :full-name "Inderjit S. Dhillon"} #search_api.search_api.Author{:id 224463, :first-name nil, :last-name nil, :full-name "Joydeep Ghosh"}), :year 2005, :venue "Journal of Machine Learning Research", :ncit 663, :string "Clustering with Bregman Divergences.. A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we propose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based parametric clustering approaches, such as classical <tt>kmeans</tt>, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical <tt>kmeans</tt> algorithm, while generalizing the method to a large class of clustering loss functions. This is achieved by first posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically decreases this loss. In addition, we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternative interpretation of an efficient EM scheme for learning mixtures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Bregman clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.", :doc-id "Clustering with Bregman Divergences. 2005  ,  ,  ,  "}, 1239162 #search_api.search_api.Paper{:id 1239162, :key "conf/ciarp/Vega-PonsR09", :title "Clustering Ensemble Method for Heterogeneous Partitions.", :abstract "Cluster ensemble is a promising technique for improving the clustering results. An alternative to generate the cluster ensemble is to use different representations of the data and different similarity measures between objects. This way, it is produced a cluster ensemble conformed by heterogeneous partitions obtained with different point of views of the faced problem. This diversity enhances the cluster ensemble but, it restricts the combination process since it makes difficult the use of the original data. In this paper, in order to solve these limitations, we propose a unified representation of the objects taking into account the whole information in the cluster ensemble. This representation allows working with the original data of the problem regardless of the used generation mechanism. Also, this new representation is embedded in the WKF [1] algorithm making a more robust cluster ensemble method. Experimental results with numerical, categorical and mixed datasets show the accuracy of the proposed method.", :author (#search_api.search_api.Author{:id 66229, :first-name nil, :last-name nil, :full-name "Sandro Vega-Pons"} #search_api.search_api.Author{:id 359750, :first-name nil, :last-name nil, :full-name "José Ruiz-Shulcloper"}), :year 2009, :venue "CIARP", :ncit 3, :string "Clustering Ensemble Method for Heterogeneous Partitions.. Cluster ensemble is a promising technique for improving the clustering results. An alternative to generate the cluster ensemble is to use different representations of the data and different similarity measures between objects. This way, it is produced a cluster ensemble conformed by heterogeneous partitions obtained with different point of views of the faced problem. This diversity enhances the cluster ensemble but, it restricts the combination process since it makes difficult the use of the original data. In this paper, in order to solve these limitations, we propose a unified representation of the objects taking into account the whole information in the cluster ensemble. This representation allows working with the original data of the problem regardless of the used generation mechanism. Also, this new representation is embedded in the WKF [1] algorithm making a more robust cluster ensemble method. Experimental results with numerical, categorical and mixed datasets show the accuracy of the proposed method.", :doc-id "Clustering Ensemble Method for Heterogeneous Partitions. 2009  ,  "}, 985307 #search_api.search_api.Paper{:id 985307, :key "journals/jmlr/Teboulle07", :title "A Unified Continuous Optimization Framework for Center-Based Clustering Methods.", :abstract "Center-based partitioning clustering algorithms rely on minimizing an appropriately formulated objective function, and different formulations suggest different possible algorithms. In this paper, we start with the standard nonconvex and nonsmooth formulation of the partitioning clustering problem. We demonstrate that within this elementary formulation, convex analysis tools and optimization theory provide a unifying language and framework to design, analyze and extend hard and soft center-based clustering algorithms, through a generic algorithm which retains the computational simplicity of the popular k-means scheme. We show that several well known and more recent center-based clustering algorithms, which have been derived either heuristically, or/and have emerged from intuitive analogies in physics, statistical techniques and information theoretic perspectives can be recovered as special cases of the proposed analysis and we streamline their relationships.", :author (#search_api.search_api.Author{:id 1515505, :first-name nil, :last-name nil, :full-name "Marc Teboulle"}), :year 2007, :venue "Journal of Machine Learning Research", :ncit 56, :string "A Unified Continuous Optimization Framework for Center-Based Clustering Methods.. Center-based partitioning clustering algorithms rely on minimizing an appropriately formulated objective function, and different formulations suggest different possible algorithms. In this paper, we start with the standard nonconvex and nonsmooth formulation of the partitioning clustering problem. We demonstrate that within this elementary formulation, convex analysis tools and optimization theory provide a unifying language and framework to design, analyze and extend hard and soft center-based clustering algorithms, through a generic algorithm which retains the computational simplicity of the popular k-means scheme. We show that several well known and more recent center-based clustering algorithms, which have been derived either heuristically, or/and have emerged from intuitive analogies in physics, statistical techniques and information theoretic perspectives can be recovered as special cases of the proposed analysis and we streamline their relationships.", :doc-id "A Unified Continuous Optimization Framework for Center-Based Clustering Methods. 2007  "}, 3483899 #search_api.search_api.Paper{:id 3483899, :key "journals/gis/HongO12", :title "Detecting ethnic residential clusters using an optimisation clustering method.", :abstract nil, :author (#search_api.search_api.Author{:id 14318965, :first-name nil, :last-name nil, :full-name "Seong-Yun Hong"} #search_api.search_api.Author{:id 77603, :first-name nil, :last-name nil, :full-name "David O'Sullivan"}), :year 2012, :venue "International Journal of Geographical Information Science", :ncit 0, :string "Detecting ethnic residential clusters using an optimisation clustering method.. ", :doc-id "Detecting ethnic residential clusters using an optimisation clustering method. 2012  ,  "}, 907739 #search_api.search_api.Paper{:id 907739, :key "journals/ijcv/Lowe04", :title "Distinctive Image Features from Scale-Invariant Keypoints.", :abstract "This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.", :author (#search_api.search_api.Author{:id 337186, :first-name nil, :last-name nil, :full-name "David G. Lowe"}), :year 2004, :venue "International Journal of Computer Vision", :ncit 19774, :string "Distinctive Image Features from Scale-Invariant Keypoints.. This paper presents a method for extracting distinctive invariant features from images that can be used to perform reliable matching between different views of an object or scene. The features are invariant to image scale and rotation, and are shown to provide robust matching across a substantial range of affine distortion, change in 3D viewpoint, addition of noise, and change in illumination. The features are highly distinctive, in the sense that a single feature can be correctly matched with high probability against a large database of features from many images. This paper also describes an approach to using these features for object recognition. The recognition proceeds by matching individual features to a database of features from known objects using a fast nearest-neighbor algorithm, followed by a Hough transform to identify clusters belonging to a single object, and finally performing verification through least-squares solution for consistent pose parameters. This approach to recognition can robustly identify objects among clutter and occlusion while achieving near real-time performance.", :doc-id "Distinctive Image Features from Scale-Invariant Keypoints. 2004  "}, 3620443 #search_api.search_api.Paper{:id 3620443, :key "journals/corr/abs-1301-7401", :title "An Experimental Comparison of Several Clustering and Initialization Methods", :abstract nil, :author (#search_api.search_api.Author{:id 564967, :first-name nil, :last-name nil, :full-name "Marina Meila"} #search_api.search_api.Author{:id 114083, :first-name nil, :last-name nil, :full-name "David Heckerman"}), :year 2013, :venue "CoRR", :ncit 0, :string "An Experimental Comparison of Several Clustering and Initialization Methods. ", :doc-id "An Experimental Comparison of Several Clustering and Initialization Methods 2013  ,  "}, 3395323 #search_api.search_api.Paper{:id 3395323, :key "journals/pr/MokHKA12", :title "A robust adaptive clustering analysis method for automatic identification of clusters.", :abstract nil, :author (#search_api.search_api.Author{:id 679295, :first-name nil, :last-name nil, :full-name "Pik-yin Mok"} #search_api.search_api.Author{:id 723050, :first-name nil, :last-name nil, :full-name "Haiqiao Huang"} #search_api.search_api.Author{:id 1108185, :first-name nil, :last-name nil, :full-name "Yi-lin Kwok"} #search_api.search_api.Author{:id 14276519, :first-name nil, :last-name nil, :full-name "J. S. Au"}), :year 2012, :venue "Pattern Recognition", :ncit 0, :string "A robust adaptive clustering analysis method for automatic identification of clusters.. ", :doc-id "A robust adaptive clustering analysis method for automatic identification of clusters. 2012  ,  ,  ,  "}, 1044411 #search_api.search_api.Paper{:id 1044411, :key "journals/prl/FrossyniotisLS04", :title "A clustering method based on boosting.", :abstract "It is widely recognized that the boosting methodology provides superior results for classification problems. In this paper, we propose the boost-clustering algorithm which constitutes a novel clustering methodology that exploits the general principles of boosting in order to provide a consistent partitioning of a dataset. The boost-clustering algorithm is a multi-clustering method. At each boosting iteration, a new training set is created using weighted random sampling from the original dataset and a simple clustering algorithm (e.g.k-means) is applied to provide a new data partitioning. The final clustering solution is produced by aggregating the multiple clustering results through weighted voting. Experiments on both artificial and real-world data sets indicate that boost-clustering provides solutions of improved quality.", :author (#search_api.search_api.Author{:id 715833, :first-name nil, :last-name nil, :full-name "Dimitrios S. Frossyniotis"} #search_api.search_api.Author{:id 1236023, :first-name nil, :last-name nil, :full-name "Aristidis Likas"} #search_api.search_api.Author{:id 863471, :first-name nil, :last-name nil, :full-name "Andreas Stafylopatis"}), :year 2004, :venue "Pattern Recognition Letters", :ncit 66, :string "A clustering method based on boosting.. It is widely recognized that the boosting methodology provides superior results for classification problems. In this paper, we propose the boost-clustering algorithm which constitutes a novel clustering methodology that exploits the general principles of boosting in order to provide a consistent partitioning of a dataset. The boost-clustering algorithm is a multi-clustering method. At each boosting iteration, a new training set is created using weighted random sampling from the original dataset and a simple clustering algorithm (e.g.k-means) is applied to provide a new data partitioning. The final clustering solution is produced by aggregating the multiple clustering results through weighted voting. Experiments on both artificial and real-world data sets indicate that boost-clustering provides solutions of improved quality.", :doc-id "A clustering method based on boosting. 2004  ,  ,  "}, 3061755 #search_api.search_api.Paper{:id 3061755, :key "journals/bioinformatics/HaoJC11", :title "Clustering 16S rRNA for OTU prediction: a method of unsupervised Bayesian clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 14116895, :first-name nil, :last-name nil, :full-name "Xiaolin Hao"} #search_api.search_api.Author{:id 1290169, :first-name nil, :last-name nil, :full-name "Rui Jiang"} #search_api.search_api.Author{:id 513159, :first-name nil, :last-name nil, :full-name "Ting Chen"}), :year 2011, :venue "Bioinformatics", :ncit 14, :string "Clustering 16S rRNA for OTU prediction: a method of unsupervised Bayesian clustering.. ", :doc-id "Clustering 16S rRNA for OTU prediction: a method of unsupervised Bayesian clustering. 2011  ,  ,  "}, 984956 #search_api.search_api.Paper{:id 984956, :key "journals/jmlr/Ben-HurHSV01", :title "Support Vector Clustering.", :abstract "We present a novel clustering method using the approach of support vector machines. Data points are mapped by means of a Gaussian kernel to a high dimensional feature space, where we search for the minimal enclosing sphere. This sphere, when mapped back to data space, can separate into several components, each enclosing a separate cluster of points. We present a simple algorithm for identifying these clusters. The width of the Gaussian kernel controls the scale at which the data is probed while the soft margin constant helps coping with outliers and overlapping clusters. The structure of a dataset is explored by varying the two parameters, maintaining a minimal number of support vectors to assure smooth cluster boundaries. We demonstrate the performance of our algorithm on several datasets.", :author (#search_api.search_api.Author{:id 43180, :first-name nil, :last-name nil, :full-name "Asa Ben-Hur"} #search_api.search_api.Author{:id 1045131, :first-name nil, :last-name nil, :full-name "David Horn"} #search_api.search_api.Author{:id 352646, :first-name nil, :last-name nil, :full-name "Hava T. Siegelmann"} #search_api.search_api.Author{:id 125753, :first-name nil, :last-name nil, :full-name "Vladimir Vapnik"}), :year 2001, :venue "Journal of Machine Learning Research", :ncit 828, :string "Support Vector Clustering.. We present a novel clustering method using the approach of support vector machines. Data points are mapped by means of a Gaussian kernel to a high dimensional feature space, where we search for the minimal enclosing sphere. This sphere, when mapped back to data space, can separate into several components, each enclosing a separate cluster of points. We present a simple algorithm for identifying these clusters. The width of the Gaussian kernel controls the scale at which the data is probed while the soft margin constant helps coping with outliers and overlapping clusters. The structure of a dataset is explored by varying the two parameters, maintaining a minimal number of support vectors to assure smooth cluster boundaries. We demonstrate the performance of our algorithm on several datasets.", :doc-id "Support Vector Clustering. 2001  ,  ,  ,  "}, 3486588 #search_api.search_api.Paper{:id 3486588, :key "conf/iceis/CarvalhoBSR12", :title "Labeling Methods for Association Rule Clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 322547, :first-name nil, :last-name nil, :full-name "Veronica Oliveira de Carvalho"} #search_api.search_api.Author{:id 14319922, :first-name nil, :last-name nil, :full-name "Daniel Savoia Biondi"} #search_api.search_api.Author{:id 1589972, :first-name nil, :last-name nil, :full-name "Fabiano Fernandes dos Santos"} #search_api.search_api.Author{:id 526939, :first-name nil, :last-name nil, :full-name "Solange Oliveira Rezende"}), :year 2012, :venue "ICEIS (1)", :ncit 0, :string "Labeling Methods for Association Rule Clustering.. ", :doc-id "Labeling Methods for Association Rule Clustering. 2012  ,  ,  ,  "}, 3548061 #search_api.search_api.Paper{:id 3548061, :key "journals/corr/abs-1210-6292", :title "A density-sensitive hierarchical clustering method", :abstract nil, :author (#search_api.search_api.Author{:id 14348081, :first-name nil, :last-name nil, :full-name "Álvaro Martínez-Pérez"}), :year 2012, :venue "CoRR", :ncit 0, :string "A density-sensitive hierarchical clustering method. ", :doc-id "A density-sensitive hierarchical clustering method 2012  "}, 1031101 #search_api.search_api.Paper{:id 1031101, :key "journals/pami/BeniL94", :title "A Least Biased Fuzzy Clustering Method.", :abstract "A new operational definition of cluster is proposed, and a fuzzy clustering algorithm with minimal biases is formulated by making use of the maximum entropy principle to maximize the entropy of the centroids with respect to the data points (clustering entropy). The authors make no assumptions on the number of clusters or their initial positions. For each value of an adimensional scale parameter /spl beta/', the clustering algorithm makes each data point iterate towards one of the cluster's centroids, so that both hard and fuzzy partitions are obtained. Since the clustering algorithm can make a multiscale analysis of the given data set one can obtain both hierarchy and partitioning type clustering. The relative stability with respect to /spl beta/' of each cluster structure is defined as the measurement of cluster validity. The authors determine the specific value of /spl beta/' which corresponds to the optimal positions of cluster centroids by minimizing the entropy of the data points with respect to the centroids (clustered entropy). Examples are given to show how this least biased method succeeds in getting perceptually correct clustering results.", :author (#search_api.search_api.Author{:id 122413, :first-name nil, :last-name nil, :full-name "Gerardo Beni"} #search_api.search_api.Author{:id 1061685, :first-name nil, :last-name nil, :full-name "Xiaomin Liu"}), :year 1994, :venue "IEEE Trans. Pattern Anal. Mach. Intell.", :ncit 99, :string "A Least Biased Fuzzy Clustering Method.. A new operational definition of cluster is proposed, and a fuzzy clustering algorithm with minimal biases is formulated by making use of the maximum entropy principle to maximize the entropy of the centroids with respect to the data points (clustering entropy). The authors make no assumptions on the number of clusters or their initial positions. For each value of an adimensional scale parameter /spl beta/', the clustering algorithm makes each data point iterate towards one of the cluster's centroids, so that both hard and fuzzy partitions are obtained. Since the clustering algorithm can make a multiscale analysis of the given data set one can obtain both hierarchy and partitioning type clustering. The relative stability with respect to /spl beta/' of each cluster structure is defined as the measurement of cluster validity. The authors determine the specific value of /spl beta/' which corresponds to the optimal positions of cluster centroids by minimizing the entropy of the data points with respect to the centroids (clustered entropy). Examples are given to show how this least biased method succeeds in getting perceptually correct clustering results.", :doc-id "A Least Biased Fuzzy Clustering Method. 1994  ,  "}, 3359998 #search_api.search_api.Paper{:id 3359998, :key "journals/eswa/BaiLDC12", :title "A cluster centers initialization method for clustering categorical data.", :abstract nil, :author (#search_api.search_api.Author{:id 92675, :first-name nil, :last-name nil, :full-name "Liang Bai"} #search_api.search_api.Author{:id 211040, :first-name nil, :last-name nil, :full-name "Jiye Liang"} #search_api.search_api.Author{:id 69946, :first-name nil, :last-name nil, :full-name "Chuangyin Dang"} #search_api.search_api.Author{:id 1342804, :first-name nil, :last-name nil, :full-name "Fuyuan Cao"}), :year 2012, :venue "Expert Syst. Appl.", :ncit 1, :string "A cluster centers initialization method for clustering categorical data.. ", :doc-id "A cluster centers initialization method for clustering categorical data. 2012  ,  ,  ,  "}, 515774 #search_api.search_api.Paper{:id 515774, :key "conf/nips/HornG01", :title "The Method of Quantum Clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 1045133, :first-name nil, :last-name nil, :full-name "David Horn"} #search_api.search_api.Author{:id 661263, :first-name nil, :last-name nil, :full-name "Assaf Gottlieb"}), :year 2001, :venue "NIPS", :ncit 0, :string "The Method of Quantum Clustering.. ", :doc-id "The Method of Quantum Clustering. 2001  ,  "}, 1009438 #search_api.search_api.Paper{:id 1009438, :key "journals/ml/Lee02", :title "A Simple Method for Generating Additive Clustering Models with Limited Complexity.", :abstract "Additive clustering was originally developed within cognitive psychology to enable the development of featural models of human mental representation. The representational flexibility of additive clustering, however, suggests its more general application to modeling complicated relationships between objects in non-psychological domains of interest. This paper describes, demonstrates, and evaluates a simple method for learning additive clustering models, based on the combinatorial optimization approach known as Population-Based Incremental Learning. The performance of this new method is shown to be comparable with previously developed methods over a set of &lsquo;benchmark&rsquo; data sets. In addition, the method developed here has the potential, by using a Bayesian analysis of model complexity that relies on an estimate of data precision, to determine the appropriate number of clusters to include in a model.", :author (#search_api.search_api.Author{:id 873860, :first-name nil, :last-name nil, :full-name "Michael D. Lee"}), :year 2002, :venue "Machine Learning", :ncit 0, :string "A Simple Method for Generating Additive Clustering Models with Limited Complexity.. Additive clustering was originally developed within cognitive psychology to enable the development of featural models of human mental representation. The representational flexibility of additive clustering, however, suggests its more general application to modeling complicated relationships between objects in non-psychological domains of interest. This paper describes, demonstrates, and evaluates a simple method for learning additive clustering models, based on the combinatorial optimization approach known as Population-Based Incremental Learning. The performance of this new method is shown to be comparable with previously developed methods over a set of &lsquo;benchmark&rsquo; data sets. In addition, the method developed here has the potential, by using a Bayesian analysis of model complexity that relies on an estimate of data precision, to determine the appropriate number of clusters to include in a model.", :doc-id "A Simple Method for Generating Additive Clustering Models with Limited Complexity. 2002  "}, 1199966 #search_api.search_api.Paper{:id 1199966, :key "reference/opt/HubertA09", :title "Assignment Methods in Clustering.", :abstract nil, :author (#search_api.search_api.Author{:id 433577, :first-name nil, :last-name nil, :full-name "L. J. Hubert"} #search_api.search_api.Author{:id 58846, :first-name nil, :last-name nil, :full-name "Phipps Arabie"}), :year 2009, :venue "Encyclopedia of Optimization", :ncit 0, :string "Assignment Methods in Clustering.. ", :doc-id "Assignment Methods in Clustering. 2009  ,  "}, 3065726 #search_api.search_api.Paper{:id 3065726, :key "journals/corr/abs-1105-0121", :title "Methods of Hierarchical Clustering", :abstract nil, :author (#search_api.search_api.Author{:id 1321196, :first-name nil, :last-name nil, :full-name "Fionn Murtagh"} #search_api.search_api.Author{:id 174224, :first-name nil, :last-name nil, :full-name "Pedro Contreras"}), :year 2011, :venue "CoRR", :ncit 1, :string "Methods of Hierarchical Clustering. ", :doc-id "Methods of Hierarchical Clustering 2011  ,  "}, 3358654 #search_api.search_api.Paper{:id 3358654, :key "journals/jis/LiL12", :title "Application of a clustering method on sentiment analysis.", :abstract nil, :author (#search_api.search_api.Author{:id 371553, :first-name nil, :last-name nil, :full-name "Gang Li"} #search_api.search_api.Author{:id 928209, :first-name nil, :last-name nil, :full-name "Fei Liu"}), :year 2012, :venue "J. Information Science", :ncit 2, :string "Application of a clustering method on sentiment analysis.. ", :doc-id "Application of a clustering method on sentiment analysis. 2012  ,  "}, 1113151 #search_api.search_api.Paper{:id 1113151, :key "journals/tkde/NgH02", :title "CLARANS: A Method for Clustering Objects for Spatial Data Mining.", :abstract "Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. To this end, this paper has three main contributions. First, we propose a new clustering method called CLARANS, whose aim is to identify spatial structures that may be present in the data. Experimental results indicate that, when compared with existing clustering methods, CLARANS is very efficient and effective. Second, we investigate how CLARANS can handle not only points objects, but also polygon objects efficiently. One of the methods considered, called the IR-approximation, is very efficient in clustering convex and nonconvex polygon objects. Third, building on top of CLARANS, we develop two spatial data mining algorithms that aim to discover relationships between spatial and nonspatial attributes. Both algorithms can discover knowledge that is difficult to find with existing spatial data mining algorithms.", :author (#search_api.search_api.Author{:id 143327, :first-name nil, :last-name nil, :full-name "Raymond T. Ng"} #search_api.search_api.Author{:id 745329, :first-name nil, :last-name nil, :full-name "Jiawei Han"}), :year 2002, :venue "IEEE Trans. Knowl. Data Eng.", :ncit 2121, :string "CLARANS: A Method for Clustering Objects for Spatial Data Mining.. Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. To this end, this paper has three main contributions. First, we propose a new clustering method called CLARANS, whose aim is to identify spatial structures that may be present in the data. Experimental results indicate that, when compared with existing clustering methods, CLARANS is very efficient and effective. Second, we investigate how CLARANS can handle not only points objects, but also polygon objects efficiently. One of the methods considered, called the IR-approximation, is very efficient in clustering convex and nonconvex polygon objects. Third, building on top of CLARANS, we develop two spatial data mining algorithms that aim to discover relationships between spatial and nonspatial attributes. Both algorithms can discover knowledge that is difficult to find with existing spatial data mining algorithms.", :doc-id "CLARANS: A Method for Clustering Objects for Spatial Data Mining. 2002  ,  "}, 642207 #search_api.search_api.Paper{:id 642207, :key "conf/vldb/NgH94", :title "Efficient and Effective Clustering Methods for Spatial Data Mining.", :abstract "Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. In this paper, we explore whether clustering methods have a role to play in spatial data mining. To this end, we develop a new clustering method called CLARANS which is based on randomized search. We also develop two spatial data mining algorithms that use CLARANS. Our analysis and experiments show that with the assistance of CLARANS, these two algorithms are very effective and can lead to discoveries that are difficult to find with current spatial data mining algorithms. Furthermore, experiments conducted to compare the performance of CLARANS with that of existing clustering methods show that CLARANS is the most efficient.", :author (#search_api.search_api.Author{:id 143327, :first-name nil, :last-name nil, :full-name "Raymond T. Ng"} #search_api.search_api.Author{:id 745329, :first-name nil, :last-name nil, :full-name "Jiawei Han"}), :year 1994, :venue "VLDB", :ncit 2121, :string "Efficient and Effective Clustering Methods for Spatial Data Mining.. Spatial data mining is the discovery of interesting relationships and characteristics that may exist implicitly in spatial databases. In this paper, we explore whether clustering methods have a role to play in spatial data mining. To this end, we develop a new clustering method called CLARANS which is based on randomized search. We also develop two spatial data mining algorithms that use CLARANS. Our analysis and experiments show that with the assistance of CLARANS, these two algorithms are very effective and can lead to discoveries that are difficult to find with current spatial data mining algorithms. Furthermore, experiments conducted to compare the performance of CLARANS with that of existing clustering methods show that CLARANS is the most efficient.", :doc-id "Efficient and Effective Clustering Methods for Spatial Data Mining. 1994  ,  "}, 2867423 #search_api.search_api.Paper{:id 2867423, :key "journals/pr/Xavier10", :title "The hyperbolic smoothing clustering method.", :abstract "The minimum sum-of-squares clustering problem is considered. The mathematical modeling of this problem leads to a min-sum-min formulation which, in addition to its intrinsic bi-level nature, has the significant characteristic of being strongly nondifferentiable. To overcome these difficulties, the resolution, method proposed adopts a smoothing strategy using a special C^~ differentiable class function. The final solution is obtained by solving a sequence of low dimension differentiable unconstrained optimization subproblems which gradually approach the original problem. The use of this technique, called hyperbolic smoothing, allows the main difficulties presented by the original problem to be overcome. A simplified algorithm containing only the essentials of the method is presented. For the purpose of illustrating both the reliability and the efficiency of the method, a set of computational experiments was performed, making use of traditional test problems described in the literature", :author (#search_api.search_api.Author{:id 1494398, :first-name nil, :last-name nil, :full-name "Adilson Elias Xavier"}), :year 2010, :venue "Pattern Recognition", :ncit 16, :string "The hyperbolic smoothing clustering method.. The minimum sum-of-squares clustering problem is considered. The mathematical modeling of this problem leads to a min-sum-min formulation which, in addition to its intrinsic bi-level nature, has the significant characteristic of being strongly nondifferentiable. To overcome these difficulties, the resolution, method proposed adopts a smoothing strategy using a special C^~ differentiable class function. The final solution is obtained by solving a sequence of low dimension differentiable unconstrained optimization subproblems which gradually approach the original problem. The use of this technique, called hyperbolic smoothing, allows the main difficulties presented by the original problem to be overcome. A simplified algorithm containing only the essentials of the method is presented. For the purpose of illustrating both the reliability and the efficiency of the method, a set of computational experiments was performed, making use of traditional test problems described in the literature", :doc-id "The hyperbolic smoothing clustering method. 2010  "}}}